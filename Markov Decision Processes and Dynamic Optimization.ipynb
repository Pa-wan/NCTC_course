{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href='http://fonts.googleapis.com/css?family=Fenix' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Source+Code+Pro:300,400' rel='stylesheet' type='text/css'>\n",
       "<style>\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
       "    }\n",
       "    div.cell{\n",
       "        width:1000px;\n",
       "        margin-left:5% !important;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    h1 {\n",
       "        font-family: 'Alegreya Sans', sans-serif;\n",
       "    }\n",
       "    h2 {\n",
       "        font-family: 'Fenix', serif;\n",
       "    }\n",
       "    h3{\n",
       "\t\tfont-family: 'Fenix', serif;\n",
       "        margin-top:12px;\n",
       "        margin-bottom: 3px;\n",
       "       }\n",
       "\th4{\n",
       "\t\tfont-family: 'Fenix', serif;\n",
       "       }\n",
       "    h5 {\n",
       "        font-family: 'Alegreya Sans', sans-serif;\n",
       "    }\t   \n",
       "    div.text_cell_render{\n",
       "        font-family: 'Alegreya Sans',Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "        line-height: 135%;\n",
       "        font-size: 150%;\n",
       "        width: 900px;\n",
       "        margin-left:auto;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    .CodeMirror{\n",
       "            font-family: \"Source Code Pro\";\n",
       "\t\t\tfont-size: 90%;\n",
       "    }\n",
       "/*    .prompt{\n",
       "        display: None;\n",
       "    }*/\n",
       "    .text_cell_render h1 {\n",
       "        font-weight: 200;\n",
       "        font-size: 50pt;\n",
       "\t\tline-height: 100%;\n",
       "        color:#CD2305;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\t\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 300;\n",
       "        font-size: 16pt;\n",
       "        color: #CD2305;\n",
       "        font-style: italic;\n",
       "        margin-bottom: .5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\n",
       "    \n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "        }  \n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division, print_function\n",
    "import pylab as plt\n",
    "import book_format\n",
    "book_format.load_style(name='/styles/custom4.css')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Decision Processes and Dynamic Optimization\n",
    "\n",
    "So far we have seen a number of approaches for calculating optimal decisions from a set of competing alternative actions. However, making optimal decisions when outcomes or events occur over time is more difficult. This is particularly the case when there is uncertainty in the dynamics of the system. That is, the state transitions from one point in time to the next can be influenced by decisions made at each step.\n",
    "\n",
    "## Iterative Decision-making\n",
    "\n",
    "First let's try to characterize the iterative (or sequential) decision-making problem. \n",
    "\n",
    "A decision-maker (or **agent**) is required to make recurring decisions. In a natural resource management setting, this could entail the setting of annual harvest policies (bag or catch limits) or stocking decisions; in an epidemiologic setting, this could be deciding the composition of the annual influenza vaccine based on information from outbreaks in other parts of the world.\n",
    "\n",
    "In principle, sequential decisions may be made in continuous time; for simplicity we will constrain decisions to occur at discrete time steps:\n",
    "\n",
    "$$t = 0, 1, 2, 3, \\ldots$$\n",
    "\n",
    "the decision intervals may or may not be of fixed widths; they may be arbitrary successive deicision-making stages.\n",
    "\n",
    "At each time step $t$, the decision-maker receives some representation of the environment’s **state** $x_t$.\n",
    "\n",
    "$$x_t \\in X$$\n",
    "\n",
    "the state may be univariate or multivariate, and may range from precise low-level instrument readings to high-level categorical descriptors of the environment.\n",
    "\n",
    "Given this state, the decision-maker chooses an **action** $a_t$ from a set of actions whose composition may depend on the state.\n",
    "\n",
    "$$a_t \\in A(x_t)$$\n",
    "\n",
    "Actions too can be specific and fine-grained (*e.g.* setting of waterfowl bag limits and season lengths) or be more general, high-level policy decisions (*e.g.* initiate captive breeding program or build a wildlife refuge).\n",
    "The set of available actions may also be temporally dynamic.\n",
    "\n",
    "Partly as the result of taking this action, the decision-maker receives a numeric **reward**\n",
    "\n",
    "$$r_t \\in R$$\n",
    "\n",
    "and the system moves to a **new state** $s_{t+1}$ as the time step increments.\n",
    "\n",
    "\n",
    "![RL environment](http://fonnesbeck-dropshare.s3.amazonaws.com/Screen-Shot-2015-03-16-08-29-10.png)\n",
    "\n",
    "\n",
    "#### In general, the goal is to maximize the system reward received, over the long run\n",
    "\n",
    "The simplest case is the simple sum of rewards:\n",
    "\n",
    "$$r = r_t + r_{t+1} + \\ldots + r_{T}$$\n",
    "\n",
    "where $T$ is a final time step. This approach makes sense in applications in which there is a natural notion of final time step, that is, systems which are *episodic*. There may be just a single episode, or multiple episodes.\n",
    "\n",
    "In contrast, some problems entail a continual process-control task (or episodes that are so long that they may be considered so). We call these *continuing* tasks. This implies that $T=\\infty$, and the corresponding sum of rewards could itself easily be infinite.\n",
    "\n",
    "In continuing tasks (and even some episodic tasks), we must invoke a **discount rate** $\\gamma \\in [0, 1]$ which determines the present value of future rewards. The rate applies multiplicatively to future rewards:\n",
    "\n",
    "$$r = r_t + \\gamma r_{t+1} + \\gamma^2 r_{t+2} + \\ldots = \\sum_{k=0}^{\\infty} \\gamma^k r_{t+k+1}$$\n",
    "\n",
    "The notion is that a reward received $k$ time steps in the future is worth only $\\gamma^{k-1}$ times what it would be worth if it were received immediately. If $\\gamma < 1$, the infinite sum $r$ has a finite value. \n",
    "\n",
    "Smaller values of $\\gamma$ result in *myopic* behavior; In the special case where $\\gamma = 0$, the decision-maker is concerned only with maximizing current reward.\n",
    "\n",
    "\n",
    "## The Markovian Property\n",
    "\n",
    "It can be useful to model these problems as a discrete time Markov process. Markov processes have the property that the future depends on the current state, but not past states. In other words, the transitions are *conditionally independent* of past states, given the present state.\n",
    "\n",
    "$$\\begin{gathered}\n",
    "\\begin{split}Pr(X_{t+1}=x_{t+1} | X_t=x_t, X_{t-1}=x_{t-1},\\ldots,X_0=x_0) = Pr(X_{t+1}=x_{t+1} | X_t=x_t)\\end{split}\\notag\\\\\\begin{split}\\end{split}\\notag\\end{gathered}$$\n",
    "\n",
    "This is the Markovian property.\n",
    "\n",
    "A **discrete** Markov process is one where the state space is *countable*. It describes movement from state $i$ to state $j$ over some interval of time $\\Delta t$.\n",
    "\n",
    "$$p(X_{t + \\Delta t} = j | X_t = i)$$\n",
    "\n",
    "It is useful to think of the Markovian property as “mild non-independence”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Chains\n",
    "\n",
    "A Markov chain is a special type of discrete Markov process, where the time step $\\Delta t=1$ and the transitions are stationary. Stationarity implies that the transition probabilities are time-homogeneous.\n",
    "\n",
    "$$p_{ij} = p(X_{t + 1} = j | X_t = i)$$\n",
    "\n",
    "> **Homogeneity**: A Markov chain is homogeneous at step t if the transition probabilities are independent of time t.\n",
    "\n",
    "> **Stationarity**: A stationary Markov chain produces the same marginal distribution when multiplied by the transition kernel.\n",
    "\n",
    "The Markov chain wanders about the state space, remembering only where it has just been in the last time step. The collection of transition probabilities is sometimes called a *transition matrix* when dealing with discrete states, or more generally, a *transition kernel*.\n",
    "\n",
    "$$P = \\left[{\n",
    "\\begin{array}{c}\n",
    "  {p_{11}} & {p_{12}} & \\ldots & {p_{1k}}  \\\\\n",
    "  {p_{21}} & {p_{22}} & \\ldots & {p_{2k}}  \\\\\n",
    "  \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "  {p_{k1}} & {p_{k2}} & \\ldots & {p_{kk}}  \\\\\n",
    "\\end{array}\n",
    "}\\right]$$\n",
    "\n",
    "Row $i$ of the matrix are the probabilities of moving from state $i$ to each possible state $j$ (including $i$ itself); hence the rows sum to 1.\n",
    "\n",
    "### Example: stationary Markov chain\n",
    "\n",
    "Consider a Markov transition matrix\n",
    "\n",
    "$$P = \\left[{\n",
    "\\begin{array}{c}\n",
    "  {0.3} & {0.5} & {0.2}  \\\\\n",
    "  {0.6} & {0} & {0.4}  \\\\\n",
    "  {0} & {0.4} & {0.6}  \\\\\n",
    "\\end{array}\n",
    "}\\right]$$\n",
    "\n",
    "The three states in the space are all recurrent aperiodic, and therefore it has a stationary limiting distribution. We can show this by simulating the chain with an arbitrarily-chosen starting distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "P = np.array([[0.3, 0.5, 0.2],\n",
    "              [0.6, 0., 0.4],\n",
    "              [0., 0.4, 0.6]])\n",
    "\n",
    "x = [0.5, 0.3, 0.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a single transition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.33,  0.33,  0.34])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.T.dot(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two transitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.297,  0.301,  0.402])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.T.dot(P.T.dot(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Five transitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.261897,  0.305349,  0.432754])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for t in range(5):\n",
    "    x = P.T.dot(x)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fifteen transitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.26086929,  0.30434832,  0.43478239])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for t in range(10):\n",
    "    x = P.T.dot(x)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a Markov chain is stationary, we can express two-step (or more) transitions in terms of its constituent one-step transitions. The probability of moving from $i$ to $k$ in two steps is just the product of the probability moving from $i$ to $j$ in one step, and then from $j$ to $k$ in another step, summing over all $j$.\n",
    "\n",
    "$$ p(X_{t+2} = k | X_t = i) = p_{ik}^{(2)} = \\sum_{j=1}^{n_j} p_{ij} p_{jk}$$\n",
    "\n",
    "This generalizes to an arbitrary number of steps by:\n",
    "\n",
    "$$p_{ik}^{(r+s)} = \\sum_{j=1}^{n_j} p_{ij}^{(r)} p_{jk}^{(s)}$$\n",
    "\n",
    "which describes the probability of moving from $i$ to $j$ in $r$ steps, and then from $j$ to $k$ in $s$ steps. This relationship is known as the *Chapman-Kolmogorov* equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Disease dynamics\n",
    "\n",
    "One can simulate the dynamics of an infectious disease using a discrete Markov process. This example is from Zipkin et al. (2010), which examined an avian disease affecting house ﬁnch (*Carpodacus mexicanus*) populations. The *Mycoplasma gallisepticum* pathogen caused a major epidemic of conjunctivitis in house ﬁnches in 1994, and was modeled by Zipkin et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9 ,  0.05,  0.05],\n",
       "       [ 0.1 ,  0.7 ,  0.2 ],\n",
       "       [ 0.  ,  0.  ,  1.  ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = np.array([[0.90, 0.05, 0.05],\n",
    "                [0.10, 0.70, 0.20],\n",
    "                [0, 0, 1]])\n",
    "P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rows are the state of a process for a given individual (0 = susceptible, 1 = infected and 2 = dead) at time $t$ and the columns indicate the state of the process at the following time step $t + 1$.\n",
    "\n",
    "Let's use this transition matrix to simulate the disease dynamics of a population of 100 susceptible individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = [100, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each step in the process, the transition matrix will be multiplied by the current vector of states, to yield an updated vector of states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize list with initial states\n",
    "X = [x]\n",
    "\n",
    "for t in range(20):\n",
    "    # Calculate transistion\n",
    "    new_x = P.T.dot(X[-1])\n",
    "    # Append new vector to list\n",
    "    X.append(new_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1042ea2b0>,\n",
       " <matplotlib.lines.Line2D at 0x1042ea550>,\n",
       " <matplotlib.lines.Line2D at 0x1042ea780>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAaEAAAEBCAYAAADRtBosAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmYHEX9x/F37ZGE3DEQCGcKEu7IFeUIRyABFTlaRRSQ\n",
       "AHILdosKiIJCOEQQsFsFFEQOgUh+YEO4j3CGMyAQ5EqggChXCGEJubPbvz+qNzuZ7dnMzs70XN/X\n",
       "8/Szu909s8Uwmc9WdfW3VBRFCCGEEOXQUO4GCCGEqF8SQkIIIcpGQkgIIUTZSAgJIYQoGwkhIYQQ\n",
       "ZSMhJIQQomy6DCGl1K5KqWeVUhdl7BuvlHpcKfWYUmqv1e0XQgghclFd3SeklBoPDAB2iaLoNKWU\n",
       "Ap4AxgMKuC+Kot1z7S9564UQQlS1LntCURQ9BMzP2DUKeCOKoiVRFC0GZiulRnaxXwghhMipqZvn\n",
       "DwValFKXYns8LfG+hhz7ZxexrUIIIWpMd0NoHjAYOBEbNlfE+xpy7O+kpaVF6gQJIUSNGzRokMrn\n",
       "vHxDqP3JZmOH3tr3jYyiaLZSqiFpf76NFUIIUZ+6DCGl1OnAN4C1lVIDoyg6Xik1CXgQiIBzAKIo\n",
       "alNKnZO9XwghhOhKl7PjSiFzOO6sa49o/3Y5MD7wwsdTbUwdmTFjRgQwZsyYvLrIojjkdS8Ped3L\n",
       "I/PzPd/huEq5WbUZ+JfrO5uUuyFCCCHSUykhBHY23VTXdwaVuyFCCCHSUe4QOjvr5y2AW1zf6e6s\n",
       "PSGEEFWo3CE0CZictW8f4A9laIsQQoiUlTWEAi+MgB8Cz2QdOsn1nZPL0CQhhBApKndPiMALFwMO\n",
       "8F7WId/1na+VoUlCCCFSUvYQAgi88ENgf+CLjN0N2OtDW5anVUIIIUqtIkIIIPDCl4FDsDe7thsI\n",
       "3On6zlrlaZUQQohSqpgQAgi88E7g51m7NXCb6zu9y9AkIYQQJVRRIRS7DLgqa9+uwF9d35G7n4UQ\n",
       "ooZUXAjFM+ZOAh7OOjQROD39FgkhhCiVigshgMALlwMHAbOyDv3W9Z1vl6FJQgghSqAiQwgg8MJP\n",
       "gf1YdWVXgH+4vrNDGZokhBCiyCo2hAACL3wT2yNakbF7DeAO13fWK0+rhBBCFEtFhxBA4IXTsCu2\n",
       "ZloXG0T9ytAkIYQQRVLxIQQQeOHVwKVZu7cHrnd9pyr+G4QQQnRWTR/gpwF3Zu37NnBuGdoihBCi\n",
       "CKomhAIvbAUOBV7OOvRL13eOKkOThBBC9FDVhBBA4IULgAOAj7IOXe36zmFlaJIQQogeqKoQAgi8\n",
       "8F1s1e2lGbsbsNeHDilPq4QQQhSi6kIIIPDCp7HFTlszdjdg7yH6XnlaJYQQoruqMoQAAi/8F8lB\n",
       "dKPrO98tT6uEEEJ0R9WGEEDghVOAw4C2jN2NwM2u73ynPK0SQgiRr6oOIYDAC/8J/IDOQTTZ9Z1v\n",
       "ladVQggh8lH1IQQQeOHN2CrbmUHUhF2Z9cDytEoIIcTq1EQIAQReeCNwJKuuzNoETHF9Z/+yNEoI\n",
       "IUSXaiaEAAIvvAE4ilWDqBm41fWd/crTKiGEELnUVAgBBF54HXBM1u72INq3DE0SQgiRQ82FEEDg\n",
       "hdcAx2bt7gXc5vrO18vQJCGEEAlqMoRgZeXt47N29wZC13f2KUOThBBCZKnZEAIIvPCvdF6LqDdw\n",
       "u+s7E8rQJCGEEBlqOoQAAi+8Ejgpa3cfYKrrO3uVoUlCCCFiNR9CAIEXXg78OGt3H+BO13fGpd8i\n",
       "IYQQUCchBBB44Z+An2TtXgO4y/WdPcrQJCGEqHt1E0IAgRf6wE+zdvfFBtFuZWiSEELUtboKIYDA\n",
       "Cy8Dfp61ux9wj+s7u5ahSUIIUbfqLoQAAi+8BDg9a3d7EI1Lv0VCCFGfCg4hpdRRSqlnlFJPKKX2\n",
       "jPdNUEo9rpR6TClV0TPPAi+8CDgja3d/4H5ZKlwIIdLRk57QKcDOwL7A+UopBZwD7A18DTi7x60r\n",
       "scALLwTOzNrdjF2h9Zeu76gyNEsIIepGT0LoZWACcABwHzAKeCOKoiVRFC0GZiulRhahjSUVeOH5\n",
       "dB6aAzgf+IvrO00pN0kIIeqGiqJo9WclPVCp44HdsUF2MzAXOBhbwbq9BzE5iqJnMh/X0tKy8hfO\n",
       "mjWroN9dCmbuK0yfNZW2qHWV/esO3oQ9Nvs2zU29y9QyIYSoDqNGjVr5/aBBg/IaSSqoJ6SU2gTY\n",
       "K4qiw6IoOgQ7NPcFMBj4ZbwNAeYV8vzloNfamr23OpRejX1W2f/+Z29x7yvXs2jpgjK1TAghaleh\n",
       "Q00NwCAApVQzNnxmY4fkwPaERkZRNLurJxkzZkyFXXMZw32v3LAFcDcwon3v/IUf8X8z/DnAvoEX\n",
       "vlKu1vXEjBkzIqjE17y2yeteHvK6l0fmSFe+CuoJRVE0C3hMKfUU8Djwh/g60CTgQew1onMKee5y\n",
       "C7zwNeyEixlZhzYApru+Mz79VgkhRG0qeGJCFEUXRFG0cxRFO0VRdF287/4oinaNomi3KIoeKF4z\n",
       "0xV44YfAOGBq1qGBwL2u7xyReqOEEKLCaK37a6330lr/Umud/XmZF5n5lUPghQtd3/kWEAA/yjjU\n",
       "BFzr+s5GwLmBFxY2s0MIIaqI1loBmwI7YUeLdga2podFD+qyYkK+Ai9sBU4GTk04fA5wjes7zem2\n",
       "SgghSk9rPVBrvbfW+iyt9d3AJ8DrwLXYBUO/TBEyRHpCqxH3dH7v+s57wPXYRfHaHQms7/rOQYEX\n",
       "tpSjfUII0VNa6wZgczp6OTsBW9Fxu03JSE8oT4EX3oK9OffTrEMTgMdd31k//VYJIUT3aa37aK13\n",
       "i6/l3IO9neY/wN+AY7DDbPkGUGbvqNukJ9QNgRc+4frOzsA9wMYZh0YDz7i+s2/ghS+Vp3VCCJFM\n",
       "az0Q2AXYLd6+yqqjOvlqAZ4BngaeAp41xqz8w7ylpeUv3X1CCaFuCrzwzTiI7gB2zDi0LrZHdFDg\n",
       "hfeXp3VCCAFa62F0BM7uwDZ0f+QrAl7Fhk176LxujGkrYlMlhAoReOHHru/sBdwIOBmHBgB3u75z\n",
       "XOCF15SndUKIehLPWhvBqqGzaQFPNR8bNpm9nJJf65YQKlDghYtc3zkIuBRwMw41An9zfWdj4NeB\n",
       "Fxb1rwYhRH2LQ2dz7L2M7aGzXgFP9S7wGLbgwBPAG8Xu5eRDQqgH4incnus7BhtGmRfyfgVs5/rO\n",
       "4YEXZk9mEEKIvGmtRwDjgb3ibZ0CnuZVOkLncWPMnCI1r0ckhIog8MI/xFO4bwQyK6DuC7zg+s53\n",
       "Ay98rjytE0JUG631OsCedASP7uZTtAIvYAPnMWC6MeaTojaySCSEiiTwwtvi60R3AGtmHNoIW3Pu\n",
       "J8AVUmFBCJFNaz0E2AMbOOOBLbv5FEuw13LaQ+dpY8wXRW1kiUgIFVHghU+5vrM9cAv2Zq92zcCf\n",
       "gV3jSQtV8eYQQpSG1rofMJaOns72dG/22kJs4DyCDZ3njTHLitzMVEgIFVnghXNc39kDuAjwsg4f\n",
       "AmwbT+N+Nf3WCSHKQWvdhL03Z29s8OyE/eM0X8uAJ4FpwEPAc8aY5cVuZzlICJVA4IXLgJ+4vjMd\n",
       "uAbon3F4C+A513eODbzwprI0UAhRclrr9YCvAV/Hhs/gbjy8DbuczEPY4HnSGLOo6I2sABJCJRR4\n",
       "4RTXd14G/g9bBqNdX+BG13d2BU4JvHBpWRoohCgarXVvYFc6gmd0N59iJjZwpgGPpnGPTiWQECqx\n",
       "wAvfcH1nR+AKYGLW4ROBr8Sz595JvXFCiB7RWm+CDZyvY6/t9O3Gw9+io6fziDHmo+K3sPJJCKUg\n",
       "vrH1SOyFxD+xas2mMdhp3BMDL7yzHO0TQuQnnlAwjo7gGdmNh88D7gceAKYZY94tegOrkIRQSuKp\n",
       "2Ve7vvM8dnguswDqEGCq6zu/xVZZWFGONgohVhVXJ9iSjtDZHeiV58PbsMU+7423540xraVoZzWT\n",
       "EEpZ4IX/dn1nB2zp8wOzDp8B7Oz6ziHxEuNCiJRprXthy+EcEG8juvHw97GBcx/wYGaFaZFM1hMq\n",
       "g8ALPwO+hV2xNfsvo3HAv13f2T3tdglRr7TWQ7TWh2qtJwNzgQexNSFHrOahy7HXdE7DrjS6vjHm\n",
       "aGPMLRJA+ZGeUJlkrNj6DPBPYHjG4XWAaa7v/BK4WKosCFF88aSC/bG9nd2xxYfz8TYdQ2wPV0tl\n",
       "gkolIVRmgRc+7vrOdsDN2FpR7RqB3wFjXd85Iu49CSEKpLVuxN4w2j7Mlm9pnKXY3s7dwL3GmNml\n",
       "aWF9kuG4ChB44UfYm9nOTzh8APBSXJdOCNENWut+WmtHa/037PWaJ4FfsPoAmou90dwBhhpj9jXG\n",
       "/EkCqPikJ1Qh4mUhznR950ngH9gZc+02BB5yfeePwC8CL6zJO6eFKAat9bDjjjuOGTNmgJ0Wne8y\n",
       "1v8BpmKLED8rM9nSoaIo3csNLS0tK3/hoEGDVFfn1ivXdzYCpgBfSTg8Czgy8MInu/OcM2bMiADG\n",
       "jBkjr3mK5HVPR7z0wbeBg7DVqPMZ5WnFFv+8A5hqjHmrdC2sD4V8vktPqAIFXviu6zu7YYfnfsqq\n",
       "i+WNAh53fedi4DdS8kfUq7g2W3vw7Maq/05y+Rx7becO7PWd+aVrociH9IQqXBxG17Lqza3tXgGO\n",
       "CLzwhdU9j/xFXh7yuheX1noD4DvAd4Fd8nzYO9jQuQO7omhVLnlQDaQnVIPi2XPbYJeGODHr8NbA\n",
       "M67vnAv8NvDCmijtLkQmrbXGBs9BwI75PGbEiBHstNNOTJ48eTTwH2OM3OZQoaQnVEVc39kH+Buw\n",
       "fsLh54GJudYpkr/Iy0Ne98LE9/AcFG9j8nxYe0msW6dMmfImyOueNukJ1bjAC+93fWc08AfgiKzD\n",
       "O2ALoZ4JXBbPthOiamitR2GH2Q4CtsvzYc8SB48x5u32nfHMOFEFJISqTHzT6pGu7/wL+CswLONw\n",
       "b+BiwHF958jAC+WeBlHR4llt3wMOI3k2aJKnsLNHb5NK1NVPQqhKBV54e7xy6xXYvxwzjcXe4Hoq\n",
       "cGXghW2pN1CIHLTWA7C1Ew8DJrD66dQRMJ2O4PlvaVso0iQVE6pY4IWfAAcDhwDZU037An8G7nN9\n",
       "Z8O02yZEJq11s9Z6v7hA6EfAdcA+5P4MagMeAU7GFgXdzRgTSADVHukJVbm4uOlk13ceBa4Cvpl1\n",
       "ygRg5uyPXmKTYV9OvX2ifsVr8eyC7fEcDAzN42GPApOBf9XrSqP1RnpCNSLwwg+wFYGPBhZkHR74\n",
       "5OypPPzaLbi+M7zzo4UoHq31llrr87HVpp/A3lrQVQC9DJwObGiMGWeMuVICqH7IFO0aFJf9uQa7\n",
       "5n22z4GzgMtlBdfSq5cp2nH1gu9jez35zGx7D7gJuNEY80qx21Mvr3ulKeTzveCekFJqPaXUNKXU\n",
       "Y0qpS+J9E5RSj8f7pOpzmQRe+C62KvePgcVZhwcCPvCc6zs7pd02UTviCtVHaK0fAuYAv6frAJoP\n",
       "/AW7do82xpxRigAS1aXgnpBS6mYgiKLoqfhnhe16j8fWcLoviqJOq4NKTyhdru+Mwpb9yVXi5Gps\n",
       "Ze55qTWqjtTaX+TxdZ4dscO+3wf6r+YhS7CVqW8E7kmrZE6tve7VIrWekFKqARjZHkCxUcAbURQt\n",
       "iaJoMTBbKTWykOcXxRN44Sxg96/ofWhuTKxofwzwhus7R7u+I9cIRSKt9TCt9c+w9Qqfwr5vcgVQ\n",
       "G3Z57KOAtY0xBxtjbpeabSJJobPj1gL6KKX+hR3e+RPwIdCilLoU2xNqwV6MlBsmyyzwwtYZM2aw\n",
       "0Zpb8H/P+TcBh2adMhTbIzra9Z0TAy98Kf1WikqjtW4Cvobt9ezP6j8vnsf2eCYbYz4ocfNEjSho\n",
       "OE4p1QQ8jF23owl7I9kPscsOnIgNoSuA86IoWiWEMrtrs2bNKrjhonAffGZ49u17aVnceQROodh8\n",
       "+FfYZsM96NWU71pgopZ88MEHPPzwwzzyyCPMn9/1SgdDhgxhjz32YNy4cay33noptVBUqlGjRq38\n",
       "vqS146IoWqGUmgMMj6Lof0qpJdgeT3sLFHa4TnpBFWj4YM1+2x7Hq+8/zctzHqe1rWOSXETEax88\n",
       "yzufvMoYvTcj1twSe7lP1LIlS5bw9NNPM23aNF577bUuz21sbGT77bdn/PjxbLvttjQ2NqbUSlGL\n",
       "ejIxYUPgSuxw3C1RFAVKqX2AX2PLbEyKouiB7MfJxITyyHWh1vWdEdiCqAfmeOhDwEmBF75R0gbW\n",
       "qEq+QB5PMvgqHZMMBqzmIa9jq7jfUOn38VTy617LUq2iHUXRe8C+WfvuB+4v9DlF+gIvfAdb8HR/\n",
       "IABGZJ0yHpjp+s5FwAWBFy5Kt4Wi2LTWawITsUPoW63m9C+wFQyuAZ6WdXlEsclsKAFA4IVTsR9I\n",
       "5wPZi+M1A78C/uP6zn5pt030nNZaaa131FpfD/wXuISuA+gJ7Oy24caYY40xT0kAiVKQ2nFipbiX\n",
       "c6brOzdgi5+OzzplBDDV9Z3bAS++KVZUMK11X+xQ20nA9qs5/UNsYdG/G2Nk+FWkQnpCopP4+s/e\n",
       "2OrcSVNtDwRec31nkus7q7uOIMpAaz1Ka30p8D/sdZxcAbQCCIEDgA2MMb+QABJpkp6QSJRRnftu\n",
       "4BzAZdU/WtbA1qA73vWds4GrAy/MHsYTKdJaN2KrqJ+EXSahK29jS+hcV+mTDERtkxASXQq88HPg\n",
       "FNd3rgMuB3bOOmVYvN9zfed04I44wERKtNbDsDPcTgC6WjsqAu7C/v+6zxgjix2KspPhOJGXwAtf\n",
       "BHYFjgU+TjhlM+ywzqOu7+yYZtvqUTzRYBet9T+wxUMvIHcAzQN+B2xijNnfGHOPBJCoFNITEnmL\n",
       "lwm/2vWdfwKnAT/DDstl2g142vWdW4BfBl74VsrNrGla637Ysks/ArZdzelPY3s9U4wxS0rdNiEK\n",
       "ISEkui3wwgXAWa7vXAFMwk7lze5VHwx8y/Wdy4Hz4qXIRYG01iOxS10fCQzq4tTF2HV6LjfGvJBC\n",
       "04ToEQkhUbDAC98HjnF95w/Y4Z59s05pBjzgSNd3fgsEgRdmr28kcogrGozF9jgPxJbDymU2ttdz\n",
       "rTGm64JvQlQQuSYkeizwwlcCL/wm9r6ipL++BwEXYpeMmChLRnRNa92ktf4edjjtccAhOYDagNux\n",
       "la43M8ZcJgEkqo18GIiiCbxwGvAV4AfY5ZuzbYC9GfJ513cmpNm2aqC1Hqi1PgXbq5mMreuWZC52\n",
       "IsLGxhjHGHO/TDQQ1UqG40RRxZMXbnR951bsNYxfAYOzTtsWeMD1nXuB0wMvfDnlZlYUrfUG2Puw\n",
       "jsMWBM7lReBS4BZjzNI02iZEqUlPSJRE4IVLAi/8PTASuIzO9egAvg686PrO313f2TjVBlYArfUO\n",
       "WuubAAP8nNwBdBewF7C9MeYGCSBRS6QnJEoq8MJ5wE9d3/kjdgjp+1mnKOyMr8PjG2LPD7zw7XRb\n",
       "mR6tdQOwH3aywe5dnLoEuB64zBjzehptE6IcpCckUhF4oQm88BDsdY5HE05pxC4t8KbrO9e4vrNJ\n",
       "qg0sMa11X631CcBr2MkEuQJoLnA2sKEx5ngJIFHrJIREqgIvfA7YE9gf+4GcrRF739Eb8TDdyDTb\n",
       "V2zz589n8uTJYCdqXAFsmuPU17DVKDYyxpxjjJmbUhOFKKuCV1YtlKysWh6VuNKk6ztN2OG5s8j9\n",
       "4dwK/AN7w2vVLBevtR4BnN7c3HzC8uVd1nWdhl3b516Z4VY8lfh+rweFfL5LCNWJSv5H6fpOIzaM\n",
       "fk2Vh5HWejPgDOw09cYcp60AbgYuNca8mFbb6kklv99rmYSQyKka/lFmhNFZ2IKoSdroCKNZabVt\n",
       "dbTWX8ZOR/8uuSsbfAZcCfzJGPO/tNpWj6rh/V6LJIRETtX0jzIOo+9he0ZdhdGN2DB6M622ZdNa\n",
       "74gNn/1znbPWWmsxd+5cF7ti6RepNa6OVdP7vZZICImcqvEfZRxGB2PDaPMcp7VhC3aeF68IW3Jx\n",
       "TbfdgTOBrio/vHHSSSdttuuuu7LTTjtVzeteC6rx/V4LCvl8l9lxomIFXtgaeOHNwNbYpcaTZtM1\n",
       "YK+/vOr6zj9c38kVVj0Wr+HzDWw9t0fIHUAvY3tyW40bN46mJrkdT4hc5F+HqHiBF7Zilxqfgr3m\n",
       "8mtgi6zTGoDDgMNc35kKXAw8UYxVXuMbTA/E9ny27+LUZ4DzgTuNMRHAjBkzevrrhahp0hMSVSPu\n",
       "GU0GRmMnMLya49T9gcewi+t9Nx7W67a4mvWh2J7NbeQOoEeAvYGdjTFT2wNICLF60hMSVSfuGf0z\n",
       "7hkdBPwG2DLh1K8CtwDG9Z1Lgb8HXrhwdc+vte4FTAR+AXRVueEe4HxjzPRu/icIIWLSExJVK/DC\n",
       "tsALb8H2jA4Gns9xqgb+CMxxfec813fWSTxJ62at9THALOAqcgfQbcAYY8y+EkBC9IyEkKh6cRhN\n",
       "wa5lNA5bdTrJEOx06ndd37nK9Z0tALTWjVrrw7DDe1cBGyY8tn1K+NbGmO8YY3IFnhCiG2Q4TtSM\n",
       "eBLCo8Cjru9sCfwUOBzolXVqL+CYKIqOOeDo3WY0NjcMbV3epnM87XJsNesLjTEVW6lBiGolISRq\n",
       "UuCFrwLHuL5zJvBj4ERsT4goivj4nQW88dSHtHy8eEyOp1gG/BW42BiTtEqsEKIIJIRETQu88EPg\n",
       "V67v/BY46uN3P//lm898tM789xclnq8UDF6n75ONzQ0/fO7Rmanc/CpEPZMQEnVh6h9e2go4AEic\n",
       "lACw/hZD2HTHtek3uPcu2OndVwFX1vIie0KUm4SQqGla622Ac+mittvwUYPYbKd1GDC0T+buwcCp\n",
       "wM9d37kHuBy4N54eLoQoEpkdJ2qS1npzrfVk4EVyB9DdwA5jvjliywFD+1yNvQ6UTQH7AncCs1zf\n",
       "Oc31nTVL0mgh6pD0hERN0VprbFmfieT+I+th4ExjzJMZ+451fecs4CTgR8CXkp4e+B0wyfWdW4A/\n",
       "A88WozSQEPVKekKiJmit19VaXw68ARxJ8nv7GWCCMWavrAAC7CSGwAvPAjYAjgZeyPHremOnfj8N\n",
       "zHB952jXd/oW4T9DiLojISSqmtZ6gNb6XGA2dhp2c8JpL2GH5HY2xjy0uucMvHBR4IXXAGOAHbH3\n",
       "CS3Ncfr2wNXA/1zfudT1nVwrwwohEsh6QnWi1tZX0Vo3YXsrk4BhOU57HTs0d6sxpq0nvy++DnQU\n",
       "Nuhy3dja7gHsUN1dE8eeuRxq53WvFrX2fq8Wqa8npJTqpZR6Ryn1o/jnCUqpx5VSjyml9urJcwuR\n",
       "JF7T55vYytZXkhxA72CH5EYbY6b0NIAAAi/8JPDCi4GR2IkKdwG5/oLbGwiBt1+e8wSLl8liqkLk\n",
       "0qOekFLKBfYAHgKuAJ4AxmNnFN0XRdHu2Y+RnlB51MJfhlrr7YHfA3vmOOVj4Gzgb8aYpJluReX6\n",
       "jgaOB44BhuY6r0E10Ba13QZcA9wXeOGKUret3tXC+70apdoTUkqtAewD3B7vGgW8EUXRkiiKFgOz\n",
       "lVIjC31+IdpprTfUWl+PrZKdFECLsfcCjTTGXJFGAAEEXmgCL/wFsD52Nt7TSee1RW0A38ZO837P\n",
       "9Z3flXIFWCGqScE9IaXU6dgLvmsD/YB/Y8vpR9ieEMDkKIqeyXyc9ITKoxr/MtRaD8Ku6XMKdkZa\n",
       "tgi4FjjLGPO/FJuWk+s722OneB8KrLGa05/C9o5uCbzw81K3rZ5U4/u9FhTy+V5QCCmlBgI3RVG0\n",
       "n1LqCKA/9mLsGdgLtwo7PHdeFEWrVB7ObOSsWbO6/btF7VuxYgUPPvggt9xyCwsWLEg8Z/To0Uyc\n",
       "OJERI0ak27g8LV2xmLc+fpk3P3iez5d82uW5TQ3NbDh0c0auvQ1rD9wIpeRzU1SnUaNGrfw+3xAq\n",
       "9GbVXYHeSqmbgI2BRuBx7JAc2BAamR1AQnQliiJmzJjBDTfcwAcffJB4zgYbbMDhhx/OtttuW9Ef\n",
       "1r2b1mDLdXdki+FfZe6C/zL7o5d455NXWdHWeaRwRdty3p47k7fnzqR/78GMXHsbNh72Zfr3HlSG\n",
       "lguRrh5P0VZKTQT6R1F0uVJqH+yU2AiYFEXRA9nny3BceVT68ITW+ivYSQedJrPEPgTOBK41xlRN\n",
       "/bbM1931nX7Y5ciPwk7o6UoEPAj8HQgDL1xc0obWmEp/v9eq1IbjekJCqDwq9R+l1noEcAFwSI5T\n",
       "FgEXAZcYY6purnOu1931nU2w08iPwFZo6EoLcBM2kGZImaDVq9T3e61L/T4hIQoVVzq4EFtmJymA\n",
       "2rCVCEYaY86pxgDqSuCFb8UlgjR2lulkcldlGIS91vosMNP1nV/G08OFqHpSwFSkSmutsDPHLgLW\n",
       "zXHaPcBpxphXUmtYmcRLQzwAPOD6zhBsIB+FLRmUZCvgfOB813eeBm7Gzq77MI32ClFsEkIiNVrr\n",
       "bYE/Yie2JHkJONUY0+laYj0IvHA+dt2iy13fGY0Nox8Aa+V4yE7xdpnrO9OwgXRb4IWfpdFeIYpB\n",
       "QkiUnNZ6KPZm0uNJHgJ+H/gVcEM1TToopcALZwI/dX3nF9gyQT+MvzYmnN4ATIi3K1zfuRsbSHcG\n",
       "Xpi8jrkQFUJCSJSM1roROBY7fJS0Ps8y4BLgglq75lMsgRcuw9ahC13fWQv4LnbILldvshfgxNsX\n",
       "ru+E2EkNDwZeuDyFJgvRLRJCoiS01mOxQ2/b5TjlLuAUY4zcsZynwAvn0jFctxHwPWwgbZvjIf2x\n",
       "w3k/AOa5vjMFG0jTAy/scVFXIYpBQkgUldZ6OHbSwQ9ynPIW8BNjzJ3ptar2BF74LvZ1vsj1nS2w\n",
       "YXQItsp3kqHACfE2x/Wdf2Jn5L0gU75FOcl9QnWi1PdNaK17AR72ZuX+CacsAs4DLjXG5JqKXHPS\n",
       "vF/F9R2FnVV3CPB9YHgeD3sXuC3enopn61U9uU+oPAr5fJeekOgxrfXXAB/YLMcpk7Gz3v6bXqvq\n",
       "T9yjeQ54zvWdU7HVJw7BVmkYkuNhG2ELxJ4CfBRfQ7oNeFiuIYk0SAiJgmmtNwYuAw7IccpM4MfG\n",
       "mEfTa5Wim4bjAAAVtUlEQVSAlfcfPQw87PrOycDXsIF0INA3x8PWxs5gPB74zPWdqcCtwP1SNkiU\n",
       "ioSQ6DatdV9sxfRTSV5i4TPgLOBKY4ws4FZm8Qy7qcDUuH7dAdhJDV8D+uR42GDg8HhbFE/7vg24\n",
       "S5adEMUkISTyFlc7cLBDb0n1ziJsqZ1fGWPmptk2kZ/ACxdi7yG6OQ6kr2MX3NsfGJDjYX2xQ3oH\n",
       "Actc33kQG0h3xDP2hCiYhJDIi9Z6I+yU6/1znPI0duhtRnqtEj0RB9KtwK2u7/QGxmMD6UBgzRwP\n",
       "64W9aXZfoM31ncewgXR74IXvlb7VotZICIkuaa2bsLPeJpF8LeEj4DTgH8YYufekSgVeuBS4G7jb\n",
       "9Z0TsDfDfjve1svxsAZgXLwFru/MxC5hfhfwdK3MtBOlJSEkctJa7wj8Bdgm4fAK7LDcJGOMXCOo\n",
       "IYEXrgAeAR5xfecn2Gnf38EGUq77kABGx9sZ2Jtj78WG0n1xXTwhOpEQEp1orQdh1/hpX6o925PA\n",
       "CcaYmak2TKQurqzwLPBsXMduazp6SF/u4qFDgcPirdX1nel09JJekxtkRTsJIbFSPPHgu9gezjoJ\n",
       "p3wGnA5cLUNv9ScOjpnxdo7rOyPpmNSwC7nXJ2vE3rO0O7bKg3F95y5sKD0aeOGSUrddVC4JIQGA\n",
       "1lpj65J9PccpNwI/M8Z8lF6rRCULvHA2HaWDhmKnfO8HfAM7xTsXDZwcbwvj2XZ3AncHXvh+aVst\n",
       "Ko2EUJ3TWjcDP8OW21kj4ZTZwI/qdY0fkZ/AC+dhi6Pe5PpOE7AzNpC+iV2IL5d+2Nl4BwK4vvNv\n",
       "4F7gfmwZobop8VSvJITqmNZ6F+zEg60TDi8HfoddZkHulhd5iyc2PB5vp7u+MwIbRvsBe5J8g3O7\n",
       "7eLtDOxNso9gV569H7mWVJMkhOqQ1noIcCFwXI5THsNOPHgtvVaJWhV44TvAn4E/xzfIjqcjlHIt\n",
       "8Q72loD2e5IA3nd9535sKD0YeOHHJWu0SI2EUB2Jogit9aHYem/DEk6Zhy3Fc60xRv7iFEUX3yB7\n",
       "B3BHXPV7G2wY7Qd8leTZmO3WBY6MN1zfeRHbQ3oAeEImOFQnWcqhTkydOjW66qqrmDkz56zqa7GV\n",
       "rj9Jr1W1T5YUyJ/rO8OwS5TvDexD172kbEuAR4mH7g7f5VcvK6XkdU9ZIZ/vEkI1rn3iQXNz82+X\n",
       "L0+szP8GdujtkVQbVickhAoT95K2pCOQ9iB39e9O1mjuz/DBI3h77itHY2+8NXI9qfQkhMQqtNbb\n",
       "AteQvMT2UuwNqb+rp0Xm0iYhVBxxbbtd6Ail7el66C7bHOIqENglLt6RUCo+CSEBgNa6D3Am9sbS\n",
       "pOt+04ATjTFvptqwOiQhVBqu76yJneCwDzaYkqq6d+U9OkLpESSUikJCSLRPu/4bsHn2sQEDBrBg\n",
       "wYKJ2GKj8g8uBRJCpRcP3W1GRy9pHMlLzHdllVAKvNAUr4X1Q0Kojmmt+wPnAz8mYZhi7NixHHXU\n",
       "UYwfP15e8xRJCKXP9Z1eX9v68KUftrzLS3Meexg7jNfVvUlJ3mXVUHqnqI2sURJCdUprPQG4ChiR\n",
       "cPh94MQpU6bcDvJhmDYJofLIfN1d3+mDnf49Lt4KCaU5wPR4ewKYKUtVdCYhVGe01oOBS4Af5jjl\n",
       "auy068/kw7A85HUvj65e9ziUdqQjlHam+6G0ALuQY3swPRN44YLCW1wbCvl8l5tVq5TW+kDgCmB4\n",
       "wmEDHGuMeSjdVglR+eKbWh+Nt3MKDKUB2GtQe8c/t7m+8xIdoTQ98MI5RW98DZIQqjJa62HYZbYP\n",
       "TjgcYZdhONMYszDVhglRpYoUSg101L07GcD1ncwhvOnAyzKE15mEUJWI1/o5FBsyQxNOeQ042hjz\n",
       "VKoNE6LGJIRSb2AHYGzGtmYeT7UB8P14A1jg+s7TwFPECwUGXji3yM2vOhJCVUBrvQF26O2bCYdX\n",
       "YIuRnic3nQpRfPFyEk/G28XxlPBRwK50hNJmeTxV9hAeru8Y4BniUAJeCLywrqrWSwhVMK11A7bS\n",
       "9UXYN3C2F4AfGmNeSrVhQtSx+KbWN+PtGlh58+wudITSGPKb7KDjrb23tML1nZl0BNMzwOvxMus1\n",
       "SUKoQmmtN8bedDou4fBS4DfAJcaYFWm2SwjRWeCFnxBXB4eVZYYKGcJrouPa0gnxvgWu78wgI5hq\n",
       "aQVaCaEKE/d+TsT2fpIKNj4BHGOMeSPVhgkh8tbFEN7O2EkPX8UuY5HPZ/AA7GKAe7bvcH3nf9hQ\n",
       "eh47IvJCta6vVFAIKaWuxI6BKuCoKIqMUmo8cDZ2htbZURRNK1or64TWWmO79+MSDi/E1oK7whhT\n",
       "s11zIWpR1hDedbDyfqXtsIHUHkyb5PmU6wHfjjfi5/svcSBlbO9Xek28gkIoiqITAJRSewKnKqVO\n",
       "AiZhCwoq4D5skUyRh7j3czxwMdAv4ZT7geOMMe+m2jAhRMnEs/Ceijdg5bWlr9ARSl8leTZskvXj\n",
       "7YCMfR+5vpMdTO9WUjD1dDhuAbAM2818I4qiJQBKqdlKqZFRFM3uaQNrndZ6I+y1n/EJhxcAPwX+\n",
       "JgVHhah98bWle+KtvTjrxqzaW9qe/Cs8rA18I97azY+DaeVQHvBWuSY/9Khsj1LqCux9K0OwN09G\n",
       "dBTPnBxF0TPZj8ks6zBr1qyCf3e1i6KIhx56iOuvv57FizvPyBw9ejQnnngia621VhlaJ4SoVK1t\n",
       "rXy26GM+WfA+ny78kE+/+JD5iz6mLSr8Ptjmxl4M7juMIf3WZkjfYQzpN4whfYfR3NS9akajRo1a\n",
       "+X3Jy/YopfbD9n5eV0ptCgzGXlBX2Hta5hX63LXuk08+4corr+SllzrPrO7Tpw8TJ05kwoQJKCXl\n",
       "xoQQq2psaGRo/+EM7d9Rsau1rZWWRXOZF4fSpwvt1tqW3+TZ5a3LmLvgv8xd8N9V9vfvM5ghfde2\n",
       "oRQH1IA+Q4r62VRQT0gptQNwSBRFP49/bgAew64P3wDcH0XRrkmPrecCpnHVgx8ClwIDE06Zhq16\n",
       "8E6xf7cU0iwPed3LQ153cH2nCTuBbPuMbTuS7znsjoXATODleHsJW1W8Jc0CplOAOUqph4GXoyjy\n",
       "lFKTgAexQ3LnFPi8NUtrvT52uYWvJxxeCJwK/EVmvgkhiiHwwhXAf+LtBgDXdxqwM/B2YNVwGtKN\n",
       "p+4H7BRvK7m+8+65R17X7XYWOjtu44R992NncYkMce/nCOAPwKCEUx7BVj2QlRyFECUVTz6YFW+T\n",
       "YeXkhw2AL2ds2wCbYke28rVRIW2Sm1VLSGu9LvBXkmu+LcLe93O59H6EEOUST9d+L97ubN/v+s4a\n",
       "wJZ0hFL71y8V8/dLCJVA3Pv5ARBgJ2xkexw4yhjzVqoNE0KIPMWFVJ+PN2Blr2ldOveaNgcaC/k9\n",
       "EkJFprUeDvwF2D/h8GLgF8CfpPcjhKg2ca/pf/F2T/v+uFbeFsC/u/ucEkJFEvd+vg/8ieTu6hPY\n",
       "3o/cwCuEqClxrbwXW1pauv3Y7lx0EjnEq51OAW6icwAtAU4BxkkACSHEqqQn1ENa64OwN+cmlWl/\n",
       "Etv7eTPdVgkhRHWQECqQ1noodujt+wmHlwJnApcZY2RNeSGEyEFCqABa6wOwU6/XTjj8HHCEMea1\n",
       "dFslhBDVR0KoG7TWQ7AFWw9POLwcu9rpxbLaqRBC5EdCKE9a628AV2PnyGf7N7b3MzPdVgkhRHWT\n",
       "EFoNrfVAbMHRoxMOrwDOAy4wxixPtWFCCFEDJIS6oLWegF1ue4OEwzOBI40xL6TbKiGEqB0SQgm0\n",
       "1v2Bi7DrI2VrAy4EJhljlqbaMCGEqDESQlm01nsAfwd0wuHXsdd+nk23VUIIUZskhGJa677ABYCX\n",
       "cDgCLgHOMsYsSbVhBWoYGynsOvS9gd5Tz26mtU3RMDbaAHstqzXra/v3rW3TVeFrvgshRDdICAFa\n",
       "612Aa4FRCYdnYa/9PFnKNjSMjfoDw4F1sr4OxQZJHzpCJfP7XMd6ZT7//md/uf3b9/JoSxtdB9UK\n",
       "7A25i7AL8i3K2Bbm8X32zwuAz9umK5ncIUSdqesQ0lr3w/Z+fgwkLUUbAGcYYxYV8vwNY6NGbDmf\n",
       "pHDJ/tqvkN9RIg1khVgqv3RstBj4PN5aMr7vzs8tbdOVVKkQokrUbQhprcdjl9tOuvZjsDXfHs3n\n",
       "ueJezLbYJXN3ALbCBsswClxjo06tEW9JlSjy1jA2WgDMBz6Lt+58/4UMRwqRnroLIa31IOD3wDE5\n",
       "TrkCOM0Y80XSwYax0QBgOzoCZwdgM5J7UuW2DDtstnTY4GVrNqiID+f3/h82GJsyvmZ+XwuV1QfE\n",
       "24YFPLa1YWzUgg2lzO3TPH6WABOim+oqhLTW+wNXklz1wADHGGOmte9oGBsNpHPgbEppAmcZ8CHw\n",
       "QdbXj7GL4S3FLguxNM/vl7VNVysXzpsxY2YEMGbMmPW7akQ8oaGR5IDK3NcbO4TYN2Prl8f3SccG\n",
       "AAOpjABsxC7HUcgSxisaxkbtvar5wKf7bK8Z2HcF/+dF59I5wFZ+bZuuFhel9UJUmboIIa31mtia\n",
       "b4cmHI6A4NOBZ1y4oP+xmzeMjX5GR+CMoueBM5/kcMn+Or8S/oqO29A+CSG1+6Di8OuHDaOBwKCM\n",
       "73Pty/55cPy1XJqw1wBXLutx/wsrs+zMrh7YMDZaSnJA5dq3cmubrpYV8z9CiDTVdAjFq50eDPwR\n",
       "WCv7eETDm/MHnnnrgv5H7gS8T88C50061mN/AXgb+KhtuqqKKd3lFoffF/H2fqHPE08GaQ+kwcCQ\n",
       "bn7ft+D/iJ7pjZ2ksk53H9gwNlpEQjjls7VNV3LDtSirmg0hrfW6wOXAgdnHIlTbwjUOmjVv8Dkj\n",
       "UH3O6OZTR6waOM8D/26brj7vYZNFEcQz49o/ZLutYWzUG9vDGpKxfSnPn9foYfML1T60uV53H9gw\n",
       "NlpCx6SMpIkaXe37XGYiip6quRCKez9HYYuODso+vqxp89ZPhlzcuLx5q83yeLoIWyWhvXfTHjgL\n",
       "ithkUUHinsHH8dYtcYCtElK/OcxMXbCoiUv/tcE5Wccyg+xLQHNx/gu6rQ92JufwAh4bNYyNPqcj\n",
       "pFoSvu9qX4sMJYqaCiGt9QjsYnN7Zx+L6MVnA37M5/2Pa0Tl/Pf+OnZRuvYezott01XiLDkhssUB\n",
       "9mG8ATBjxqcA/P7nG56d63Hx9bC+dA6mpLAakrCVa0KHwv6hNwjYqJAniO8Nyw6o9u3zPL5vkSHF\n",
       "6lYTIaS1bgB+hC0s2ummz6XN2zFv8IUsb04qiMDbwI3AjW3T1RslbagQCeLrYQvjbU53HhsH2ACS\n",
       "w6mr7UvYa2Dlvo+t/d6wQnpiADSMjZaRFVB7jN6Yfn3auNuL/hjvW8CqNzcn/by4EiYH1ZuqDyGt\n",
       "9aYRTdcpVuyUfaxN9eGzAT9nQb8jQK3yb+0T4J/Y8Hla3niiWsXv3fYP0ne789iMGYmZkzOSJmzk\n",
       "msRRzpmImXphJx6tnHz06Mwh7d+e3I3naY2HF7NDakEe2xfZP8v1svxUbQgNGX1Z797LX7iqD02H\n",
       "KVZ0Go5Y0mtn5g2+gBVNK0cJFgEhNngekDplot5lzUj8b3cf3zA2asIG0RDskNzghK9J+zKPVcK9\n",
       "Ye0a6egp9lg8azFXUH2RtS1M2NfpnMx7/2pFVYbQ0K1/c3K/JY9f3Nxq+mQfa1P9mT/wDL7o+31Q\n",
       "qhV4APgHcLtc3xGieNqmqxXYe5c+LeTxWT2xzGDKvAdsUML32T9X6udY+6zFHpWhyhQHW2Zw5dpW\n",
       "dzx7W1SuEaFK/Z+X6EujL9qu17IXbxu47KkRSccX9d6TTwefR2vj8GewPZ5/tk1X3Z7lJIQovZ72\n",
       "xGBlkPUhK5wuPOqtBxYuaeTcm0d4rHpD8wA63wTdvq93j/6D0tEebMOK/cRxwOVT9T7nz/Pv7v7v\n",
       "rYoQGjL60n7Nre9MHrDkof0aos4FrVvVYD4beNqHX/Q9+EpUw01t09WsMjRTCJGyOMgWx1vGrMTP\n",
       "ADjnZB3k+1zxFPv2uoNJQdW+9c/6OWlf/x79h5VHe8ClquJDaOhWvz6939JHJjW3zklcWmBx713N\n",
       "F30PPXHRGl+/XyYYCCEKFU/1XoqduNQjDWOjBuxQY1Jgte/v7lZJy70UTcWG0JdGX7hL72X/vmXg\n",
       "smcT7wJf3rTJksW9d/vpvFd+c0XabRNCiK7EEwjaJyF8UIznjIOtL52Dqastn3P6YYc0y6LiQmjI\n",
       "6EsHNa9469YBS6aNb6Bz2bU2NSBa1GfvW1Y0rn/4/JmnyAw3IURdiIOt/RpaUcU1F9cg/8r3uY51\n",
       "KpO2OhUVQmtu9atJ/Zc+ckZT6/ud2hWhWNJ799eXNW/1rU9nnvp6OdonhBC1KL6nqccB19JCty+J\n",
       "VEQIfWn0b/fqvXTGzQOWv5A442NZ02YLl/Qee9K8V866Lu22CSGEKJ2ih5BSajxwNrb459lRFE3L\n",
       "de6Q0Zes1bxi9m0Dlzy0q6LzyFqrGhwt7jPh2hWN6x47f+YpcvexEELUmKKGkFJKAZOA8djihvcB\n",
       "OUOo/6IpHzS1fdSpdlVEA4t7j3tpefMWzqczf/5OMdsohBCichS7JzQKeCOKoiUASqnZSqmRURTN\n",
       "TvzlCQG0tHmrlqW9djp23itnTily24QQQlSYYofQUKBFKXUptifUEu9LDKFMrQ1rti3qM/6K1oa1\n",
       "fzx/5ilyv48QQtQBFUXF+7xXSm0KnAGciA2hK4DzMntCLS0tEjBCCFHjBg0apPI5r9gVbGdjh+TA\n",
       "hlDOoTghhBCiqMNxURS1KaXOAR7Ezo47p5jPL4QQorYUdThOCCGE6I5KWlBKCCFEnZEQEkIIUTYS\n",
       "QkIIIcom9RBSSo1XSj2ulHpMKbVX2r+/Himl/q6UekopNU0pNbHc7allSqldlVLPKqUuytgn7/kS\n",
       "y/G6y/u+xJRSVyqlHlZKPaKU0vG+br3fUy1g2t2yPqJoIuDgKIrmlLshdaA3cAGwC8h7PkWrvO4x\n",
       "ed+XWBRFJwAopfYETlVKnUQ33+9p94RWlvWJomgxMFspNTLlNtQjhQy9piKKooeA+Rm75D2fgoTX\n",
       "HeR9n6YFwDIKeL+nvZRDwWV9RI8sAG5SSs0DTomi6K1yN6iOyHu+fOR9n56jAZ8C3u9ph9A8YDCr\n",
       "lvWZl3Ib6k4URS6AUmpb4PfAt8rboroi7/kykfd9OpRS+2F7P6/Hpdu69X5Pu6sqZX3KawkkLNwk\n",
       "SqG9bpa859OVVK9M3vclopTaARgXRdEf4l3dfr+n2hOSsj7loZSaDAzHDk+cVObm1DSl1OnAN4C1\n",
       "lVIDoyg6Xik1CXnPl1SO113e96U3BZijlHoYeDmKIq+773cp2yOEEKJsZOaIEEKIspEQEkIIUTYS\n",
       "QkIIIcpGQkgIIUTZSAgJIYQoGwkhIYQQZSMhJIQQomwkhIQQQpTN/wMat40ugXR4twAAAABJRU5E\n",
       "rkJggg==\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1039765f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pylab as pl\n",
    "\n",
    "pl.plot(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Markov assumption greatly simplifies the sequential decision analysis problem. If we had to model the process generally, we would be specifying:\n",
    "\n",
    "$$Pr(r_{t+1}, s_{t+1} | r_t, s_t, a_t, r_{t-1}, s_{t-1}, a_{t-1}, \\ldots, r_0, s_0, a_0)$$\n",
    "\n",
    "If we are able to assume conditional independence, then we can drop much of this, so the model becomes:\n",
    "\n",
    "$$Pr(r_{t+1}, s_{t+1} | r_t, s_t, a_t)$$\n",
    "\n",
    "By iterating this equation, one can predict all future states and expected rewards from knowledge only of the current state just as well as if one had the complete history up to the current time.\n",
    "\n",
    "## Markov Decision Process\n",
    "\n",
    "A Markov process where the transition probabilities can be influence by the actions of a decision-maker is called a Markov decision process.\n",
    "\n",
    "A Markov decision process (MDP) is defined by the available states and alternative actions, as described above, as well as by the state dynamics inherent to the environment.\n",
    "\n",
    "Given any state and action, $x$ and $a$, the probability of each possible next state, $x^{\\prime}$, is described by the **state dynamics function**:\n",
    "\n",
    "$$f(x^{\\prime} | x, a) = Pr(X_{t+1}=x^{\\prime} | X_t=x, A_t=a)$$\n",
    "\n",
    "These probabilities correspond to the elements in the transmission matrix, as described in the Markov chain discussion.\n",
    "\n",
    "For any current state and action, $x$ and $a$, together with any next state, $x^{\\prime}$, the expected value of the next reward is:\n",
    "\n",
    "$$r(x, a, x^{\\prime}) = E[R_{t+1} | X_t=x, A_t=a, X_{t+1}=x^{\\prime}]$$\n",
    "\n",
    "\n",
    "\n",
    "![MDP](http://fonnesbeck-dropshare.s3.amazonaws.com/MDP_flow.png)\n",
    "\n",
    "\n",
    "In some real-world problems, the actual system state is not entirely known by the decision maker, rendering the states only partially observable. Such MDPs are known as **partially-observable Markov decision processes** (POMDP).\n",
    "\n",
    "The sequence of the decision rules to be used at each decision point can be summarized as a **policy**, which is a function that maps states to actions:\n",
    "\n",
    "$$\\pi_t : X_t \\mapsto A_t$$\n",
    "\n",
    "If the policy is stationary, then that $\\pi_t = \\pi$ (*i.e.* the policy does not change over time)\n",
    "\n",
    "We can denote the influence of a policy on the Markov transitions by:\n",
    "\n",
    "$$p_{\\pi}(X_{t+1} = j | X_t = i)$$\n",
    "\n",
    "Which implies that the state-specific decision at each step is taken from $\\pi$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value functions\n",
    "\n",
    "We can compare competing MDP policies by evaluating their performance in terms of value. A **value function** is a function of the system state that is an estimate of how good it is to be in that state. This value is in terms of *expected future rewards*. Since the expected future rewards, as shown above, are a function of the state-specific actions taken at each decision step, we can use the value function to discriminate among different policies that may be used to selection actions.\n",
    "\n",
    "The value of state $x$ under policy $\\pi$ is the total expected (discounted) system reward for starting in state $x$, and following policy $\\pi$ thereafter.\n",
    "\n",
    "$$V_{\\pi}(x) = E_{\\pi}[R | X_t=x] = E_{\\pi} \\left[ \\sum_{k=0}^{\\infty} \\gamma^k r_{t+k+1} \\big| X_t=x \\right]$$\n",
    "\n",
    "this is the state-value function for policy $\\pi$.\n",
    "\n",
    "Note that in some applications, the value function is in terms of state-action pairs, thereby describing how good it is to perform a particular action from a particular state, following policy $\\pi$ thereafter.\n",
    "\n",
    "$$Q_{\\pi}(x, a) = E_{\\pi}[R | X_t=x, A_t=a] = E_{\\pi} \\left[ \\sum_{k=0}^{\\infty} \\gamma^k r_{t+k+1} \\big| X_t=x, A_t=a \\right]$$\n",
    "\n",
    "Note that the value function can be written recursively:\n",
    "\n",
    "$$\\begin{aligned}V_{\\pi}(x) &= E_{\\pi}[R | X_t=x] \\\\\n",
    "&= E_{\\pi} \\left[ \\sum_{k=0}^{\\infty} \\gamma^k R_{t+k+1} \\big| X_t=x \\right] \\\\\n",
    "&= E_{\\pi} \\left[ R_{t+1} + \\gamma \\sum_{k=0}^{\\infty} \\gamma^k R_{t+k+2} \\big| X_t=x \\right] \\\\\n",
    "&= \\sum_{x^{\\prime}} f(x^{\\prime} | x, a) \\left[ r(x, a, x^{\\prime}) + \\gamma E_{\\pi} \\left[ \\sum_{k=0}^{\\infty} \\gamma^k R_{t+k+2} \\big| X_t=x \\right] \\right] \\\\\n",
    "&= \\sum_{x^{\\prime}} f(x^{\\prime} | x, a) \\big[ r(x, a, x^{\\prime}) + \\gamma  \\color{red}{V_{\\pi}(x^{\\prime})} \\big]\n",
    "\\end{aligned}$$\n",
    "\n",
    "This expression is the **Bellman equation** for $V_{\\pi}$. The Bellman equation averages over all the candidate next states $x^{\\prime} \\in X$, weighting each by its probability of occurring as specified by the state dynamics function. \n",
    "\n",
    "It states that the value of the start state must equal the (discounted) value of the expected next state, plus the reward expected along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing MDPs\n",
    "\n",
    "In order to solve our decision analysis problem, we have to identify a policy that maximizes the long-run expected rewards. We now have a way to achieve this: *optimize Bellman's equation*.\n",
    "\n",
    "An optimal policy $\\pi^*$ maximizes $V_{\\pi}(x)$ for all $x \\in X$. The value function under this policy is the optimal value function:\n",
    "\n",
    "$$V^*(x) = \\max_{\\pi}V_{\\pi^*}(x)$$\n",
    "\n",
    "Bellman's equation allows us to approach the optimization problem into smaller, recursive sub-problems. In fact, Bellman's **Principle of Optimality** states this explicitly:\n",
    "\n",
    "> An optimal policy has the property that whatever the intial state and initial decision are, the remaining decisions must constitute an optimal policy with regard to the state resulting from the first decision.\n",
    "\n",
    "The Bellman's optimality equation expresses the fact that the value of a state under an optimal policy must equal the expected return for the best action:\n",
    "\n",
    "$$V^*(x) = \\max_{a \\in A(s)} \\sum_{x^{\\prime}} f(x^{\\prime} | x, a) \\big[ r(x, a, x^{\\prime}) + \\gamma  V_{\\pi}(x^{\\prime}) \\big]$$\n",
    "\n",
    "By means of $V^*(x)$, the optimal expected long-term return is turned into a quantity that is locally and immediately available for each state.\n",
    "\n",
    "The business of optimizing MDPs is therefore a matter of calculating or estimating $V^*(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Programming\n",
    "\n",
    "Dynamic programming is an approach to computing optimal policies for MDPs, provided that an appropriate state dynamics model is available. These methods use value functions to organize and structure the search for good policies. Specifically, they turn Bellman's equations into assignments, using them to update approximations to the true value function.\n",
    "\n",
    "There are 2 fundamental DP algorithms to solve infinite-horizon discounted MDPs: \n",
    "\n",
    "1. value iteration \n",
    "2. policy iteration  \n",
    "\n",
    "Value iteration starts with an arbitrary value for each state and, at each iteration, solves Bellman's equation using the value from the previous iteration until the difference between successive values becomes sufficiently small.\n",
    "\n",
    "It starts with an **arbitrary decision rule** and finds its value; if an improvement in the current decision rule is possible, using the current value function estimate, then the algorithm will find it; otherwise, the algorithm will stop, yielding the optimal decision rule.\n",
    "\n",
    "In many situations, the stationary assumption is not reasonable, such as when the transition probability represents the probability of a disease outcome that is increasing over time or when age-dependent mortality is involved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy Iteration\n",
    "\n",
    "The expected value expression of $V^*(x)$ is a system of equations, whose solution is straightforward, though requiring extensive computation. Instead, an iterative approach can be adopted.\n",
    "\n",
    "An initial approximation (guess) $V_0$ is chosen, and the Bellman optimality equation is used to updte $V_0$:\n",
    "\n",
    "$$V_{k+1}(x) = \\sum_a \\pi(a|x) \\sum_{x^{\\prime}} f(x^{\\prime} | x, a) \\big[ r(x, a, x^{\\prime}) + \\gamma  V_{k}(x^{\\prime}) \\big]$$\n",
    "\n",
    "where $\\pi(a|x)$ is the probability of selecting action $a$ under policy $\\pi$ in state $x$. This algorithm is called iterative policy evaluation, and the sequence $\\{V_k\\}$ can be shown in general to converge to $V_{\\pi}$ as $k \\rightarrow \\infty$.\n",
    "\n",
    "To produce each successive approximation, $V_{k+1}$ from $V_k$, iterative policy evaluation applies the same operation to each state: it replaces the old value of $x$ with a new value obtained from the old values of the successor states of $x$, and the expected immediate rewards, along all the one-step transitions possible under the policy being evaluated. This operation is called a **full backup**.\n",
    "\n",
    "All the backups done in DP algorithms are called full backups because they are based on *all possible next states* rather than on a sample next state. \n",
    "\n",
    "![policy evaluation](http://fonnesbeck-dropshare.s3.amazonaws.com/Screen-Shot-2015-03-17-08-47-04.png)\n",
    "\n",
    "This is known as **policy evaluation**. Each iteration involves a sweep through the state space, and terminates when the largest change is smaller than the stated tolerance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are able to evaluate the policy, we can attempt to **improve** it.\n",
    "\n",
    "Suppose we have determined the value function $V_{\\pi}$ for some deterministic policy $\\pi$ (not necessarily optimal!). For some state $x$, we might wonder whether we should deviate from $\\pi$ to deterministically choose an action $a \\ne \\pi(x)$. From policy evaluation, we know the value of following the current policy from $x$, but would it be better or worse to change to the new policy?\n",
    "\n",
    "The value of the new policy is:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "Q_{\\pi}(x, a) &= E_{\\pi}\\left[R_{t+1} + \\gamma V_{\\pi}(X_{t+1}) \\big| X_t=x, A_t=a \\right] \\\\\n",
    "&= \\sum_{x^{\\prime}} f(x^{\\prime} | x, a) \\big[ r(x, a, x^{\\prime}) + \\gamma  V_{\\pi}(x^{\\prime}) \\big]\n",
    "\\end{aligned}$$\n",
    "\n",
    "notice we are using the state-action pair formulation of the value function here. If we take the action that maximizes this, we should replace the action in $\\pi$ with the maximal action, to derive a new policy $\\pi^{\\prime}$.\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\pi^{\\prime}(x) &= \\text{argmax}_a Q_{\\pi} (x, a) \\\\\n",
    "&= \\text{argmax}_a E_{\\pi}\\left[R_{t+1} + \\gamma V_{\\pi}(X_{t+1}) \\big| X_t=x, A_t=a \\right] \\\\\n",
    "&= \\text{argmax}_a \\sum_{x^{\\prime}} f(x^{\\prime} | x, a) \\big[ r(x, a, x^{\\prime}) + \\gamma  V_{\\pi}(x^{\\prime}) \\big]\n",
    "\\end{aligned}$$\n",
    "\n",
    "The process of making a new policy that improves on an original policy, by making it greedy with respect to the value function of the original policy, is called **policy improvement**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a policy has been improved to yield a better policy, we can then compute $V_{\\pi^{\\prime}}$ and improve it again to yield an even better $\\pi^{\\prime\\prime}$. We can thus obtain a sequence of monotonically improving policies and value functions:\n",
    "\n",
    "$$\\pi_0 \\xrightarrow{evaluate} V_{\\pi_0} \\xrightarrow{improve} \\pi_1 \\xrightarrow{evaluate} V_{\\pi_1} \\xrightarrow{improve} \\dots \\xrightarrow{improve} \\pi^* \\xrightarrow{evaluate} V_{\\pi^*}$$ \n",
    "\n",
    "\n",
    "![policy iteration](http://fonnesbeck-dropshare.s3.amazonaws.com/Screen-Shot-2015-03-17-11-51-14.png)\n",
    "\n",
    "Note that each policy evaluation, itself an iterative computation over all the states, is started with the value function from the previous policy. This typically results in quicker convergence of policy evaluation, since there should generally be few changes to the value function from one policy to the next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Iteration\n",
    "\n",
    "A drawback of policy iteration is that the policy evaluation component can be computationally intensive, involving multiple sweeps through the state space. It turns out that it is usually not necessary to run the policy evaluation to convergence in order to obtain the optimial policy; in most cases, the policy will become stationary before the policy evaluation converges.\n",
    "\n",
    "The **value iteration** algorithm is a simplified operation that combines policy improvement and (truncated) policy evaluation into a single step.\n",
    "\n",
    "$$\\begin{aligned}\n",
    "V_{k+1}(x) &= \\max_a E\\left[R_{t+1} + \\gamma V_k(X_{t+1}) \\big| X_t=x, A_t=a \\right] \\\\\n",
    "&= \\max_a \\sum_{x^{\\prime}} f(x^{\\prime} | x, a) \\big[ r(x, a, x^{\\prime}) + \\gamma  V_k(x^{\\prime}) \\big]\n",
    "\\end{aligned}$$\n",
    "\n",
    "It can be shown that $V_k(x)$ converges to $v^∗(x)$ under the same conditions that guarantee the existence of $v^∗(x)$.\n",
    "\n",
    "Notice that value iteration backup is identical to the policy evaluation backup, except that it requires the maximum to be taken over all actions. In fact, it is just the Bellman optimality equation, turned into an update rule.\n",
    "\n",
    "![value iteration](http://fonnesbeck-dropshare.s3.amazonaws.com/Screen-Shot-2015-03-17-14-59-20.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Optimal taxi behavior\n",
    "\n",
    "Consider a simple, contrived example of a taxi driver attempting to maximize fares. The taxi serves two adjacent towns: A and B. Each time the taxi discharges a passenger, the driver must can choose from two possible actions:\n",
    "\n",
    "1. **Cruise** the streets looking for a passenger.\n",
    "2. Go to the nearest taxi **stand** (hotel, train station, etc.)\n",
    "\n",
    "Passengers picked up while cruising tend to stay in the same city, while those from the taxi stand have  higher probability of moving to the other city. \n",
    "\n",
    "City B pays higher fares, than city A.\n",
    "\n",
    "Cruising fares are higher than standing fares in city A, while the opposite is true in city B.\n",
    "\n",
    "*What is the optimal behavior in each state?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# States\n",
    "A, B = 0, 1\n",
    "CRUISE, STAND = 0, 1\n",
    "\n",
    "# State transitions\n",
    "T = {CRUISE: {\n",
    "    A: {A: 0.9, B: 0.1}, \n",
    "    B: {A: 0.1, B: 0.9}\n",
    "},\n",
    "    STAND: {\n",
    "    A: {A: 0.4, B: 0.6}, \n",
    "    B: {A: 0.6, B: 0.4}\n",
    "}}\n",
    "\n",
    "# Rewards\n",
    "R = {\n",
    "    CRUISE: {A: 8, B: 20}, \n",
    "    STAND: {A: 5, B: 22}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states = [A, B]\n",
    "actions = [CRUISE, STAND]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to intitialize the data structures for storing values, indexed by states and actions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "V = {}\n",
    "V2 = {}\n",
    "logs = {}\n",
    "\n",
    "for s in states:\n",
    "    logs[s] = {}\n",
    "    for a in actions:\n",
    "        logs[s][a] = []\n",
    "             \n",
    "for s in states:\n",
    "    V[s] = 0\n",
    "    V2[s] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model parameters, including tolerance for convergence and the desired discount rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convergence criterion\n",
    "epsilon = 0.0001\n",
    "# Discount rate\n",
    "gamma = 0.8\n",
    "# Maximum number of iterations\n",
    "max_iters = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 56\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(max_iters):\n",
    "    for s in states:\n",
    "        \n",
    "        value_candidates = []\n",
    "        for a in actions:\n",
    "            value = R[a][s] + gamma * sum(T[a][s][s2]*V[s2] for s2 in states)\n",
    "            value_candidates.append(value)\n",
    "            logs[s][a].append(value)\n",
    "            \n",
    "        # Choose the largest candidate value\n",
    "        V2[s] =max(value_candidates)\n",
    "        \n",
    "    # If there is no change from the last estimate, we are done\n",
    "    if max(abs(V2[s] - V[s]) for s in states) < epsilon:\n",
    "        break\n",
    "    else:\n",
    "        V, V2 = V2, {}\n",
    "        \n",
    "print(\"Iterations: %i\" % len(logs[A][STAND]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: A Action: CRUISE --> 67.473360\n",
      "State: A Action: STAND --> 72.368097\n",
      "State: B Action: CRUISE --> 92.104939\n",
      "State: B Action: STAND --> 86.210202\n"
     ]
    }
   ],
   "source": [
    "for s in states:\n",
    "    for a in actions:\n",
    "        value = R[a][s] + gamma * sum(T[a][s][s2]*V[s2] for s2 in states)\n",
    "        print(\"State: %s Action: %s --> %f\" % (['A', 'B'][s], ['CRUISE', 'STAND'][a], value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x104205f98>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAaEAAAEBCAYAAADRtBosAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl4VOXZ+PHvMxN2JCAoLiAcAUUWMRDWMSFBZBGQURTc\n",
       "wAVUQExUsNWfby340tpWoCZYrFqt2ldF1DLFWhQoEEKMyBK1uCDoAFaqZTMCYZGZ5/fHmRkmITOZ\n",
       "TCaz3p/rOtfMnPV5MiE355zn3LfSWiOEEELEgiXWDRBCCJG6JAgJIYSIGQlCQgghYkaCkBBCiJiR\n",
       "ICSEECJmJAgJIYSImaBBSCl1uVLqQ6XU7/zmXaGUKlZKrVNKDalpvhBCCBGICvackFLqCuAMYJDW\n",
       "+mdKKQWsB64AFPCe1jo70Px6b70QQoiEFvRMSGv9T+Cg36wuwDat9TGt9VFgh1Kqc5D5QgghREBp\n",
       "tVy/NVCulFqAecZT7plnCTB/RwTbKoQQIsnUNgjtB1oC0zCDzdOeeZYA809TXl4ueYKEECLJpaen\n",
       "q1DWCzUIeXe2A/PSm3deZ631DqWUpbr5oTZWCCFEagoahJRSPwdGAm2VUi201ncrpR4DVgEamAOg\n",
       "tXYrpeZUnS+EEEIEE3R0XH3wvxwX6ulasti0aZMGyMzMlH6nCOl76vU9VfsN4f19l4dVhRBCxIwE\n",
       "ISGEEDEjQUgIIUTMSBASQggRMxKEhBBCxIwEISGEEDEjQUgIIUTMSBASQggRMxKEhBBCxIwEISGE\n",
       "EDEjQUgIIUTMSBASQggRMxKEhBBCxExti9oJIcJgGIbC/E9f1UkFea36vrrPgSYCfCbIPP9Xqvlc\n",
       "q/ePP/44ANdff33fIPusKtCycDJS13abiGS9njt3LgDXX3/9oEjsL4JcTqdzQ6wbUZUEIZEwDMOw\n",
       "As08U1OgSTWvjYDG1bw2DDA1qDKl+b1WN1n9Xq2YQUFj/gE7rS5Kq1at8JRL+RZwV5l0kPe6yvtA\n",
       "86hmnUDLqGZ+1Xn+r6Euq/b9m2++iVIK4H84XbAaMoGWRbLuTL3t6+233/a+fSCCx4iECkCCkEhN\n",
       "LpcLwzDOAs6sZmoJtADSq7yeATTHDCQALuAw5j+mCuBolddjftNxv9cfPa8nqpl+qmY66Zl+8hzT\n",
       "+9nl99kFnHQ6ne5g/farLXNeLX9kCc+v72Nj3ZZo8uv3dbFuSyKQICTqxDCMZkA7z9QeOA9o6z+1\n",
       "bNkSi8UCsBo4AOz3vB4ADgL/BbYD5ZgBw/t6CDPonHA6ndGtviiEiAoJQiIowzAaAB2AzkAnv9cO\n",
       "wNmYZyD/9kzfAHuAr4DvvdMzzzyz32KxkJmZ2TP6PRBCxDMJQgLwBZuLgB5AT89rd8z7LLuAHZ5p\n",
       "I7AYcAL7arocBbBp06Z6arUQItFJEEpBnhv83YABnqkv0Ab4EtgK/AtYDmx1Op3lsWqnECL5SRBK\n",
       "AYZhNAWyPdMA4BLgC8yRMm8DjwJ75L6LECLaJAglIcMwLMBlwJXAMOBiYD2wBvNS2mdOp/Nk7Foo\n",
       "hBAmCUJJwjCMRphBZzyQi3lpbSXwIPBRKPduhBAi2iQIJTDPYIIrgAmYAWg98Dow1el0VsSybUII\n",
       "EQoJQgnIMIxewDRgFOZ9nSXADKfTeSSmDRNCiFqSIJQgPGc91wD3Yg6bfgp40Ol0Hoppw4QQog4k\n",
       "CMU5wzDaAncBdwDvY97j2SAj2URtuewZgRKYVvcev3lhvbc8uNB73DOC7LOqWCYwjch+rDOfBMBl\n",
       "zzgzQsePFG11lB2MdSOqkiAUpzzB5xFgDPBnYKDT6fwutq2KLy57RhrBE5j6vw+UwLRqEtPaJjD1\n",
       "nyxVX7uedR5ojWvff76g+iza/pmzvf+xqDYZapD5wVTdJhoJTAG4+E//6/3zvTmU9UNcFon1w90m\n",
       "JF1e+q33bXG0j12DQ8DAGB07IAlCccYwjHRgFjARKAQucTqdx2Lbqshx2TMsmAlKa5PAtDlm5uzm\n",
       "mMHG+wfbReUkpsc8r/7JS72vVROY/oT5j7KmBKYnCZzANNDk9r5un/Sz/wJcOv++fgTJom11lCXd\n",
       "me3npxJ5XhTrtkTTF6f63T3WbUkEEoTihGEYTYDpmPd8XgZ6JUq2Apc9wwqcQ4AEpl3adSat4kdc\n",
       "B/77HeYf3R+onMD0B8ykpeWY+ee2UjmB6WHgiOe1wuooS5jh5i5PyiKro+zHGDdFiLgkQSjGPMXO\n",
       "bgDmAu8A/Z1O5/exbVVlniDTntMTmLYHzse8fPUdpxKYepOXfgJ8v+vq26852ewMej2Rd24y/o9f\n",
       "CBE+CUIxZBjGucDTmJeZrnQ6nV/Hsj0ue0YjoCunEpj2ALpgXhr7BjOB6VfAZ5gB89/At1ZHWdDL\n",
       "hSdOnQ1IABJCVCJBKAY8Zz+3AP8L/Bp4Ltqj3Vz2jKZAb04lMO2JGWy+wExguhVYCnwZjyNqhBDJ\n",
       "QYJQlB04cABgGeaorGyn07k7Gsd12TM6ciqBaX/MWkCbgQ+AZ4FPrI6yvdFoixBCeEkQiqLi4mJe\n",
       "e+01MM8w/lyfZz8ue0YLzBxyw4ChmKPG1gBFwG+B3XJ5TAgRaxKEosBTv+fxLl268NhjjzFixIgX\n",
       "6uM4LntGZ8wEpldhltteC6wAHrM6yuJqsIMQQoAEoXpnGEYL4FVg/+zZs2nYsGFE9++5zDYeM4mp\n",
       "BTOP3N3AZ3KmI4SId2EHIaXU7cBUzAf6fqG1XqOUGgr8EvMhvNla69WRaWZiMgzjQsAB/AWY17Bh\n",
       "w0mR2K/LntEKmATciPkQ5xLgJqujbFsk9i+EENFSlzOh+zELpzUH3lVK2YA5mKUFFPAekLJByDCM\n",
       "HMx0O/c6nc6/A2zyDFUOl8uecSkwAxgOvAZMtjrKPq1bS4UQInbqEoQ+wbzhfTZmwOkCbNNaHwNQ\n",
       "Su1QSnXWWu+oezMTi2EYd2Km3hnjdDq31mVfLntGA8COGXyaY2bPzrc6yo7WuaFCCBFjSuvwbhso\n",
       "pe7GHPJrwfxf+V7MexOaU1lnF2utN/hvV15e7jvg9u3bwzp2PFu+fDnFxcU89NBDtGjRIuz9KNdJ\n",
       "WpcVc/YHK6g4z2Bv3yEcadcJVKQSAwshRGR16dLF9z49PT2kP1ZhnQkppToBQ7TWEzyf1wB5mIko\n",
       "p2EGoaeB/eHsP1GtWrWKNWvW8Mtf/pJmzZqFtxPtptXWDzmn+G0OX3Ax2yc+yE/p8ZYRXgghIiPc\n",
       "y3HeTMgopRpgBp8dmJfkwAxCNV6Ky8zMTJr/1huGcQtmrZ8rBg8evK+6dTadyq57Wr89tV6uAn4F\n",
       "bAd+0eyF975oW39Njppg/U520vfU63uq9hsqX+kKVVhBSGu9XSm1TilVihlwntRaH1VKPQaswrwk\n",
       "NyecfSciwzCuBx4GhjidzmoDUDAue0Ym8HvMB0qnWB1ldRvBIIQQCSLsgQla619j5j3zn7cC8+HI\n",
       "lGEYxljMHHBX1Db7tcue0RhzSLsduNfqKFtVD00UQoi4ZYl1AxKZYRjDgSeA4U6n89vabOuyZwwA\n",
       "NmFW/ewjAUgIkYokY0KYDMPoByzCDEC7Qt1O/XQClz3jCWAU5qW39+urjUIIEe8kCIXBMIw2wCvA\n",
       "DU6nM+TnoJr++ysu+PtL3o995FkfIUSqkyBUS55kpK8A851O58ZQt3PZM+7ocObZ7Lr6DrrZJzxY\n",
       "fy0UQojEIUGo9h7FLF39TCgre0pj/w7ov/3Wn3OyWfgPsAohRLKRIFQLhmFcBYwFBoVSC8hlz0gH\n",
       "FgP/Aa442axF0DLYQgiRamR0XIgMw+gI/AG43ul0VtS0vsue0QUowRyyPtnqKDten+0TQohEJGdC\n",
       "ITAMozHwBvCA0+msMeGdy54xBHgemG51lC2v7/YJIUSikiAUmgJgjdPpXFrTii57xijM7AdXWR1l\n",
       "n9d7y4QQIoFJEKqBYRg3AV0x6yQF5bJnDAWeBIZZHWXO+m6bEEIkOglCQRiG0RozNVG20+k8GWxd\n",
       "lz0jG3PE3EgJQEIIERoJQsH9BnjK6XTuDraSy54xEHgRGGN1lH0ZjYYJIUQykCAUgGEYNqAvMD3Y\n",
       "ei57Rm/gVeAaKbUtwmGxaYWZjV5hjli1VPlcdbn3PVWWqSDLqGZ+1Xn+r6EuC/h+yf9rBEA/m+5a\n",
       "pcvBShzUtvxBOOUS6rXEwms/b4wG+tl0z/o8Thjc7hIVd3+jJAhVwzCMBph54aY5nc6fAq3nsmf0\n",
       "BN4EJlgdZR9Fq32pzGLTFqCpZ2rimfzfNwIaV/PaMMjUAPPfQgO/94Emq99r1fcWv1cN0LrFpWgN\n",
       "Bw7p/3i64P98mfL7rAG3Z9LVTIHmB5sI8Jkg86q2sernULfhN0s6eP/aP111WQ3HCCTQOuGVh66n\n",
       "fT3paO99O7+u+wpBbdp7BLi2vhoSLglC1bsf2OB0OgMmF3XZMy4E/gZMsjrKPoxayxKYxaYbAWdW\n",
       "M7XELJLYwvPqfX8G0NwzNfbsxoVZd6nC8+r//pjn9bjnfdXXH4ETnuknv9eq00nP5P/+pOfYrirv\n",
       "q05ud4lye/u8adMn3gJn59btp5d4Nm360tv33Fi3JZo2bdru7fewWLclEUgQqsLzUOo0oE+gdVz2\n",
       "jCaYZ0D3Wx1l66PSsDhlsWkrcDbQHmgHnAe09Z/Oa92D4z9ZALYBBzDLvh/wTAeBHzCzSnyBGSjK\n",
       "Pa+HgMOe6bi7REXyf7xCiDggQciPYRgKWAg86nQ6DwRZ9SngPauj7G/RaVnseO5XnA10Ajp7pk5A\n",
       "B8yg0xAzl96/gW+APcBuYKNn/veLH/rU2bihJjMzs2PUOyCEiGsShCobi3np5/8CreCyZ0wGDODu\n",
       "aDUqGjzBph3QA+jpee2BeWbzX+ArYIfntRhwAt+6S1SN5Sg2bZITGCFE9SQIeRiG0RyYB4wOlJzU\n",
       "Zc/IAB4GbFZHWdDnhuKZJ+B0APoDAzBHAXbCPIvZCvwLc8TfVsxAI1FECFEvJAid8kvgNafT+UV1\n",
       "C132jFaYGbFvtTrKvo9qy+rIYtNpmAEnGzPo9Ma8VLYB+ADzIdvt7hLlilkjhRApSYIQYBjGecD1\n",
       "QLfqlrvsGRbgZWCR1VFWEs22hcNzptMZuBIYhnmm8xGwBrO20ZZQLqMJIUR9kyBk+hmwMEiJhocw\n",
       "hwEXRq9JteMZpXY5MB4YgTnybAVmLrtSd4mSUhJCiLiT8kHIMIxzgGsIfBaUC9wEDLQ6yuLq3ojn\n",
       "wc0BwATMQRWfAkuAR90lan8s2yaEEKFI+SAEPAj8wel0Hqm6wPM80B8xMyIcinrLArDYdCfM0Xnj\n",
       "MEesLQHmuEtUsGHlIsryCuxq4qBH0GjyCuwNOZWSp+qkqrwmRdqeET1v9fwc5tqoLJy0PXGXnifQ\n",
       "MYb1uAWAvIK5OVE4fm2cLMx3xN1zjSkdhAzDOBu4DugeYJX/B7wdDyl5PGc9w4B7gQsxU6EMcJeo\n",
       "vTFtWJTkFdgVZtaEZp7Jm6qn6qt/uh7/9zWl7fFP2RMsdY9/qp5AKXh83trku4L7JafS8vin5wn0\n",
       "PlCqnqrzqGadSKbtCWVZ1fcAfLZng/ft/aGsH+KySKwf7jYh+fK7Ld63tX2Mo76vtFQAEoTizCzg\n",
       "j06n83DVBS57xiXAjcBlUW+VH4tNpwO3YWZx+BKzwN4q/9QwicDlPklegf08zDQ9rTk9bY83ZY//\n",
       "qzdtj/cP/DHM7AkVhJ62Z7/n9TinUvZEIm2PuzDfUeMfjU2eh6RS8UFdv75fF+u2RNOmTZtuAHjg\n",
       "5l/fGOu2JIKUDUKGYZwF3EA1Z0Eue4bCPNOYaXWUnRagosFi0y0xLxVOxLzcdpW7RH0di7YE4jk7\n",
       "SedUyp72VE7bczbQtnGDZlgtaQBvU33anq8xU/V40/X4p+2pKMx3yNBxIZJUygYh4AHgWafTWd29\n",
       "nolAeSzS8lhsugkwwzP9GejhLlE/RrsdXnkF9iaYGSK86Xr80/a0wsz79m8qp+35BE/KHuD76/ve\n",
       "96NSiszMzID5+IQQqSklg5CnYurNmOlpKnHZM1oDc4DB0WyTxaYbALdjDgdfBvR1l6j/Ruv4eQX2\n",
       "xphlzHtyKm1PN8xLYV9zKm3PWuB5zLQ9P4R4Sap+Gi2ESHgpGYQwb5Q+73Q6y6tZ9hvgD1ZHWdBq\n",
       "qpFkselRmCmDPgBy3SVqV30eL6/A3gC4lFNpezIx7798zqm0PW8AnxXmO04bNSiEEJGSckHIMIxW\n",
       "wCTMP8KVuOwZIVVTjRSLTZ+J+TBpF+B6d4naWh/HySuwtwByOJW250LMQLMBMxXRzMJ8R0qMshNC\n",
       "xJeUC0LAfcCfnU7nD/4zXfYMbzXVqVZHWcBqqpFisemxwALPMW+PZN62vAJ7GubZjTdtTwfMy2hr\n",
       "MC+lbSvMdyTU6DohRHJKqSBkGEYzzPsu1Q27vh8otTrKSuuzDT8csWKx6VcwA8NId4n6MhL79Qwg\n",
       "GImZticL80xnBeZZ3dZQ7t0IIUS0pVQQwkxv807VgnUue0ZL4B4goz4PXrw1nfl/bQ9mwbdJdT37\n",
       "ySuwN8I805mAebltNWYtpNsK8x3H6tZaIYSof6kWhO7EDDZV5QEvWx1l9ZL2xpPV+n8uOv88Fk7b\n",
       "zjUjez5Zl/3lFdgzMR9eHYZZYG4JMEUCjxAi0aRMEDIMowfQ0Ol0bvGf77JnpAOTqaezIItNNwVe\n",
       "ABo+m7+Npo3CuxXjOeu5DjNtjxv4A3BvYb4jUOZvIYSIe2EHIaXU+cBfPPvYqLWeqZQailkcTgOz\n",
       "tdarI9PMiLgTeK6a+XnA/9XHWZDFps8HHMByYHbTRu5aX37LK7CfD0zFHNG3GrinMN+xOaINFUKI\n",
       "GKnLmdA84BGtdSmAUkphPuR5BeYDju9h/tGMOcMwGgPXUiVFj8ue0QKYgllpNKIsNt0PeA14xF2i\n",
       "FgPU5plNT561RzEvuT0HZMowaiFEsgkrCCmlLEBnbwDy6AJs01of86yzQynVWWu9IwLtrKtxwAqn\n",
       "01k1/c29wCtWR1lEa+9YbPpGYC5wg7tEbazNtnkF9jOBn2MONpgP5BfmO6QgnRAiKYV7JnQW0Fgp\n",
       "tRQz2/FTwHdAuVJqAeaZUDlmtuR4CEJ3YqbD8XHZM87wzM+M5IEsNn07kA9ku0vUt6Ful1dgb4Z5\n",
       "aXAq8CegZ2G+I25qGAkhRH1QWtf+8RGlVBrmg4+DMQNZCXAHZlLQaZhB6GlgbtUzofLyct8Bt2/f\n",
       "HnbDQ/Xtt9+yYMEC5s2bh3nF0NS25B9Yjx9lz5BxETvWe5tb8eLKc1k040taNT8Z0jZaa77e+y8+\n",
       "3l3EBa0voUe7QTRu0DRibRJCiGjp0qWL7316enpIRQXDOhPSWp9USn0DnKu1/lYpdQzzjMfbAoV5\n",
       "uS7mZ0H//Oc/ueKKKyoFIMuJY7Teso4v73gkYsdZ83FLnn/vXBbdE3oAOnL8Rz746h+AZljPSTRv\n",
       "lB6x9gghRCII60wIQCl1AWbp6xbAEq11oVJqGObNdA08prVeWXU7/zOhUCNluAzDaIgZHC/zf0DV\n",
       "Zc/4OdDa6ij7WSSO40lAugAY6i5R3wRaz1vk6+WSuRbMzA2PArOBl5I5o4FfcbNolFuOK9L31Ot7\n",
       "qvYbwvv7HvboOK31buCqKvNWYKaKiRdjgaIqAag55iXDfpE4gMWmr8RMQjosWADyOny8HMwh2z8B\n",
       "tsJ8R8j3jYQQItkk+8Oqd2KOUvM3DXjT6iirc60ei00PxjwbHOkuUc6a1v/qvx/z0e51YKbWeSWZ\n",
       "z36EECIUSRuEDMMwMEtOF3vnuewZjTHT9vSv6/4tNt0Ls/Lp1TUlIfVktX7i7BbtGXnpbWQPyv2/\n",
       "uh5fCCGSgSXWDahHU4AXnE6n/9nGtcBqq6Ps+7rs2GLTLTHr8NxaUw2gvAJ7S+DvwBlXdr+Fpg3P\n",
       "qMuhhRAiqSRlEDIMIw2zfPdLVRbdDTxbl31bbNri2e9z7hJVHGzdvAL7RZjD15cDd1ot1rocWggh\n",
       "kk6yXo67EtjkdDp9aW5c9oyuQDpmNdG6eBBzUMHvg62UV2AfipluZ2phvuM9gE21ydsjhBApIFmD\n",
       "0LXAG1Xm3QU8a3WUhT0YwGLTuZiJRAe6S1TA/eQV2KdjpgQaWZjv+CLc4wkhRLJLuiBkGIYVGA7M\n",
       "9M7zDEi4DugZ7n49GbGfxxyIUDUHnU9egf1+z7FshfmOeqlPJIQQySLpghAwENhaJVnpOGCl1VFW\n",
       "Hs4OLTbdAHgd+EWwgQieM6AbgCsL8x0BA5UQQghTMg5MuAZYWmVeXQck/A74yF2iXgm0Ql6B/Q7M\n",
       "EXkjJAAJIURokupMyDAMBVyNGTQAcNkzumGmFvownH1abPpazLOrwYHWySuw3wTcB1xRmO84GM5x\n",
       "hBAiFSVVEMK85/O90+n0fw7oTsIckGCx6XTM4n3D3CWq2po+eQX2ccD/AEOk6JwQQtROsgWhSpfi\n",
       "XPaMJpiDBHqEub+5wAvuElVtNvC8Avto4FfA0MJ8x3dhHkMIIVJWMgYh/wJB44AV4QxIsNh0XyAX\n",
       "6FPd8rwC+yDMZ4WuLMx3/DuMtgohRMpLmoEJnlxxFqfT+ZXf7LuBZ2q7L4tNp2EmJp1R3WW4vAL7\n",
       "2cDLwPjCfMfO8FoshBAiaYIQYKfypbjuQHNgYxj7mg5sdZeotVUXeJKRLgZ+XZjvKAuvqUIIISC5\n",
       "LsddA+T7fQ5rQILnodQHCFxv6DHg68J8xwthtVIIIYRPUgQhwzDOBs4HPgLfgIRxQPcwdvckMNdd\n",
       "ok6rN5RXYL8aMxvD5eG3VgghhFdSBCFgDLDMr2zD1cAqq6OsVg+NWmz6KuA84LSznLwCeyegAPNZ\n",
       "oKN1bK8QQgiS557QNYDD7/P1mGl2Qmax6aaYo92mukuU239ZXoG9CWZC1LzCfMfXdWyrEEIIj4QP\n",
       "QoZhnAH0AtYDuOwZzYABwOpa7uoR4G/uEvUv/5l5BXYFLAKWF+Y73q57i4UQQnglw+W4EcAKp9Pp\n",
       "8ny+CjNZ6YlQd2Cx6bbALVR/D2kScAFmXjghhBARlAxB6BrgNb/P13F6RdWazAIWuUvUYf+ZeQX2\n",
       "s4A5wOWF+Q5XtVsKIYQIW0IHIcMwGmImFr0DwGXPaArYgImh7sNi02cD46n+LOgJ4PeSEUEIIepH\n",
       "QgchzLQ67zudzmOezyOBf9bmUhxm8btnqjkLysFMiCqX4YQQop4kehAaBfgPFrgOCFjzpyqLTbfB\n",
       "LEJXqeJqXoG9EfAH4LbCfMfJCLRTCCFENRJ9dFwOsAZ8D6hmAStrsf0DwHPVlOt+EFhdmO8IJ+WP\n",
       "EEKIECXsmZBhGG2AJk6n8xvPrBHAGqujrNq6P1VZbLo1cDNwqf/8vAJ7Z8x7TBkRbK4QQohqJPKZ\n",
       "UDZQ5Pf5OswHSkN1P/C8u0T5yjx4ngn6A/BQYb6j1uUfhBBC1E7CnglhXopbC+CyZzTGHCU3OZQN\n",
       "LTZ9JuYIul5VFo0HNLULZkIIIcKUyGdCOZw6ExoOFFkdZccCr15JPvBnd4n6wTsjr8DeEngcuKcw\n",
       "31HrUuBCCCFqLyHPhKq5HxTypTiLTbcEbgMuq7LoMeD5wnzHV6dtJIQQol4kZBDC736Qy57RCPN5\n",
       "obtC3DYfeMldog56Z+QV2C/AHO7dLcLtFEIIEUSiBqEcPPeDgGFAsdVRVmN5BYtNN6P6kW8PA/ML\n",
       "8x0hjawTQggRGYl6TyiHU/eDajMqbjzwjrtEHfDOyCuwt8cMZM9HsoFCCCFqlnBByDCM1njuB3ku\n",
       "xV0BvBvi5ncBz1aZ9zBmfjg5CxJCiChLuCBE5eeDhgIlVkdZRU0bWWz6UsDqLlEfeed5zoJGAH+q\n",
       "j4YKIYQILhGDUA6n7gfZgbdC3O5OTj8LegjzLCjUod1CCCEiqE5BSCnVUCm1Uyk13fN5qFKqWCm1\n",
       "Tik1JDJNPE0OUOSyZ1gw7+W8V9MGntLdY4HF3nl5BfZ2mFm3n6ufZgohhKhJXc+EpgKbAZRSCrMA\n",
       "3JWYD4/OruO+T+O5H9TU83xQBvCV1VEWSnqd64F/VCnX8HPgSTkLEkKI2Al7iLZSqgnmmcgSoDnQ\n",
       "BdimtT7mWb5DKdVZa70jIi01+d8PGg38PcTt7gLu9X7IK7Cf79lengsSQogYqstzQnnAU0Bbz+fW\n",
       "QLlSagGggHLPvEgGoRxO3Q8aBdxS0wYWm+4BNHKXqC1+s71nQTU+WySEEKL+KK1rnyZNKdUCeFVr\n",
       "PVopdSvmmdBKzOHO0zCD0NPA3KpnQuXl5b4Dbt++vVbHnTVrFg899BDnNG5Al5ef4PPpc2vcZv5b\n",
       "7TDOOca1tn0AVBw/xLv/epGrM6aSZm1Qq+MLIYQIrEuXLr736enpKpRtwj0TuhxopJR6FbgQsALF\n",
       "mJfkwAxCEb0Ud+jQIY4fP06bNm1o8dF6fuzcs8Ztjp1QrPmkFXeP+tQ3b+u379P13H4SgIQQIg6E\n",
       "dSZUaQdKTQKaa60XKaWGAY9ilkN4TGt9WpVT/zOhUCMlgGEY1wCjnE7nFJc94y1gkdVR9s9g21hs\n",
       "eiKQ7S5RdwLkFdhbA1uASwrzHTU+WxRpmzZt0gCZmZkh9zsZpGq/QfoOqdf3VO03hPf3vc6547TW\n",
       "L/u9XwGsqOs+A8gB1nqyJAwAbgxhm7swS3h73Qq8GosAJIQQ4nSJ9LBqDubIuGyg1OooOxFsZYtN\n",
       "d8O8V7UJfFVT70SeCxJCiLiREEGoyvNBoQ7NvhN41l2ivKeHOcCuwnzH1/XTSiGEELWVEEEIyMLM\n",
       "kqAwsxwsD7ayxaYbA+OAV/1m3w38sd5aKIQQotYSJQjlYD4fdDFw0Ooo+76G9ccAq90lqhwgr8B+\n",
       "NtCf0B9uFUIIEQWJEoRswHpCvxQ3jso1hm4H/lKY7zhZD20TQggRprgPQoZhWIB2wC7MLAlBg5Dn\n",
       "UtzlwCqAvAK7BZiMlGsQQoi4E/dBCDAA545eLdM97z+qYf1hQJG7RHmL1A0FthXmO3bXYxuFEEKE\n",
       "IRGCUA/gU8zM3CusjrKanq4dR+UaQ1ORAQlCCBGXEiUIbSW0S3EN8Sv3nVdgPw/oRejlv4UQQkRR\n",
       "IgSh7k0sfAbkAkHT9HjW+cBdorwZESYDfy7Md7jqs4FCCCHCU+e0PVHQ43mjeSPgX1ZH2ZEa1vVd\n",
       "issrsFt6kjFZAAAd9klEQVSB2zCfMRJCCBGH4joIGYbRAGjdt5l1EPBOsHUtNm0FRgCzPLNGAh8V\n",
       "5jv21G8rRTIqLy+3WK3W3yuleiqlwr5i0KFDBwAqKirWRqptiSJV+57s/dZau7XW/3K5XPenp6e7\n",
       "67q/uA5CQGdgh1JqJHBtDetmAR+7S9SPns93Awvrs3EieVmt1t83adJkqtVqbViX/TRt2tT7dnDd\n",
       "W5VYUrXvqdBvl8tlO3r0KEB+XfcV7/eEepzXQG0HzrA6ypw1rOt/Ka49ZnaFVfXcPpGklFI96xqA\n",
       "hEhWVqu1oVKq5qJuIYj3INT9ljaNXMCaYCtZbNqCmapnmWfWjcD/FeY76nyqKFJTXS7BCZEKIvVv\n",
       "JN7/ofW4Mr3BWdQ8Kq4/sM1dog54Pt8AvF6vLRNCCFFn8X5PqHv7hhYrMK2G9fwvxXUBVGG+Y1t9\n",
       "N04IIUTdxO2ZkGEYjc9poFqkKXUiWNZsi00rYCzg8MyagJwFiSRWUVHBpEmTGDhwIFlZWTz11FOV\n",
       "lpeXl/P000+Hte+//e1vfPHFF5FoZiUTJ07k4osvjvh+O3TowN13313r7Wrq51tvvcVbb70VcHkk\n",
       "7d+/n/Hjx9OnTx+ys7O55pprfMvmzJnDhRdeSHZ2NpmZmdx///2+ZUVFRYwZM8b3ef78+Tz22GO+\n",
       "z4sWLaJfv340b96c7Oxstm/f7lsW7HeoqKiI1q1bk52dTVZWFtnZ2Zw8WX+5n+P5TOjiYekNDlDD\n",
       "/SAgA/jWXaL+6/k8ATMoCZGUnnjiCS644AJefvnlapcfPHiQRYsWMW1aTRcQTudwOBg9ejRdu3at\n",
       "azN9Tpw4QWlpKR07duTjjz+mV69eEdlvaWkp3bp1Y/Xq1bjdbiyW0P9PXVM/x40bF5E2hmLGjBmM\n",
       "HDmS22+/HYAff/zxtOUPPPAAACNGjODdd99lxIgRACilAu53+vTpjBo1ijFjxrBu3bpKy2r6HbLZ\n",
       "bCxbtqzaZZEWt2dCQPehLRooYHUN6/lfiusOVEj1VJHMtNb88MMP1S4rLS1l/Pjx7Ny587T/VQPM\n",
       "nj2b4cOH07t3b0aPHs3x48d9y+68806WL1/Oo48+SnZ2Nm+//bZv2b59+7juuuvIzc0lJyeHzZs3\n",
       "h9ze5cuXM3z4cCZNmsTixYtr2dvAlixZwh133EFWVharVlUeCFtUVERubi5ZWVnYbDY++uhU3uNg\n",
       "/SwtLSUrK4sOHTqwYMGCSvs8evQod911F4MGDaJ///4sXLiw0vGuvPJKZs2aRW5uLn379uXAgQPU\n",
       "pLy8nA0bNvgCEECLFi0qraO1mS7z4MGD7N+/n/bt24fw0wku2O+Q/zGjIZ7PhHr0bJp2NlAUaAXP\n",
       "pbhrMTNlg1yKE1GyeouD1Vv+Vqd9DOk9liG97bXe7sEHH2Tq1Kn06dOH++67j4kTJ/qWDRw4kDfe\n",
       "eKPa//2C+b/q2bNnA2C321m6dCk33HADAM899xy33347Y8aM4dprKz+Wd++99zJlyhRGjBjB7t27\n",
       "GTNmDB9//HFI7X399de555576NmzJ7/73e94/PHHa93n6rz77rv85je/oWXLlixevJhhw4YBsGvX\n",
       "LqZMmcLq1aur/YMdrJ8DBw6kuLiYOXPmnLbdr371K1q2bMn777/PsWPHyM3NpUePHuTm5gKwbds2\n",
       "nnrqKebNm8dtt92Gw+HgjjvuCNoHp9NJx44dg67z9NNP88orr+B2u3nyySfp3r170PVDEex3CMxg\n",
       "PGTIELTWtG7dmjfffLPOxwwkboPQxY0tfRXstzrKDgZZrRvwg7tEfZtXYFfA9ZilHISoV0N628MK\n",
       "IJHQrFkz/vKXv7B7925mzZrF2rVref7550PatlWrVhQVFfHll19SUVHBf/7zn5C2W7VqFd999x2/\n",
       "/e1vAfMS28GDB2nVqlXQ7Y4dO8bKlStxOs3H/L7//ns2b95Mnz59QjpuIOvXr+fAgQPk5ubicrn4\n",
       "5ptvcLlcWK1W/vGPf3D99ddH5IzB37vvvsvrr5v/x23cuDF33HEHy5cv9wWhyy67zHffyzCMoGca\n",
       "tTF9+nSuvfZabDYbPXr0iMg+a/odGjRoUNQux8VtEOrXPK2XBV6tYbVrgL963vcC9hfmO76p35YJ\n",
       "ER8uuOACFi9eTNu2bTl58iRpacH/OVdUVDB48GCuvvpqbDYbnTt3DvmyS1paGsuWLeOMM86oVRvf\n",
       "eecdbrnlFn7/+98DsHjxYl5//fU6B6HXX3+dZ599lrFjzdu/U6dOZcWKFYwcORKgXm6kK6Uq/by0\n",
       "1kHvyYTCMAy+/rrmuwcdO3ZkypQpzJw5k5deegmAhg0bcuLECd86J06coFGjRrU6fm1/h+pDXN4T\n",
       "Mgyj2YBmaU2bWlVNJRhGcCqn3A1A5C44CxGnKioqfO8///xz2rZtW+mPR+PGjdm/fz9ut/mstvcP\n",
       "57Zt22jYsCG/+MUv6N27N2VlZacFocaNG/P9999X2g5g7NixPProo77PoQavJUuWMHr0aN/nESNG\n",
       "8Ne//jXIFjXTWvP3v/+dK6+80jdv1KhRvvtNI0eOZMmSJezYsSPgPgL1M5iRI0f6Rh1WVFTw/PPP\n",
       "+4JeuNLT07HZbCxatMg3z3vWWNVDDz1EcXExxcXFAHTp0oVPP/2Uw4cPA/DBBx9wySWXVNpGa11t\n",
       "/2r6HYrmPaG4DEJpcElmszQrsD7QOhabTgfOBz73XIobB9TfhUsh4sSyZcvo06cPgwcPZtasWbzx\n",
       "xhuVlrdt25bBgweTkZHB8OHD2bRpEwC9evXiggsuoFevXkycOJGcnBy+++67StvefPPNLFiwgCFD\n",
       "hpCffyot2Lx586ioqKBfv35kZ2czefLkGttZUVFBcXExgwefSqHWsmVL2rVrx4cffuib5x055/+H\n",
       "MZiioiK6du3qn6ONoUOHsnLlSn766Sc6duzISy+95Bu0MHjwYEpKSkLqZzAPP/wwhw4dYuDAgeTk\n",
       "5DBp0iRycnJC2jaYhQsXsm7dOvr06cPll1/OzJkzOXTo0GnrNWnShCeeeIJ77rkHl8tFmzZtfIMr\n",
       "BgwYQJs2bbj66qt96y9atKjSIBX/Ido1/Q6VlpZWGqId6ncTDhXNiAdQXl7uO2B6enq157IzMi76\n",
       "f/ef03h6p+WftAu0H4tNXwuMcpeoyXkF9n7AbwrzHUMi3+LI2bRpkwbIzMys2zl8gknEfldUVKxt\n",
       "2rRp0iagjCcVFRUMHTqUoqIiGjRoEOvmiBBVVFQUNW3aNMd/Xih/36uKyzOh3k3Thuw54d5Uw2rD\n",
       "gBWe9xOQS3FCJKQ9e/bwzDPPSABKUXE5MOHiJpYe357QjwZa7hmaPRR4JK/AbsEcpt03Wu0TQkRO\n",
       "586dY90EEUNxdybksmdYOzWytvnymOuNIKt1Bg64S9R+YBCwrTDfsS86LRRCCBEpcXcm9GnFSdtR\n",
       "Nyf+58Mvgj0fNBx4z/NeHlAVQogEFXdnQj9prv/0qGtnDasNA1bkFditwNXA0npvmBBCiIiLuyDU\n",
       "Kk3lfFRxckOg5Rabbgj0AT7ALJ/7cWG+IzKPJgshhIiquApCLntGg1ZpFmPVjz8FK8s9ENjoLlE/\n",
       "AeORS3FCCJGw4ioIAX23HXUdO+rmkyDrDAfeyyuwpwFXAW8HWVeIpCP1hE5JhnpCgb7Pr776iqys\n",
       "LLKysjjnnHPo1q0b2dnZTJgwodL21f1sd+3ahdVq5dNPPwXMmkWGYfiW5+bmkpGRQe/evZk8eTLl\n",
       "5eX13MvA4i0IDSk69JMVCFYV1ft8UDZQVpjv+DHIukIkHW8tmNLSUoqLi5kxY0al5d56QuFwOBy+\n",
       "P1yR4q0n1L59+5Azb4eiaj2h2qipn+PGjYtaTaFA32enTp18aXquuuoq5s6dy7p163xJVCH4zzYt\n",
       "La1SxvKqee5eeOEFtmzZQmZmJjfddFM99jC4uApCx916eOnhkwecTueJ6pZbbPosoIW7RH2FmTE7\n",
       "2DBuIZKS1BMyJUM9Iai5to93neoE+9ledNFF7Ny5M2AuOu8+p02bRnl5OVu2bAmpvRHnTXAXremH\n",
       "H37Q3sl//smxl6mdIy9deWHHjksCbasGuW9Sg9yL7n1ybNq9T47dfe+TY9Oj3f66TBs3btQbN27U\n",
       "sWyD9Du06ciRI2t1EPNedevzxtRtmveqO9ghAjp8+LC+5ZZbdO/evfXLL7982vKdO3fqnj17Vrvt\n",
       "3r17fe/Hjh2rX3vttUrLb7vtNv3WW2+dtt0NN9ygly9frrXWeteuXfrSSy8Nub033nijXr9+vS4v\n",
       "L9fdu3cPebuadO3aVR87dkyvWLFC33HHHb75O3fu1J07d9a7d+8OuG2gfnrNnj1bz58/v9K8Rx55\n",
       "RD/44INaa62PHj2qBwwYoFevXq211nrt2rW6ffv2+osvvtBaa33rrbfq559/PqR+1PR9BmtvoJ/t\n",
       "zp07dY8ePfTSpUv1XXfdpfft26c7duzoW56Tk6M3b97s+3zffffpF198MaT2enn+jVT6dxPo73uw\n",
       "KaznhJRSfwQuBhRwu9baqZS6ApgNaGC21rqmiqiVWB1lOscwHECbIKsNwxyOnQ18VJjviN2FTJHS\n",
       "Zt6omHljbI4t9YSSq55QuN9nTT9bpRR2u505c+awZ8+eoGUntI5uDlF/YQUhrfVUAKVULvCgUuoe\n",
       "4DHgCszA9B41l+WuTg+g2pFxnlQ9uUAe8FvkUpxIcVJPKPHrCfmr7fcZ6s/2vvvuY968eUH3tXHj\n",
       "xtOqq0ZLXe8JHQJOAF2AbVrrY1rro8AOpVQ4CaF6AFuDLNs1Y/w1R4BRQHTK/gkRZ6SeUPLUE/Lu\n",
       "y6u67zOQmn623n7dfPPNrF8fsCoOixYtIj09vc7/MQhXXdP2TAYKgNZAuVJqAeaZULlnXuDfAk6l\n",
       "+AfzB9ayZUv++Mc/fuGtf+Ivb2xbjv+kGNb9lpOf7dnAkG4TfqhuvUTg3+9Ukkj97tChQ6V6NfFk\n",
       "2bJlPPHEEzRv3pymTZsGrSd0zjnnMHfuXPr27VupntAFF1wQsJ7Q7bffzhtvvEGPHj0oLCwEzHpC\n",
       "M2fOpF+/fjRu3JjOnTvzwgsvBG2nt57QK6+84pvnX0+oX79+gDkY4MYbb+Szzz4L6WceqJ7Q3Xff\n",
       "fVo9Ia01FouFX//619hsthr7GczDDz9Mfn4+AwcOxOVyceutt0aknlBN3yecPrKtpp9t27Ztfduk\n",
       "paWRl5dHQUFBpX1MmTIFt9tNRkYGr732Wq3bfeTIkcGfffZZpX/TXbp0qfV+wq4npJQaDXTWWj+p\n",
       "lLoIeBiYhhmEngbmaq1PC0L+9Sb8iyxprfnuu+8499xzqz3evYu6MG3Ut/x48i3OOuN8Op19aVjt\n",
       "FiIUHTp04Kyzzop1M1KC1BNKTHv37mXXrl2V5vkHoVDrCYUVhJRSfYAbtdazPJ8twDrM8goWYIXW\n",
       "+vLqtg2r6JFNNwW+7NvtdaN/j8U7gEsTcVBCIhZ3i4RE7LcUtYueHTt2cPToUXr27BnrpohaiFRR\n",
       "u3Avx70BfKOUWgN8orXOV0o9hjmoQANzwtxvIFnA+v49FtuATxIxAAkhqif1hFJbuKPjLqxm3gpO\n",
       "VTqNtOGefcsDqkIIkUTiKmNCEEMaNyxfDYxGRsUJIUTSiPsgZLHpZkCrKfbbOgD/krINQgiRPOI+\n",
       "CGHWDtqMXIoTQoikkwhBqL9Sro3AGOBvsW6MEEKIyEmIINSj03tHga1yKU4IIZJLIgShzL7dXr8E\n",
       "uRQnBJBYRe2Kiopo3bo12dnZ9O/fn3HjxvHjj5ErAZYMRe3279/P+PHj6dOnz2nlN+bMmcOFF15I\n",
       "dnY2mZmZ3H///b5lRUVFjBkzxvd5/vz5PPbYY77PixYtol+/fjRv3pzs7OxKyQGC/Q75f2dZWVlk\n",
       "Z2fXSy4+r7qm7alXFps+F/Shpo1/HAE8FOv2CBEPvEXQXn755WqXe4vaTZs2rdb7djgcjB49mq5d\n",
       "u9a1mT42m41ly8xBrQ8//DALFy7kkUceqfN+qxa1s1hC/z91Tf2MVkE7gBkzZjBy5Ehuv/12gNOC\n",
       "9IwZM3jggQcAMz/cu+++y4gRI4DT0/n4mz59OqNGjWLMmDGsW7eu0rKafof8v7P6FtdBCOjf6oxv\n",
       "/wN8VpjvOBjrxgjh9dxzz/GnP/2pTvuYMmUKd955Z62389RtqXZZaWkp+fn5vqJ2rVu3ZunSpb7l\n",
       "s2fPprS0lL1793Leeefx1ltv0ahRI+BUsbcPP/yQgoICHnzwQd//tPft28fUqVPZv38/Wmvmz58f\n",
       "csJLb1YWl8vF3r17IxbgvEXtli9fzqpVqxg2bJhvWVFREbNnz+bkyZO43W7+8Ic/cNlll9XYz9LS\n",
       "Un72s5+xe/du8vPzfX/8wSxql5+fz9atW3G5XNxyyy3ce++9vuPNnTuXXr16sXnzZg4fPsx7773H\n",
       "mWeeGbQP5eXlbNiwoVLuthYtWlRax/vzO3jwIPv3749IiYpgv0P+x4yKUAsPRWqqTdEjNcj9eP87\n",
       "X9ly75NjR0a7nfUxJWJxt1Ttd01F7WIpkYrarV27Vrdu3Vrn5OTotm3b6gkTJoS0XSiSoahdWVmZ\n",
       "zs3NDdqOTp066YyMDN2rVy+9Zs0a37K1a9fqMWPG+D7PmzdPz5kzp9L2gX4Xgv0Oeb+z3NxcnZOT\n",
       "o8eNG1dt22Ja1C5aLJafBnU4d3NbYGWs2yJEvEikonYAgwYNYtmyZbhcLn7+85/zi1/8gv/93/8N\n",
       "6biBJFNRu5pMnz6da6+9FpvNRo8ePSKyz5p+h7zfWTTE7cAEi01bLcp1Wev03a8W5jvq766YEAnK\n",
       "WwRt2bJlId04rqioYMCAAaxbt45OnTqFVdRuzZo1rFmzhs8//zykAOTParUyY8aMiPxx8xa1e//9\n",
       "99mwYQNXX301K1acyhqWKEXtDMPg66+/rnG9jh07MmXKFGbOnOmb17BhQ06cOOH7fOLECd+l1VDV\n",
       "9neoPsRtEAK6tmrxb0ua9acXY90QIeJJIhW1q7rum2++Se/evUPeNtD+kqWoXXp6OjabjUWLFvnm\n",
       "ect1V/XQQw9RXFxMcXExYJZN+PTTTzl8+DAAH3zwAZdcckmlbbyXvKqq6XeoNt9vXcVtEGp75pfX\n",
       "nt3qq8OF+Y5PY90WIeLJsmXL6NOnD4MHD2bWrFlBi9oNHz4cb/FH/6J2EydODFjUbsGCBQwZMoT8\n",
       "/Hzf/Hnz5lFRUUG/fv3Izs5m8uTJIbe3tLSU7Oxs+vTpw8cff8yTTz552vKOHTtW+sMYTKCiditX\n",
       "rjytqF1WVhaDBw+mpKQkpH4G8/DDD3Po0CEGDhxITk4OkyZNikhRu4ULF7Ju3Tr69OnD5ZdfzsyZ\n",
       "Mzl06NBp6zVp0oQnnniCe+65B5fLRZs2bXj00UfJzs5mwIABtGnThquvvtq3/qJFixg/frxvkIr/\n",
       "EO2afoe835l3iHao3004wi5qF65Q6010uLbso7Nafr1p0wvjpkSnZfUvEevqREIi9lvqCUWPFLVL\n",
       "TJGqJxSXZ0J5Bfa0I0dbXXLkWKuCmtcWQiSyPXv28Mwzz0gASlFxOTruxyNnjak43tK1bVfu1li3\n",
       "RQhRv6SoXWqLyzOhvQc7zUizHv/EXaKie61QCCFEVMVdEMorsLc6+GO73hVHz3w71m0RQghRv+Iu\n",
       "CAETnHsy/+vWaaWxbogQQoj6FY9B6La9P1zYHNgU64YIIYSoX3EVhPIK7F0PVbRu5nY3+MFdoiKX\n",
       "710IIURciqsgBNz62ddDPwA2xLohQsQrqSd0SjLUEwr0fX711VdkZWWRlZXFOeecQ7du3cjOzmbC\n",
       "hAmVtp84caIvZ53Xrl27sFqtfPqp+az//v37MQzDtzw3N5eMjAx69+7N5MmTKS8vr+deBhY3QSiv\n",
       "wK6AEZ/sGHUYCUJCBOStBVNaWkpxcTEzZsyotNxbTygcDofD94crUmw2G+vWrWPDhg1cdNFFLFy4\n",
       "MCL7rVpPqDZq6ue4ceOiVlMo0PfZqVMnX5qeq666irlz57Ju3TpfElUw88WVlpbSvn17Pv7440r7\n",
       "TUtL4/HHH/d9rprn7oUXXmDLli1kZmZy00031WMPg4ubIFSY79BAv+MnzuiJBCEhAvKkzK92WWlp\n",
       "aaVULf5VOsGsJzR8+HB69+7N6NGjOX78uG+Zt86ONxXM22+fGqC6b98+rrvuOnJzc8nJyWHz5s21\n",
       "ai+cqifUrl272nQ3IG89oaysLFatWlVpWVFREbm5uWRlZWGz2fjoo498y4L1s7S0lKysLDp06MCC\n",
       "BQsq7fPo0aPcddddDBo0iP79+1cKpkVFRVx55ZXMmjWL3Nxc+vbty4EDB0LqR7Dv03+d6ixfvpzh\n",
       "w4czadIkX+48r4suuoidO3cGzEXn3ee0adMoLy9ny5YtIbU34kKt+RCpKVi9CTXIbVGD3P9Rg9xp\n",
       "0W5XNKZErKuTqv2uqZ6Qa+lL+uRtQ+s0uZa+FOwQAUk9IVMy1BPSuubvM1h7b7zxRr1+/XpdXl6u\n",
       "u3fv7pu/c+dO3aNHD7106VJ911136X379umOHTv6lufk5OjNmzf7Pt933336xRdfDKm9XslaT+hi\n",
       "YIe7REnpBhHXLPZJYJ8Uk2NLPaHkqicU7vd57NgxVq5c6TvT+f7779m8ebOv4q1SCrvdzpw5c9iz\n",
       "Z0/QshNaxy4vQNxcjvPoj1yKEyIkUk8o8esJ+avt9/nOO+9wyy23UFpaSmlpKQsXLqx0v8jrvvvu\n",
       "Y968eUH3tXHjxogVzKstCUJCJBipJ5Q89YS8+/Kq7vsMZMmSJYwePdr3ecSIEfz1r3/1ffb26+ab\n",
       "b2b9+vUB97No0SLS09N9Z1DRJkFIiAQj9YSSq55QTd8nnD6yraKiguLiYgYPPlVtpGXLlrRr144P\n",
       "P/yw0jZpaWnk5eWdts8pU6Zw2WWXsXHjRl577bU69yNccVNPyGLTClgETE/WxKWJWFcnEhKx31JP\n",
       "KHqknlBiilQ9obgZmOAJPNNi3Q4hRHRJPaHUFjdBSAiRmqSeUGqLt3tCQsQFHcsxq0IkAK117dJU\n",
       "BCBBSIjqVUgcEqJ6ngdNj0ZiXxKEhKiG2+3+/YkTJ/bGuh1CxKMTJ07sdbvd8yOxL7knJEQ1zjjj\n",
       "jFWHDx8uOHny5BCllDXc/Rw5cmQwQLNmzYoi17rEkKp9T/Z+a61dWuvVLVq0WB2J/UU8CCmlrgBm\n",
       "AxqYrbWOSEOFiLbmzZv/CvhVXfbx2WefeYen50SiTYkkVfueqv0OV0SDkDKfjnoMuAJQwHuABCEh\n",
       "hBDVivQ9oS7ANq31Mc9Nqx1KKRl/KYQQolqRvhzXGihXSi3APBMq98wLnMRJCCFEyopo2h6l1EXA\n",
       "w5iZDxTwNDBXa+0LQv5pHYQQQiSnUNP2RPpy3A7MS3JgBqHO/gFICCGE8BfRy3Faa7dSag6wCnN0\n",
       "3JxI7l8IIURyiXoWbSGEEMJLMiYIIYSIGQlCQgghYkaCkBBCiJiJehBSSl2hlCpWSq1TSg2J9vGj\n",
       "SSl1uVLqQ6XU7/zmJX3/lVJ/VEqtUUqtVUoZnnlJ328ApdRcpdRqpdTKVOs7gFKqoVJqp1Jquufz\n",
       "0GTvu1Lqz0qpUs/3PskzL+n77aWUOt/T93VKqfmeeaH335OSOyoT5rDtEqAx0ARYF83jR3vCTF9k\n",
       "B36Xov3PxSzZnlL99vTdBvwx1foO5AFvAdNTpe/AC0B7v88p0W+//r4GDAy3/9E+E0qptD5a638C\n",
       "B/1mpVT/gUPACVKv3wD9gS9Iob4rpZoAw4C/eWalSt8Vla8qpUq/UUpZMJ8HLfWbXav+R7uUQ6qn\n",
       "9Um1/k8GCkixfiulioBzgcuBTqRO3/OAp4C2ns+p8r0fAl5VSu0HHiB1+g1wFtBYKbUUaIH5/X9H\n",
       "Lfof7SC0H2hJ5bQ++6PchlhKmf4rpUZj/m/oC086p5ToN4DWerBSqi/wMnAvKdB3pVQLIEtr/Vul\n",
       "1K2YfU2J33etdR6AUuoy4AngZ6RAvz32Az8A4zDjSQlwB7Xof7SDUKqm9fHmUEqJ/iul+gA5WutZ\n",
       "nlkp0e8qvsfMGvIVqdH3y4FGSqlXgQsBK1BMavTd6xjwE6nznaO1PqmU+gY4V2v9rVLqGLX89x7V\n",
       "IKRTLK2PUurnwEigrVKqhdb6bqXUYyR//98AvlFKrQE+0Vrnp0i/UUq9DrQBjgIzUuV3Xmv9D+Af\n",
       "AJ4RYs211p+kwveulFqMefn1EHBPqnznfh4CnvOcDS/RWh+tzfcuaXuEEELEjDysKoQQImYkCAkh\n",
       "hIgZCUJCCCFiRoKQEEKImJEgJIQQImYkCAkhhIgZCUJCCCFiRoKQEEKImPn/ANLkBPyiKPQAAAAA\n",
       "SUVORK5CYII=\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1042a3f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pylab as pl\n",
    "\n",
    "x_axis = range(1, 1 + len(logs[A][STAND]))\n",
    "for s in states:\n",
    "    for a in actions:\n",
    "        pl.plot(x_axis, logs[s][a], label=\"State %s, Action %s\" % (['A', 'B'][s], ['CRUISE', 'STAND'][a]), \n",
    "                linewidth=0.9)\n",
    "pl.legend(loc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Induction\n",
    "\n",
    "We can also calculate optimal policies by applying the backward induction algorithm. It is an iterative procedure, but unlike value or policy iteration, it iterates over time. Specifically, it iterates backward in time, beginning at the time horizon $T$ which is populated with a terminal value function (or arbitrarily set to zero). It then calculates the immediate reward from the previous time step, recording the action that leads to the highest expected total value. The value for each state under the optimal policy is stored, and updated repeatedly according to this algorithm.\n",
    "\n",
    "This backward recursion approach reduces computational complexity by only tracking the value function corresponding to the optimial policy.\n",
    "\n",
    "Initialize the optimal value fuction (lookup table) \n",
    "\n",
    "$$v^*_{t+1}(x_{t+1}) = v_T(x_T)$$\n",
    "\n",
    "For each value of $x_t$, $a_t$, $z_t$ compute the next state:\n",
    "\n",
    "$$x_{t+1} = f_t(x_t, a_t, z_t)$$\n",
    "\n",
    "along with the associated probability \n",
    "\n",
    "$$Pr[x_{t+1} = f_t(x_t a_t, z_t)] = p(z_t | x_t, a_t)$$\n",
    "\n",
    "Compute the optimal value function for the current time step\n",
    "\n",
    "$$V_t^*(x_t) = \\max_{a_t \\in A_t} \\left[ \\sum_{z_t \\in Z_t} p(z_t|a_t,z_t)[v^*_{t+1}(x_{t+1}) + r_t(x_t, x_{t+1},a_t,z_t)]\\right] $$ \n",
    "\n",
    "However, we cannot evaluate $v^*_{t+1}(x\\_{t+1})$ directly, since it is a function of discrete values of $x_t$. Thus, an interpolation must be performed:\n",
    "\n",
    "$$v^*_{t+1}(x_{t+1}) = L(v^*_{t+1}(X_{t+1}), x_{t+1})$$\n",
    "\n",
    "where $L$ is the linear interpolation function.\n",
    "\n",
    "We then substitute the state dynamics function into the value function, so that it is expressed in terms of values at time $t$:\n",
    "\n",
    "$$V_t^*(x_t) = \\max_{a_t \\in A_t} \\left[ \\sum_{z_t \\in Z_t} p(z_t|a_t,z_t)[L(v^*_{t+1}(X\\_{t+1}), \\color{red}{f_t(x_t, a_t, z_t)}) + r_t(x_t, x_{t+1},a_t,z_t)]\\right] $$ \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mangel and Clark example\n",
    "\n",
    "Marc Mangel and Colin Clark applied stochastic dynamic programming to address behavioral ecology problems. In this case, the \"decision-maker\" is an individual organism that presumably is optimizing some measure of biological fitness in the face of various constraints and tradeoffs.\n",
    "\n",
    "Consider a simple patch dynamics model: an organism has three patches available to it. Two patches are feeding patches, and a third is a reproductive patch, where it can lay eggs. In the feeding patches, the food resources are used to enhance both survival and reproduction. At the end of the season, the organism may reproduce prior to dying. Each of the three patches has different costs and risks. There is an energetic cost $a_i$, a mortality risk $m_i$, a feeding probability $p_i$, and an energetic value of food $y_i$ for each patch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>m</th>\n",
       "      <th>p</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 1</td>\n",
       "      <td> 0.01</td>\n",
       "      <td> 0.2</td>\n",
       "      <td> 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 1</td>\n",
       "      <td> 0.05</td>\n",
       "      <td> 0.5</td>\n",
       "      <td> 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 1</td>\n",
       "      <td> 0.02</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a     m    p  y\n",
       "1  1  0.01  0.2  2\n",
       "2  1  0.05  0.5  4\n",
       "3  1  0.02  0.0  0"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "m = [.01, .05, .02]\n",
    "p = [.2, .5, 0]\n",
    "y = [2, 4, 0]\n",
    "a = [1, 1, 1]\n",
    "\n",
    "pd.DataFrame({'m': m, 'p': p, 'y':y, 'a':a}, index=(1,2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the decision is whether to occupy patch 1, 2 or 3.\n",
    "\n",
    "The value is calculated as the reproductive success for behaviour $n$ at energy $x$, time $t$ in the fitness array $f$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Largest energy store\n",
    "xmax = 30\n",
    "# Minimum reproductive energy\n",
    "xrep = 4\n",
    "# Time horizon\n",
    "tmax = 20\n",
    "\n",
    "c = 4\n",
    "acap = 60.0\n",
    "x0 = 0.25*xmax\n",
    "xint = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we specify the **state-action value function**, which here is the value of visiting patch $i$ on day $t$, given energetic stores $x$.\n",
    "\n",
    "The state dynamics are specified by:\n",
    "\n",
    "$$X(t+1) = \\left\\{ \\begin{array}{l}\n",
    "x - a_i + Y_i, &\\text{with probability } p_i \\\\\n",
    "x - a_i, &\\text{with probability } 1 - p_i\n",
    "\\end{array} \\right.$$\n",
    "\n",
    "which describes the probability of locating food during day $t$ in patch $i$. Each of these have associated fitness values:\n",
    "\n",
    "$$Q_i(x, t) = \\left\\{ \\begin{array}{l}\n",
    "(1 - m_i)F(x - a_i + Y_i, t+1), &\\text{with probability } p_i \\\\\n",
    "(1 - m_i)F(x - a_i, t+1) &\\text{with probability } 1 - p_i\n",
    "\\end{array} \\right.$$\n",
    "\n",
    "for patches 1 and 2. Visits to the reproductive patch involves three alternative scenarios, depending on the state:\n",
    "\n",
    "- If energetic reserves are below the reproductive minimum $x_{rep}$, there is no reproduction, and the only fitness is from future expected reproduction:\n",
    "\n",
    "$$Q_3(x,t) = (1 - m_3)F(x - a_3, t+1)$$\n",
    "\n",
    "- If energetic reserves are just above the reproductive minimum, within the daily energetic cost, there is limited reproduction:\n",
    "\n",
    "$$Q_3(x,t) = (x - x_{rep}) + (1 - m_3)F(x - a_3, t+1)$$\n",
    "\n",
    "- If energetic reserves are above $x_{rep} + c$, there is full reproduction:\n",
    "\n",
    "$$Q_3(x,t) = c + (1 - m_3)F(x - c- a_3, t+1)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Q(i,x,t,f):\n",
    "\n",
    "    # Fitness value for visiting the two foraging patches\n",
    "    if i<2:\n",
    "        \n",
    "        # forages\n",
    "        x1 = chop( x + y[i] - a[i], 0, xmax ) \n",
    "        x2 = chop( x - a[i], 0, xmax )\n",
    "        \n",
    "        return (1.0 - m[i]) * (p[i] * f[x1,t+1] + (1.0 - p[i]) * f[x2,t+1])\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        # tries to reproduce\n",
    "        if x < xrep: # can't reproduce\n",
    "            reproduction = 0\n",
    "            x1 = chop(x - a[i],0,xmax)\n",
    "            \n",
    "        elif x < xrep+c: # limited reproduction\n",
    "            reproduction = x - xrep\n",
    "            x1 = chop(xrep - a[i], 0, xmax)\n",
    "            \n",
    "        else: # full reproduction\n",
    "            reproduction = c;\n",
    "            x1 = chop(x - a[i] - c, 0, xmax)\n",
    "            \n",
    "        return reproduction + (1.0 - m[i]) * f[x1,t+1]\n",
    "    \n",
    "def chop(x, minval, maxval):\n",
    "    # Utility function to constrain state to the range [minval, maxval]\n",
    "\n",
    "    if minval <= x <= maxval:\n",
    "        return x\n",
    "    elif x<minval:\n",
    "        return minval\n",
    "    else:\n",
    "        return maxval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At each step in the DP, we caluclate the optimal decision and the corresponding value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "listmax = lambda x: (np.max(x), np.argmax(x))\n",
    "\n",
    "def update(f, dec, t):\n",
    "    \n",
    "    f[0,t] = 0.0\n",
    "    for x in range(1,xmax+1):\n",
    "        choices = [];\n",
    "        for n in range(3):\n",
    "            choices.append( Q(n,x,t,f) )\n",
    "            \n",
    "        (f[x,t], dec[x,t]) = listmax(choices)\n",
    "        \n",
    "    return f, dec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize data structures to hold fitness values an decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = np.zeros((xmax+1,tmax+1), float)\n",
    "dec = np.zeros((xmax+1,tmax+1), int)\n",
    "for x in range(xmax+1):\n",
    "    f[x,tmax] = acap*x/(x + x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the SDP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = []\n",
    "\n",
    "# Reverse iterate over time\n",
    "for t in range(tmax-1, 0, -1):\n",
    "    \n",
    "    f, dec = update(f, dec, t)\n",
    "    \n",
    "    # Scan across states\n",
    "    for x in range(1, xmax+1):\n",
    "        output.append(( x, dec[x,t]+1, f[x,t], t ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = pd.DataFrame(output, columns=['x', 'dec', 'f', 't'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the optimal strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAiQAAAFgCAYAAACL0mKXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAFF9JREFUeJzt3X2wrVV9H/DvAS5OoEDUVCOoIdH6iwQGI1rRUgioNWBa\n",
       "tZOxbUY7DYmWF1txBibjC1aHpLUxYhIMXouJb7FJ1ATbGgyt0QglA4loWqzmpw5qnUQzMRm5Cka4\n",
       "vad/nH2bI7333H1PePY65+zPZ2YPz8vee/0us2bf713Petazsrq6GgCAkY4YXQAAgEACAAwnkAAA\n",
       "wwkkAMBwAgkAMJxAAgAMd9ToAg7lopXjD/u+5CvvuDVXnXbmFOWwDekPrKc/sJ7+sHi7V/esHOj4\n",
       "jhwhOenUU0aXwBaiP7Ce/sB6+sPWsSMDCQCwvQgkAMBwAgkAMJxAAgAMJ5AAAMMJJADAcAIJADCc\n",
       "QAIADCeQAADDCSQAwHACCQAwnEACAAwnkAAAwwkkAMBwAgkAMJxAAgAMJ5AAAMMJJADAcAIJADCc\n",
       "QAIADCeQAADDCSQAwHACCQAwnEACAAwnkAAAwwkkAMBwAgkAMJxAAgAMJ5AAAMMJJADAcAIJADCc\n",
       "QAIADCeQAADDCSQAwHACCQAwnEACAAwnkAAAwwkkAMBwAgkAMJxAAgAMd9RUX1xVRyX5lSQnJzk6\n",
       "yc8k+VKSDyT5zOxtb+7u905VAwCwPUwWSJK8IMlXu/ufV9WDk/xRktcmeUN3v3HCdgGAbWbKQPKe\n",
       "JPtHP45Icl+SM5J8f1U9N8lnk7y0u++esAYAYBuYbA5Jd9/T3XdX1XFZCyavSvIHSS7v7nOS3Jnk\n",
       "NVO1DwBsHyurq6uTfXlVPSrJbyV5U3e/o6pO6O67Zucen+QXu/uZG33Hn3zyU6snnXrKZDUCAItx\n",
       "0crx2b26Z+VA56ac1PrwJDcmubS7PzI7fGNVvaS7P5bk6UluP9T3XHXamYfd9u7VPblo5fjD/hw7\n",
       "k/7AevoD6+kPW8eUc0henuQ7k1xZVa9OsprkZUl+vqruTfKVJC+esH0AYJuYLJB092VJLjvAqbOm\n",
       "ahMA2J4sjAYADCeQAADDCSQAwHACCQAwnEACAAwnkAAAwwkkAMBwAgkAMJxAAgAMJ5AAAMMJJADA\n",
       "cAIJADCcQAIADCeQAADDCSQAwHACCQAwnEACAAwnkAAAwwkkAMBwAgkAMJxAAgAMd9ToAgA2a/fd\n",
       "X1ro5xbhomMfNboEGMIICQAwnEACAAwnkAAAwwkkAMBwAgkAMJxAAgAMJ5AAAMMJJADAcAIJADCc\n",
       "lVoBtpCtvIrsZll9lnkYIQEAhhNIAIDhBBIAYDiBBAAYTiABAIYTSACA4QQSAGA4gQQAGE4gAQCG\n",
       "s1IrAJPa6qvPbqY+q88+8IyQAADDTTZCUlVHJfmVJCcnOTrJzyT5VJK3J9mX5JPdfelU7QMA28eU\n",
       "IyQvSPLV7j47yQ8neVOSq5O8orvPSXJEVT1nwvYBgG1iykDyniRXzraPTLI3yRO7++bZsQ8mecaE\n",
       "7QMA28Rkl2y6+54kqarjkrw3ySuT/Ny6t3w9yQlTtQ8AbB+T3mVTVY9K8ltJ3tTdv15VP7vu9HFJ\n",
       "vnao77jyjltz0qmnHHbbu1f3HPZn2Ln0B77NMf4txDqb6A9+UzbnopXjD3puykmtD09yY5JLu/sj\n",
       "s8OfqKqzu/umJOcn+fChvueq08487LZ3r+7Z8A/NctEfdq5N3U56zAnJPXc98MWwPW2yP7jt94E3\n",
       "5QjJy5N8Z5Irq+rVSVaTvDTJNVW1K8mnk7xvwvYBgG1iyjkklyW57ACnfmiqNgGA7cnCaADAcJaO\n",
       "B7atzVzH3726Z3Of2+LLn7NYi+oPyzRXxQgJADCcQAIADCeQAADDCSQAwHACCQAwnEACAAwnkAAA\n",
       "wwkkAMBwAgkAMJyVWgFgi1qmFWGNkAAAwwkkAMBwAgkAMJxAAgAMJ5AAAMMJJADAcHMFkqo6evbf\n",
       "x1bVs6tKkAEAHjCHDBZV9eokb62qRye5KcnLkrxl6sIAgOUxz0jHP0ryoiQ/luRXu/sZSX5w0qoA\n",
       "gKUyz0qtR3b3t6rqR5K8ana55tiJ6wIAFmRRK8JuZJ4Rkt+tqk8mOTprl2w+muQ/T1oVALBUDhlI\n",
       "uvvyJBckObO79yX5V939U5NXBgAsjXkmtT44yZVJPlRVD03yr2fHAAAeEPNcsrkuyR8meWiSryf5\n",
       "cpJfnbIoAGC5zBNIvre7/0OSfd19b3e/MskjJ64LAFgi8wSSvVV1QpLVJKmqv5Nk36RVAQBLZZ7b\n",
       "fl+d5PeSPLqq3p/kqUkunLIoAGC5zBNIvpzkmUmekuTIJP+yu/9s0qoAgKUyTyD5je5+fJLfnroY\n",
       "AGA5zRNIPjV7ns1tSb65/2B33zRZVQBbzEXHPmoh7WyFFTNhhHkCyUOSnDt77bea5LxJKgIAls4h\n",
       "A0l3n5skVXVc1p5r87XJqwIAlsohA0lVfV+SX0/ymCQrVfXFJM/v7s9OXRwAsBzmWYfkLUl+trsf\n",
       "2t0PSfLvsrZ6KwDAA2KeQPJd3f2+/Tvd/Z6szSsBAHhAzBNIvlVVT9y/U1VnJLlnupIAgGUzz102\n",
       "lyX5zar6yyQrWRsd+SeTVgUALJV5AkknedzsdcRs/xFTFgUALJeDBpKqelTWRkRuSHJ+kq/PTj1y\n",
       "duz7J68OAFgKG42QvDZri6GdmGT9qqx7k3xgyqIAgOVy0EDS3RcmSVX9VHf/+8WVBAAsmw3nkFTV\n",
       "aUneMdv+u0lemOTj3f22eRuoqqckeV13n1tVT8ja6MpnZqff3N3v3VTlAMCOsdEckhcmuSrJj1bV\n",
       "MUl+N8kvJDm/qh7Z3Vcd6sur6oqshZhvzA6dkeQN3f3Gv3HlAMCOsdE6JC9L8uTu/ljWQsVHuvtV\n",
       "SX4syT+d8/s/l+R56/bPSPLsqvpoVb21qo7dTNEAwM6yUSA5orv/fLZ9btburEl37533y7v7+qxN\n",
       "gt3vtiRXdPc5Se5M8prDqhYA2JE2mkOyWlVHJ/lbSZ6aZP8k14cmOXKT7b2/u++abV+f5BcP9YEr\n",
       "77g1J516ymE3tHt1z2F/hp1Lf2A9/YFvc8wJoytYHvfcddBTGwWStya5dbZ9Q3ffWVXnJfm32fzD\n",
       "9W6sqpfMLgM9Pcnth/rAVaedediN7F7dk4tWjt9EeexE+gPrbfX+sPvuL40uYbkcc8KGf0myOBvd\n",
       "9vtLVfWHSb47yQdnh09Ksru7377J9i5Ock1V3ZvkK0levMnvAQB2kA1v++3uP7jf/rsOt4Hu/mKS\n",
       "p822P5HkrMP9DgBgZ5vnab8AAJMSSACA4Q4ZSKrql6rqyYsoBgBYThvOIZm5LcnrquphSd6Z5F3d\n",
       "/ZVpywIAlskhR0i6+53d/fQkFyRZSfL7VfWBqnru5NUBAEthrjkkVfW9Sf7F7PW5rC1q9vyqeudk\n",
       "lQEAS+OQl2yq6pYkD8/a5Zof7u7/PTv+jiR/Mm15AMAymGcOyZXd/eH7H5w90+bhD3xJAMCymSeQ\n",
       "vLCqXrBufzXJN5N8Osl13X3vJJUBAEtjnjkke5OckOT9s9d3JHlYkscl2T1daQDAsphnhOQHu/tJ\n",
       "+3eq6r8kua27n19V/2O60gCAZTFPIDm2qr573dojD8vaKMm8nwdgTvdd/s9Gl7BUdl17w6b+n+/6\n",
       "uV+boJrlNk+g+DdJbq+q309yZJInJXlpVb0myX+bsDYAYEnME0j+OMnpSf5+kv+T5MXd/dWq+mh3\n",
       "/+Wk1QEAS2GeQPIb3f34rC2G9v8IIwDAA2WeQPKpqnp11p5p8839B7v7psmqAgCWyjyB5CFJzp29\n",
       "9ltNct4kFQEAS+eQgaS7zz3UewAA/ibmeZbN9yR5a5KTszax9T8mubC7vzBpZQDA0phnpda3JHl9\n",
       "km8k+bMkv5a1B+0BADwg5gkk39Xd/zVJunu1u69Lcvy0ZQEAy2SeQPLNqnpk1iaypqrOSvKtSasC\n",
       "AJbKPHfZvCzJB5I8pqr+KGt33Tx/0qoAtphrLj5rdAlsITttif+tsBT+PHfZfKyqnpy1p/semeSP\n",
       "u/veySsDAJbGvHfZvCRrIyMrs2Pp7gsnrg0AWBLzXLJ5T5KbZ6/VacsBAJbRPIFkV3dfPnklAMDS\n",
       "mucum/9eVf+wqo6evBoAYCnNM0Lyo1mbQ7JaVcnaPJLV7j5yysIAgOUxz102Jy6iEABgeR30kk1V\n",
       "Xbxu+wfud+7npywKAFguG80hedG67Xfd79zZE9QCACypjS7ZrBxkGwDYQRa58uyua2844PF57rJJ\n",
       "rD8CAExoo0AihAAAC7HRJZsfqKo7Z9snrdteSfKIacsCAJbJRoHkcQurAgBYagcNJN39xUUWAgAs\n",
       "r3kntQIATEYgAQCGE0gAgOEEEgBguHme9gtwWK65+KzRJWxoq9cHy2jyQFJVT0nyuu4+t6oek+Tt\n",
       "SfYl+WR3Xzp1+wDA1jfpJZuquiLJdUkeNDt0dZJXdPc5SY6oqudM2T4AsD1MPYfkc0met27/jO6+\n",
       "ebb9wSTPmLh9AGAbmDSQdPf1SfauO7T+qcFfT3LClO0DANvDoie17lu3fVySrx3qA1fecWtOOvWU\n",
       "w25o9+qew/4MO5f+wHoHe/w5y0l/WJz7LrngoOcWHUg+XlVnd/dNSc5P8uFDfeCq08487EZ2r+7J\n",
       "RSvHb6I8diL9YfG28l0su669YcMfRZaL/rB1LDqQXJ7kuqraleTTSd634PYBgC1o8kAye0jf02bb\n",
       "n03yQ1O3CQBsL1ZqBQCG2/IrtW72WvRWvobN4ukPAFubERIAYDiBBAAYTiABAIYTSACA4QQSAGA4\n",
       "gQQAGE4gAQCGE0gAgOEEEgBgOIEEABhOIAEAhhNIAIDhBBIAYDiBBAAYTiABAIYTSACA4QQSAGA4\n",
       "gQQAGE4gAQCGE0gAgOEEEgBgOIEEABhOIAEAhhNIAIDhBBIAYDiBBAAYTiABAIYTSACA4QQSAGA4\n",
       "gQQAGE4gAQCGE0gAgOEEEgBgOIEEABhOIAEAhhNIAIDhBBIAYDiBBAAYTiABAIYTSACA4QQSAGC4\n",
       "o0Y0WlW3J7lrtvv57v6JEXUAAFvDwgNJVT0oSbr7vEW3DQBsTSNGSE5PcmxV3ZjkyCSv7O7bBtQB\n",
       "AGwRI+aQ3JPk9d39rCQXJ3l3VZnLAgBLbEQQ+EySdydJd382yV8kecSAOgCALWJldXV1oQ1W1UVJ\n",
       "TuvuS6vqxCQfSnJqd+870PtX//QLqysnnrzIEgGACdx3yQXZde0NKwc6N2IOyS8neVtV3ZxkX5IL\n",
       "DxZGkmTvT19y2A3suvaG3HfJBZuvkB1Ff2A9/YH19IetY+GBpLvvS/KCRbcLAGxdJpMCAMMJJADA\n",
       "cAIJADCcQAIADCeQAADDCSQAwHACCQAwnEACAAwnkAAAwwkkAMBwAgkAMJxAAgAMJ5AAAMMJJADA\n",
       "cAIJADCcQAIADCeQAADDCSQAwHACCQAwnEACAAwnkAAAwwkkAMBwAgkAMJxAAgAMJ5AAAMMJJADA\n",
       "cAIJADCcQAIADCeQAADDCSQAwHACCQAwnEACAAwnkAAAwwkkAMBwAgkAMJxAAgAMJ5AAAMMJJADA\n",
       "cAIJADCcQAIADCeQAADDCSQAwHACCQAw3FGLbrCqVpJcm+T0JH+V5Ce7+85F1wEAbB0jRkiem+RB\n",
       "3f20JC9PcvWAGgCALWREIDkrye8kSXffluRJA2oAALaQEYHk+CR3rdvfW1XmsgDAEhsRBPYkOW59\n",
       "Dd29b0AdAMAWsbK6urrQBqvqHyf5ke6+sKrOTHJldz/7YO9f/dMvrK6cePLC6gMApnHfJRdk17U3\n",
       "rBzo3MLvsklyfZJnVtUts/0f3+jNe3/6ksNuYNe1N+S+Sy7YRGnsRPoD6+kPrKc/bB0LDyTdvZrk\n",
       "4kW3CwBsXSaTAgDDCSQAwHALn9QKAHB/RkgAgOEEEgBgOIEEABhOIAEAhhNIAIDhBBIAYLgRS8dP\n",
       "pqpWklyb5PQkf5XkJ7v7zrFVMUpV3Z6/frL057v7J0bWwxhV9ZQkr+vuc6vqMUnenmRfkk9296VD\n",
       "i2Ph7tcfnpDkA0k+Mzv95u5+77jqltuOCiRJnpvkQd39tFmnu3p2jCVTVQ9Kku4+b3QtjFNVVyR5\n",
       "YZJvzA5dneQV3X1zVb25qp7T3f9pXIUs0gH6wxlJ3tDdbxxXFfvttEs2ZyX5nSTp7tuSPGlsOQx0\n",
       "epJjq+rGqvrQLKCyfD6X5Hnr9s/o7ptn2x9M8ozFl8RA/19/SPLsqvpoVb21qo4dVBfZeYHk+Pz1\n",
       "EH2S7K2qnfZnZD73JHl9dz8raw9zfLe+sHy6+/oke9cdWv/Y868nOWGxFTHSAfrDbUmu6O5zktyZ\n",
       "5DUj6mLNTvuB3pPkuHX7R3T3vlHFMNRnkrw7Sbr7s0n+IskjhlbEVrD+9+C4JF8bVQhbwvu7+xOz\n",
       "7euTPGFkMctupwWSW5JckCRVdWaSO8aWw0AXJnlDklTViVn7y+fLQytiK/h4VZ092z4/yc0bvZkd\n",
       "78aq2n9p/+lJbh9ZzLLbaZNar0/yzKq6Zbb/4yOLYahfTvK2qro5a/8qvtBoGUkuT3JdVe1K8ukk\n",
       "7xtcD2NdnOSaqro3yVeSvHhwPUvN034BgOF22iUbAGAbEkgAgOEEEgBgOIEEABhOIAEAhhNIAIDh\n",
       "dto6JMAWUVVvSvL3khyd5LFJ/lfWlm5/XJLHdPdXBpYHbDHWIQEmVVXfk+Qj3f19o2sBti4jJMBC\n",
       "VdXnk5yT5Nwkz05y0uz1C0keneS8JF9Ncn5331tVL0xyWdZGV25Pcml33zuidmA65pAAi7Z+WPbJ\n",
       "Sf5BkrOz9uyh3+7u07MWPp5VVackeVGSp3b3E5P8eZIrFlwvsABGSIBFW1m3fUt3353k7qpaTfLh\n",
       "2fEvJnlw1kZRHpvk1qpaSbIryccXWSywGAIJsGjrR0i+7dLLAR6AeGSS93T3ZUlSVcfE7xbsSC7Z\n",
       "AIuwcpDtg71nv99L8ryq+tuzEZLdWZtPAuwwAgmwCKsH2d7wPd39P5O8NmuXcu7IWmh53RQFAmO5\n",
       "7RcAGM4ICQAwnEACAAwnkAAAwwkkAMBwAgkAMJxAAgAMJ5AAAMMJJADAcP8XQDBQj40mgHgAAAAA\n",
       "SUVORK5CYII=\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b869b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl.imshow(output.pivot(index='x', columns='t', values='dec'), \n",
    "          aspect='auto', cmap='Reds', interpolation='nearest', origin='lower')\n",
    "pl.ylabel('Energy Stores'); pl.xlabel('Time');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study: Optimal fire management of a threatened species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will apply dynamic optimization methods implemented in **PyMDPtoolbox**, a Markov decison process (MDP) toolbox for Python. An early application of these methods to wildlife biology was by Possingham and Tuck (1997), which examines the problem of deriving an optimal fire managment strategy for the conservation of endangered vertebrates.\n",
    "\n",
    "The Possingham and Tuck model models the spatial structure of the populations in question, but for simplicity, we will simplify the model to a single patch here.\n",
    "\n",
    "First, we need to specify the dimensions of the problem. In the Possingham and Tuck problem, there are seven population abundance classes (`pop_classes`), including exctinction (0), there are 13 fire classes (`fire_classes`), which represent the number of years since the last burn. The system state is made up of all pairwise combinations of population and fire classes. Since there is no population structure in this problem, there are only two possible actions, `burn` or `no_burn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_pop_classes = 7\n",
    "n_fire_classes = 13\n",
    "\n",
    "states = [(p, f) for p in range(n_pop_classes) for f in range(n_fire_classes)]\n",
    "n_states = len(states)\n",
    "\n",
    "no_burn, burn = 0, 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input validation\n",
    "\n",
    "The key to reliable scientific computing is to write tests for all the important steps in your program. To facilitate this, we need test functions to validate the inputs to various functions that we will define. We’re going to want to send the action, population class, fire class, and a probability as input to multiple functions. Each of these functions will raise an exception for invalid entries, and let us know what was passed to the function, versus what was expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_action(x):\n",
    "    \"\"\"Check that the action is in the valid range.\"\"\"\n",
    "    if not x in [0,1]:\n",
    "        msg = \"Invalid action '%i', it should be in {0, 1}.\" % x\n",
    "        raise ValueError(msg)\n",
    "\n",
    "def check_population_class(x):\n",
    "    \"\"\"Check that the population abundance class is in the valid range.\"\"\"\n",
    "    if not (0 <= x < n_pop_classes):\n",
    "        msg = \"Invalid population class '%i', it should be in {0, 1, …, %d}.\" \\\n",
    "              % (x, n_pop_classes - 1)\n",
    "        raise ValueError(msg)\n",
    "\n",
    "def check_fire_class(x):\n",
    "    \"\"\"Check that the time in years since last fire is in the valid range.\"\"\"\n",
    "    if not (0 <= x < n_fire_classes):\n",
    "        msg = \"Invalid fire class '%i', it should be in {0, 1, …, %d}.\" % \\\n",
    "              (x, n_fire_classes - 1)\n",
    "        raise ValueError(msg)\n",
    "\n",
    "def check_probability(x, name=\"probability\"):\n",
    "    \"\"\"Check that a probability is between 0 and 1.\"\"\"\n",
    "    if not (0 <= x <= 1):\n",
    "        msg = \"Invalid %s '%i', it must be in [0, 1].\" % (name, x)\n",
    "        raise ValueError(msg)\n",
    "        \n",
    "def check_states(x):\n",
    "    if not (0 <= x < n_states):\n",
    "        msg = \"Invalid index '%i', it should be in {0, 1, …, %d}.\" % (x, STATES - 1)\n",
    "        raise ValueError(msg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Habitat suitability\n",
    "\n",
    "The core of our habitat model is a simple relationship between habitat suitability and the number of years since the last fire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_habitat_suitability(years):\n",
    "    \"\"\"The habitat suitability of a patch relatve to the time since last fire.\n",
    "\n",
    "    The habitat quality is low immediately after a fire, rises rapidly until\n",
    "    five years after a fire, and declines once the habitat is mature. See\n",
    "    Figure 2 in Possingham and Tuck (1997) for more details.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    years : int\n",
    "        The time in years since last fire.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    r : float\n",
    "        The habitat suitability.\n",
    "\n",
    "    \"\"\"\n",
    "    if years < 0:\n",
    "        msg = \"Invalid years '%s', it should be positive.\" % str(years)\n",
    "        raise ValueError(msg)\n",
    "    if years <= 5:\n",
    "        return 0.2*years\n",
    "    elif years <= 10:\n",
    "        return -0.1*years + 1.5\n",
    "    else:\n",
    "        return 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the form of this relationship by passing a range of values to `get_habitat_suitability`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAisAAAFkCAYAAADhSHsMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmcFPWd//HXXByD3AyHB4KAH1FAFA/kEBTM4W3UKJqY\n",
       "NTHGHLvZnL81uskmUbNroknWJJvDRCUJHqh4i4lyeiLgLXwAuQQUBgSGa2CG6d8f1Q3NONPTwNRU\n",
       "dff7+XjwYLpruubDF2b6Q1V96l2USCQQERERiaviqAsQERERyUTNioiIiMSamhURERGJNTUrIiIi\n",
       "EmtqVkRERCTW1KyIiIhIrIXerJjZqWY2vYHnzzOzOWb2gpldE3YdIiIikptCbVbM7HvAn4DW9Z4v\n",
       "BW4HxgNjgWvNrCLMWkRERCQ3hX1kZQlwUQPPDwQWu3uVu9cAzwOnh1yLiIiI5KBQmxV3nwLUNrCp\n",
       "A7A57fEWoGOYtYiIiEhuKo3o61YRNCwp7YFNmV6QSCQSRUVFoRYlEqZNW3Zy3X8/y7bqWoqLi7ju\n",
       "osF8ekTfqMsSEYnCfr2ht1SzUr+oBUB/M+sEbCc4BfTzjDsoKqKycktI5eW+ior2Wp8M4rA+dz+9\n",
       "gG3VtYw94TDm+Tp+99CbvPf+Ri4d25/i4uga8TisTZxpfRqntclM69O4ior2+/X5LTW6nAAwswlm\n",
       "do271wLfBv4BvADc6e4ftFAtIi1u+YdVzH7jAw6raMeVZw3ghqtOolfXcp6Z8z6/nfIWO3ftjrpE\n",
       "EZHYKsqh1OWEOtTGqYPPLMr1SSQS/Oxv81myejPfu3woA/t0AWBbdQ2/m/I2C1ZspE/P9vzbJUPo\n",
       "dEjrJvbW/PRvJzOtT+O0NplpfRpXUdF+vw4n66ZwIiF7+d21LFm9mWFWsadRAWjXpoxvffZ4Rg3u\n",
       "xfIPt3DTxLmsWrc1wkpFROJJzYpIiKp31TJ5+hLKSou57Iz+H9teWlLM1Wcfw8VjjuKjqp3c8rd5\n",
       "vL10QwSViojEl5oVkRA9+dIKNm3dxadO6U23Tm0b/JyioiLOOa0P111wHLW7E/xq8ptMf211C1cq\n",
       "IhJfalZEQrJu43aembOSLh1ac/ZpRzb5+acM7MH3J5xAeZtS/vqMc/+0xdTlzjVlIiKhUbMiEpL7\n",
       "py2hdneCz57Rn9ZlJVm9pv/hHbnxC3snhX435W121mhSSEQKm5oVkRC8s+wjXlu8nqOP6MTJx3Tf\n",
       "r9d279SWH3x+GMf07sT8RZX8z9/ns3nrzpAqFRGJPzUrIs2sdncdk55dRFERXDF+AAdy5+V2bcr4\n",
       "9mVD950UqtSkkIgUJjUrIs1s2vzVfLBhO2OGHkbvHvt3l8Z0qUmhz5x+FBuqdnLLXzUpJCKFSc2K\n",
       "SDOq2r6LR59fRnnrUi4affC5P0VFRZw7Yt9JoRmaFBKRAqNmRaQZPTxzKTt21nLh6L60L2/VbPtN\n",
       "nxSaqEkhESkwalZEmkmQ/7OGw7q144wTD2v2/fc/vCM3XjWMnl00KSQihUXNikgzSCQSTHp2MQmC\n",
       "i2pLisP51ureuZwbrto7KXTrJE0KiUj+U7Mi0gxeeXctS1ZtZtjR++b/hCE1KTRycE+WfaBJIRHJ\n",
       "f2pWRA5S9a5aJs94L8j/OfPj+T9hKC0p5otnD9wzKfSzv83j7WWaFBKR/KRmReQgPfnSCjZu2Zkx\n",
       "/ycMqUmhr5x/HDW1CX71wJvMeF2TQiKSf9SsiByEdZt28Myc9+ncvjVnD286/ycMpx6bNik01Xlg\n",
       "2hJNColIXlGzInIQ7n9uMbW764L8n1bZ5f+EIX1SaOqclZoUEpG8omZF5ADtyf85vCOnDNy//J8w\n",
       "aFJIRPKVmhWRA7BP/s9ZRx9Q/k8YNCkkIvlIzYrIAZieyv85/tCDyv8JQ2pS6CJNColInlCzIrKf\n",
       "qrbv4pFU/s/pR0VdToOKioo4T5NCIpIn1KyI7Kew8n/CcOqxPfjehKF7J4Wma1JIRHKPmhWR/bDi\n",
       "wy2h5v+EYcDhnfZOCr2ykv/TpJCI5Bg1KyJZSiQS/P3ZRSSACSHm/4She+dyfvD5YFJoniaFRCTH\n",
       "5M5PW5GIpef/HBty/k8YDmmbnBQapEkhEcktalZEsrBz124mz3iP0pJiPttC+T9hKC0p5ovn7Dsp\n",
       "NN/XRV2WiEhGalZEsvDky8uD/J9Te1PRgvk/YUhNCl17/rHU1Cb48Z0vM1OTQiISY2pWRJqwbtMO\n",
       "pr4S5P+cE1H+TxiGH9uT700YSrs2ZdyjSSERiTE1KyJNiEv+TxgGHN6JX3xzND1Sk0KPaFJIROJH\n",
       "zYpIBu8sj1f+TxgO7XYIN3x+GHZEJ+Z5JbdOek2TQiISK2pWRBpRu7uOe59dTBEwYXx88n/CcEjb\n",
       "Mr5z+VBGDOrJsg+quGniPFZrUkhEYkLNikgjps9fzZr12xgz9FCO7Bmv/J8wlJYU86VzBnLR6L5s\n",
       "qKrmlr/N451lH0VdloiImhWRhuRC/k8YioqKOG9k3+SkUB2/fOANTQqJSOTUrIg0YMqsIP/nghzI\n",
       "/wlDMCl0AuVtSrlnqjNZk0IiEiE1KyL1rPhwC7NeX8Oh3dpxxgm5kf8ThgGHd+KGq4bRo0s5T2tS\n",
       "SEQipGZFJE39/J/SksL+FunRufzjk0LbdkVdlogUmML+SSxSzysLgvyfE4+u4LgczP8Jw8cmhe6Z\n",
       "q0khEWlRalZEknbu2s3k6UH+z2U5nP8ThgYnhZZrUkhEWoaaFZGkfMr/CUP9SaFfPfAGs95YE3VZ\n",
       "IlIA1KyIkL/5P2EYfmxPvnv5CbRtXcrdTy9k8gxNColIuNSsiAAPTFtC7e46Lj2jX97l/4Th6CPS\n",
       "JoVeXsnvH3mbXZoUEpGQqFmRgvfO8o+Yv6iSAYd35NSBPaIuJ2ekJoWOPqITc72S/9GkkIiERM2K\n",
       "FLT0/J8r8jz/JwyHtC3jO5cN5bTj0iaF1m+LuiwRyTNqVqSgTX8tyP85vUDyf8JQVlrMNecO5MLU\n",
       "pNBf52pSSESalZoVKVhV23fxyOxltC2w/J8wFBUVcf7Ivlx7niaFRKT5qVmRgpXK/7lwdF86FGD+\n",
       "TxiGH6dJIRFpfmpWpCAp/yc8eyaFOrfVpJCINAs1K1JwEokEk5T/E6oencu54aqT9kwK3XqvJoVE\n",
       "5MDpp7QUnFcWrGXxqs2cMKCb8n9ClD4ptHRNFTdP1KSQiBwYNStSUPbJ/xk3IOpy8l76pND6zdXc\n",
       "8ldlConI/lOzIgXlyZdXJPN/jqC78n9axL6TQrs1KSQi+03NihSMIP9nZTL/p0/U5RSc+pNCD854\n",
       "T5NCIpIVNStSMPbk/4xV/k9U0ieFnnp5Bb9/9B1NColIk9SsSEF4fdE65i+qpP/hHTn1WOX/RGmf\n",
       "SaGF67j13teo0qSQiGRQGtaOzawI+B1wPFANXOPuS9O2Xwl8G6gF7nL334dVixS22t11/PGRtykC\n",
       "rlT+TyykJoXufnoBL72zlpsmzuWblx7PYd3aRV2aiMRQmEdWLgRau/sI4Hrg9nrbfw6cCYwCvmNm\n",
       "HUOsRQrY9NdW8/7aLYw+Xvk/cRJMCh3LhaP2Tgq9q0khEWlAmM3KKGAqgLu/ApxUb/sbQGcgNZKh\n",
       "K+2k2W3ZvotHZy+jXZtSPjNG+T9xU1RUxPmj+vLl5KTQLzUpJCINCO00ENAB2Jz2uNbMit29Lvn4\n",
       "HWAesBV42N2rmtphRYX+V5yJ1ufjHnjwDbbvrOXLFwyi35Fdoy4ntqL+t3P+2Pb0692Fm++aw91P\n",
       "L2Trzt18/tMDKS6Oxym7qNcnzrQ2mWl9mkeYzUoVkP63tKdRMbPBwDnAkcA24O9mdrG7P5Rph5WV\n",
       "W8KqNedVVLTX+tSz4sMtPPPScg7t1o6zR/bV+jQiLv92urdvxQ8+dyK/mvwGD05bzPI1m7nmnIG0\n",
       "Kot2cisu6xNHWpvMtD6N298mLszTQC8AZwOY2XDgrbRtm4HtwE53TwDrCE4JiTSLffJ/xin/J1f0\n",
       "6LLvpNDPNSkkIoTbrEwBdprZC8BtwLfMbIKZXePuK4E/As+b2SygI3B3iLVIgZmzYN3e/J++yv/J\n",
       "JXszhXrw3poqblKmkEjBC+00UPKIyVfrPb0obfsfgD+E9fWlcO3ctZsHpi9R/k8OS00K9ehcziPP\n",
       "L+OWv87j6xcN4lgFT4oUJB0bl7yTyv/55CnK/8llmhQSkRQ1K5JXKtPzf047MupypBmclswUatOq\n",
       "RJlCIgVKzYrklfT8nzatwhx2k5Z09BGduPGqk5QpJFKg1KxI3nh3+UfMU/5P3tKkkEjhUrMieWF3\n",
       "XR33PrtY+T95rqFJoTWaFBLJe2pWJC9Mn7+a1eu3Kf+nAKQmhS5IZgrdrEwhkbynZkVyXtX2XTwy\n",
       "exltWyv/p1AUFRVxwai+fPncvZNCszUpJJK31KxIzntk1lK276zlglF96VDeKupypAWdNmjvpNBd\n",
       "Ty/koZmaFBLJR2pWJKetXLuFma+voVfXcs488bCoy5EIpE8KPfmSJoVE8pGaFclZiUSCSf8M8n+u\n",
       "GH+08n8K2J5JocM7alJIJA/pp7vkrDkL1rFI+T+SdEjbMr5z+QmaFBLJQ2pWJCftzf8p4rIz+0dd\n",
       "jsSEJoVE8pOaFclJT+3J/+lN987lUZcjMaJJIZH8o2ZFck7lph08/cpKOh3SSvk/0qjTBvXkO5cN\n",
       "1aSQSB5QsyI5Z0/+zxn9lf8jGVnvztx41Ul016SQSE5TsyI5ZUEq/+ewjgxX/o9koUeXcm7UpJBI\n",
       "TlOzIjljd10dk1L5P2cp/0eyl5oUGq5JIZGcpGZFcsbe/J9eyv+R/VZWWsyXNSkkkpPUrEhO2JKe\n",
       "/3N6v6jLkRyVPim0q0aTQiK5Qs2K5IQps5ftzf9pp/wfOThBppAmhURyhZoVib2Va7cw87XVyv+R\n",
       "ZlV/UugPmhQSiS01KxJr6fk/E8YPUP6PNKvUpNCAwzvyqiaFRGJLP/kl1l5duDf/Z1DfrlGXI3no\n",
       "kLZlfFeTQiKxpmZFYkv5P9JSUpNC54/ss2dSaIEmhURiQ82KxNZTL6/goyrl/0jLKCoq4sLRR3HN\n",
       "uQPZVbOb2zUpJBIbule5xNL6TTuYOkf5P9LyRgzqRdcObfjNw29x19ML2bprN5886XCKdRNCkcjo\n",
       "yIrE0v3Tl1BTq/wfiUb6pNDk5xZrUkgkYmpWJHYWLP+Iea78H4lWjy7l3PD5YRzbt4smhUQipmZF\n",
       "YmV3XR2Tngvyf644a4DyfyRS7ctbcdN1IzQpJBIxNSsSKzNeW8PqyiD/p0/PDlGXI0JZaYkmhUQi\n",
       "pmZFYiPI/1mq/B+JnQYnhd7UpJBIS1GzIrExZfYytlXXcsHIPsr/kVgaMajX3kyhp5QpJNJS1KxI\n",
       "LKxcu4WZryfzf4YdHnU5Io2y3p25IS1T6I+PaVJIJGxNNitm9t9mVpr2uKeZPR5uWVJIEokEk55d\n",
       "TCKh/B/JDT2Tk0IDDu/InAXr+Pl9r1G1XZNCImHJ5l2hCzDHzI41s88Bc4Dp4ZYlheTVhetY9P4m\n",
       "hvZX/o/kjvblrYJMoWN78N7qKm66R5NCImFpsllx92uBW4E3gJ8DY9z99rALk8Kws2Zv/s/l45T/\n",
       "I7mlrLSYL5+3d1LoFk0KiYQim9NAVxM0KTcAU4HJZjY07MKkMDyt/B/JcalJoS+dM5CdmhQSCUU2\n",
       "9zG/DjjL3RcCmNk5wCNAnxDrkgKwftMOnn5F+T+SH0YO7kW3jslMoacWsm7jDi46/ShlCok0g2yu\n",
       "WTnN3ReaWWcAd38SOD7csqQQ7Mn/Gav8H8kP1rszP/j8MLp32jspVFOrSSGRg5VNszLYzBYCb5jZ\n",
       "YWa2BNAdu+SgLFixkXleSb/DOjD8OOX/SP7o1bUdN1w1jP7JSaFb79WkkMjByqZZuQO4CNjg7quB\n",
       "rwK/D7UqyWu76+qY9OyiIP9n/NHK/5G80768Fd+7fOieSaGbJ87lgw2aFBI5UNk0K+XuviD1wN3/\n",
       "CbQOryTJd6n8n1FDetG3l/J/JD+VlZbsmRSq3FTNzRPnsWDFxqjLEslJ2TQrH5nZ8UACwMyuBDSb\n",
       "Jwdk646aZP5PCReP0dlEyW8fmxS6/3Wef/ODqMsSyTnZXNX4VeAe4Dgz2wQsBj4XalWSt6bMWsq2\n",
       "6louP7O/8n+kYKRPCv3lqQWs27SdC0drUkgkW9ncFO49dx9FcCfb3u5+srt7+KVJvlm5dgszlP8j\n",
       "BSp9UuiJFzUpJLI/Gj2yYmbTSZ76qfc8AO5+ZnhlSb7ZJ/9nnPJ/pDClJoXuePgt5ixYx0dVO/nG\n",
       "xYPpUK6jjCKZZHrH+C/gx8Aa4D3gh8APgLeAJaFXJnlln/yfo5T/I4UrNSl06rE9WLJ6syaFRLLQ\n",
       "6JEVd58JYGa/cPeT0za9bGZzQ69M8kZ6/s9lyv8Roay0hGvPO5bundry+IvLuXniPL7xmcEcc2Tn\n",
       "qEsTiaVsjsW3NbOjUw/MbDBQFl5Jkm9S+T+fOLk3PZT/IwIEk0IXnb53Uui2+1/nhbc0KSTSkGym\n",
       "gb4NzDCz1UAJUAFcEWpVkjfWbw7yfzoq/0ekQSMH96Jrhzb8dspb/PnJBazduIOLRvfVzRJF0mQz\n",
       "DfQPgtDC64BrgL7uPjvkuiRPPDAtyP/57Nj+tG2t/B+RhhxzZDApVNGpDU+8uJw/aFJIZB9NvnuY\n",
       "2ZHANwhGl4uSz+HuXwy5NslxC1ZsZK7yf0SyEkwKncRvHtKkkEh92Vyz8gBBkzIbmJn2S6RRyv8R\n",
       "2X8dylvxvQlDOWVgd00KiaTJ5rh8mbt/d393bGZFwO+A44Fq4Bp3X5q2/WTgtuTDD4HPubuiSfOE\n",
       "8n9EDkxZaQnXnn8c3TuX88SLy7nlr/P4+kWaFJLCls2RlefN7Dwz299jkRcCrd19BHA9cHu97X8E\n",
       "/sXdTwemArr6Mk8o/0fk4BQXFfGZ5KRQ9S5NColk06xcAjwKVJtZXfJXNld+jSJoQnD3V4CTUhuS\n",
       "o9AbgG+b2Qygi7sv3t/iJZ5S+T/nj+xLR+X/iBywkYN78Z3LhtK6rIQ/P7mAh2ctJZH42I3FRfJe\n",
       "k6eB3P3QA9x3B2Bz2uNaMyt29zqgG3Aa8DVgKfCEmc119xkH+LUkJt5ft5UZr6+mZ5dyxin/R+Sg\n",
       "HXNkZ264ahi/mvwGT7y4nMpNO/ji2cdQVloSdWkiLSZTNtC17v5HM/thQ9vd/SdN7LsKaJ/2ONWo\n",
       "QHBUZYm7L0p+rakER15mZNphRUX7TJsLXtTrk0gkuH3yGyQScN3FQ+jVs2Ok9dQX9frEmdYms6jX\n",
       "p6KiPb/8VmduvmsOr7y7lqrtNdxw9Sl0PKR1pHWlapPGaX2aR6YjK0X1ft9fLwDnAg+a2XCCTKGU\n",
       "pcAhZnZU8qLb0cCdTe2wsnLLAZaS/yoq2ke+Pq8uXMfb721gaP9u9O5aHnk96eKwPnGltcksTuvz\n",
       "75cM5s9PLmDOgnV8+5cz+ealQ+jVtV1k9cRpbeJI69O4/W3iisI6/5k2DTQk+dTVwDCgnbvfaWZj\n",
       "gf9JbnvR3b/VxC4T+ktvXNTfFDtrdnPDn16matsufnrNqbG7rX7U6xNnWpvM4rY+dYkEj8xexhMv\n",
       "Lqddm9JIJ4XitjZxo/VpXEVF+/06EBLaLUXdPQF8td7Ti9K2zwBODevrS8tK5f+cPfzI2DUqIvkk\n",
       "NSnUvVNb7pm6kNvuf51/+fQxjBzcK+rSREKTzTSQSEbK/xFpeaOG7DspNEWTQpLHmmxWzOx7Ztaz\n",
       "JYqR3JTK/7l0bD/l/4i0oNSkUEWnNjz+4nL++Pi7yhSSvJTNkZW2wEwze9LMLjWzsrCLktyxJ//n\n",
       "0A4MP049rUhLS2UK9T+sI6+8u5af3/c6W7brZuCSX7JJXf6JuxvwM+AM4A0z+42ZDQ29Oom13XV1\n",
       "3JvK/znraIqV/yMSiX0yhVZt5uaJ85QpJHklq2tWzKwc6AscBdQBG4H/NbOfhVibxNyM19awqnIb\n",
       "I5X/IxK5VKbQuSOOZN2mHdzy13n4yo1RlyXSLLK5ZuXvwHvAWOAmdx/k7v8JnAV8JdzyJK6U/yMS\n",
       "P8GkUD++eHaQKfSL+5QpJPkhm6shnwOudfc9xxTNrJW77zSzY8MrTeJsyuwg/+eyM/sr/0ckZkYN\n",
       "6UXXjm347cNv8ecnF1C5aQcXjOpLkU7VSo7K5jTQl+s1KsXAPAB3/zCswiS+3l+3lRmvKf9HJM4G\n",
       "pk0KPfbCcv6kSSHJYZmygaYRnPrBzOrSNtUCj4VblsRVIpFg0j8XkUjAhPEDKC3RrXpE4io1KXTH\n",
       "Q2/y8rtr2VBVzTc+M5j25ToaKrml0WbF3c8EMLNfu/s3W64kibO5Xom/v4mh/bsx+KiuUZcjIk3o\n",
       "UN6K7084YU+m0M0T5/Hvnz2enl10p2nJHZmOrJzr7k8A883sqvrb3X1iqJVJ7Oys2c0D0xZTWlLE\n",
       "ZeP6R12OiGQpNSnUvXNbnnhxBTdPnMs3PjMY6x1NppDI/sp0DP/k5O9jCe6vUv+XFJinX17Bhqqd\n",
       "nHXyEcr/EckxqUmhq88+Zs+k0Itva1JIckOm00A/Sv5+dcuVI3GVnv9z7ml9oi5HRA7Q6CGH0q1j\n",
       "W3778Fvc+cQC1m3UpJDEX6bTQMuARlOx3P2oUCqSWHpg+nvK/xHJE6lJoV8+8AaPvbCcdRt3cPXZ\n",
       "Aykr1QXzEk+Z3nXGtlQREm8LVmxk7sJ1yv8RySO9urbjxi9oUkhyQ6Y2erC7rwDGNPJLCkAq/weU\n",
       "/yOSb1KTQqcM7M7iVZu5+a/z+PCj7VGXJfIx2Vxg29DFtWPDLUviYubrQf7PKOX/iOSl1KTQOacd\n",
       "ybqNO7h54lxlCknsZH2BrZl1AHa5e3UL1SYR27qjhimzlP8jku+Ki4q4eEw/unduy8Spzi/ue52r\n",
       "zz6GEYN6RV2aCJBdkOEgM5sPLAVWmdnzZqaLawtAKv/nvBF9lf8jUgBGDzmUb3/2eFqXlXDnEwt4\n",
       "ZPZSEolG5yxEWkw2l37/AbjB3bu5ezfgNuCucMuSqKXn/4w/Sfk/IoViYJ8u3HDVMLp1TGYKPfEu\n",
       "NbV1Tb9QJETZNCtt3f3p1AN3nwLo4oU8lkgkuPdZ5f+IFKrUpFC/wzrw8jtrue2+19i6oybqsqSA\n",
       "ZbrPSu/kh2+Y2X8AfyYIMbwSmN0CtUlE5nolC1du4vh+XZX/I1KgOpS34nuXn8BfngoyhW6aOJd/\n",
       "v1SZQhKNTPdZmUlwU7gigumfr6RtSwD/Fl5ZEpVU/k9JcRGXjxsQdTkiEqFWZcGkUEWntjz5kjKF\n",
       "JDqZpoH6tmQhEg9TX1nJhqqdfHp4b3rof1AiBa+hSaEvnj2Q0wbpBpHScpq8b7qZGfA14BCCoywl\n",
       "QF93Pz3k2qSFrd+8g6deXqH8HxH5mNFDDqVbhzb8dsrb/OmJd1m7cTvXXDQk6rKkQGQT8nI/8Cgw\n",
       "Grgb+DTwdog1SURS+T+XjFH+j4h83MA+XfjB54fxq8lBptCHG6up6Ng66rJiq7y8Fdu374q6jFi6\n",
       "7pKh+/X52bwjFbv7j8ysDJhPMMr84gHUJjG2MC3/R4d3RaQxh3Zrx41XncQdD7/JnHc/jLocyVFh\n",
       "NCvbzaw1sAgY5u7Pm1mbAylO4ml3XR2TlP8jIlnq0K4V/++KE9myq44NG7ZFXU5sdepUzqZNylpq\n",
       "Dtk0K38DHicYWX7JzD4FrA61KmlRe/J/Biv/R0SyU1pSzNG9O1LZVqeMG1NR0Z7KyrKoy8gLTd7t\n",
       "y91/A1zs7pUEI8x/BC4MuS5pIfvk/4xV/o+IiMRPNtlAL7n7FgB3XwU8BrwSdmHSMh5R/o+IiMRc\n",
       "pjvYTiM4koKZpQdD1BI0LJLj3l+3lenK/xERkZjLdFO4MwHM7Nfu/s2WK0lagvJ/REQkV2Q6snKu\n",
       "uz8BzDezq+pvd/eJoVYmoZqn/B8REckRmS7jPhl4guSpoAaoWclRO2t2c7/yf0REJEdkOg30o+Tv\n",
       "V7dcOdIS9uT/nKr8HxERib9ssoGWEaQs78PdjwqlIgnVnvyfdq04d0SfqMsRERFpUjZ38xmb9nEZ\n",
       "cBGgMIgctSf/55PK/xERkdzQ5LuVu6+o99TPzWwucFM4JUlYUvk/Ryn/R0REckg2p4FOT3tYBBwH\n",
       "tA2tIglFkP+zGIArlf8jIiI5JJvzAD9O+zgBrAe+EE45EpZZr69hVeVW5f+IiEjOyeY00Bnpj82s\n",
       "g7tXhVeSNLetO2p4eNZS2rQq4eIxui5aRERySzangc4FRgM/BV4FKszsR+7+27CLk+aRyv/57Bn9\n",
       "6XiIro0WEZHcks091n8E3AVcDswB+gC690qOWKX8HxERyXFZBcK4+0LgHOAxd98KKJ43ByQSCSYl\n",
       "838uH6f8HxERyU3ZvHutNbM7gJOAqWZ2G7Ay3LKkOaTyf4b068qQfsr/ERGR3JRNszKB4FqVM9x9\n",
       "G7A0+ZzEWHr+zwTl/4iISA7LZhpoC2mhhbqwNjco/0dERPKFLmLIQxs2V/O08n9ERCRPqFnJQw9M\n",
       "X8Ku2jouGav8HxERyX1NNitm9lADzz0XTjlysHzlRl5V/o+IiOSRRv/bbWZTgOOBQ81sab3XvB92\n",
       "YbL/dtfV8fd/Bvk/V4xX/o+IiOSHTOcIvgB0AX4N/Fva87XA2jCLkgOTnv9z1KHK/xERkfzQaLOS\n",
       "zP+pAi4wsxOAQwhSl0uATwJ/ybRjMysCfkdwdKYauMbdlzbweX8ANrj7Dw70DyGwZfsu5f+IiEhe\n",
       "yuaalXuAB4BHgFuAx4HLstj3hUBrdx8BXA/c3sC+vwIM2p+CpWF/n7qQbdW1nD+yr/J/REQkr2Qz\n",
       "DXQ6cCwwGbgWOJXsbrc/CpgK4O6vENwBdw8zOw04GfjDftQrDVi1bitPv7iMHsr/ERGRPJRNs7LG\n",
       "3WuABcAQd38HaJ/F6zoAm9Me15pZMYCZ9SQISPwGwaklOUCp/J+6BExQ/o+IiOShbG7CsdrMrgee\n",
       "BW41MwiuX2lKFfs2NcXuXpf8+FKgK/AU0Atoa2YL3X0iGVRUZNMjFZYX3ljDwpWbOGlgD8YN7xN1\n",
       "ObGmfz+N09pkpvVpnNYmM61P88imWfkScI67v2pmDxPkAl2XxeteAM4FHjSz4cBbqQ3ufgdwB4CZ\n",
       "fQGwphoHdFIEAAATc0lEQVQVgMrKLVl82cKxq2Y3f3rkLUqKi/jyBYO0PhlUVLTX+jRCa5OZ1qdx\n",
       "WpvMtD6N298mLptzBt9w9/sgaDLc/QLgE1m8bgqw08xeAG4DvmVmE8zsmv2qUBoV5P9U84mTj+DQ\n",
       "imwOdomIiOSeTDeF+2+gO3C+maXH9pYCw4GMo8bungC+Wu/pRQ183j1ZVyt7bNhczVPK/xERkQKQ\n",
       "6TTQQwRTQOOAmWnP1wI/DbMoaVoq/+fzn1T+j4iI5LdMN4V7FXjVzKYkbxAnMZHK/+nbS/k/IiKS\n",
       "/zKdBprv7icCm8wskbapCEi4e0no1cnH1NUlmPRskP9z5VnK/xERkfyX6cjKicnfdeOOGJn5xhre\n",
       "X7eVkYN7Kv9HREQKQpMXO5hZGcGo8ligBvgn8JfkBbTSgrbuqOHhme/RplUJl4zpF3U5IiIiLSKb\n",
       "KzN/S3A32rsJTgF9ARgCfDO8sqQhj85exrbqWj57Rn/l/4iISMHIplkZ7u5DUg/M7AngjfBKkoas\n",
       "WreV6a+tVv6PiIgUnGyuR1ltZkelPT4U+CCkeqQBe/N/EkwY11/5PyIiUlAyTQNNBxJABfCGmc0C\n",
       "dhOkKb/dMuUJwDyvZOHKTQzp15Uh/bpFXY6IiEiLynQa6L8aef62EOqQRuyq2c3905ZQUlzE5eMG\n",
       "NP0CERGRPJNpdHnPXWvN7ASCpOUioAToy753tZWQTJ0T5P986tTe9OxSHnU5IiIiLS6b0eV7gBFA\n",
       "F2ABMJQgUfkv4ZYmGzZX89RLK+jQrhXnKf9HREQKVDZXap5OkBE0GbgWOBVoFWZREpg8I8j/uXSs\n",
       "8n9ERKRwZdOsrHH3GoKjKkPc/R2gfbhlia/cyJwFyv8RERHJ5r/rq83seuBZ4FYzg+D6FQlJev7P\n",
       "FWcNUP6PiIgUtGyOrHwJWJZMYX4YmAB8NdSqCtye/J9BPel3aMeoyxEREYlUk0dW3H0LcF/y4zuA\n",
       "O8IuqpBtq65hyqyltGlVwsVjlf8jIiKS6aZwdQQ3hauvCEi4e0loVRWwR2YvY+uOGi49ox+dlP8j\n",
       "IiKS8T4re04Rmdlr7n5Cy5RUuFZVbmX6/NX06NyWs046IupyREREYiHbkJmGjrBIM0okEtz77OIg\n",
       "/2f8AOX/iIiIJGX7jqhxlJDNX1TJghUblf8jIiJSj46sxIDyf0RERBqX6QLbZextUg4zs6XJj1MX\n",
       "2B4VdnGFYuqclazfXM2nTlH+j4iISH2ZRpfHtlQRheyjqrT8n5F9oi5HREQkdjJNA61oyUIK1QPT\n",
       "g/yfz31C+T8iIiIN0chJhNLzf0YMVv6PiIhIQ9SsRET5PyIiItlRsxKRWcr/ERERyYqalQhsq67h\n",
       "4VlLaa38HxERkSapWYlAKv/n/BF9lP8jIiLSBDUrLSw9/2e88n9ERESapGalBaXn/1w+bgBlpVp+\n",
       "ERGRpujdsgWl8n8GH9WV4/sr/0dERCQbalZayL75P/2jLkdERCRnqFlpIc8k83/OOukIenVtF3U5\n",
       "IiIiOUPNSgv4qKqaJ19W/o+IiMiBULPSAh6YvoRdNXVcPOYo5f+IiIjsJzUrIVv0/qZk/k97Rg7u\n",
       "FXU5IiIiOUfNSojq6hJM+uciAK4462jl/4iIiBwANSshmvXmGlau28oI5f+IiIgcMDUrIdlWXcPD\n",
       "M4P8n0uU/yMiInLA1KyE5FHl/4iIiDQLNSshWF25lWnzV9Nd+T8iIiIHTc1KM0skEkxS/o+IiEiz\n",
       "0TtpM5u/aP3e/J9+XaMuR0REJOepWWlGNbW7uX/a4j35P0UaVRYRETloalaa0dQ577N+czXjTzpc\n",
       "+T8iIiLNRM1KM/moqponX1pOh3atOH9k36jLERERyRtqVprJ5BnvKf9HREQkBGpWmsGi9zfxyrtr\n",
       "lf8jIiISAjUrB6muLsGkZ5P5P+OV/yMiItLc1KwcpFlvrmHl2mT+z2HK/xEREWlualYOgvJ/RERE\n",
       "wqdm5SA8+nyQ/3Oe8n9ERERCE9rYipkVAb8DjgeqgWvcfWna9gnAN4Ea4C13/1pYtYRhdeVWps0L\n",
       "8n/OUv6PiIhIaMI8snIh0NrdRwDXA7enNphZG+AnwBh3Hw10MrNzQ6ylWSUSCe59Tvk/IiIiLSHM\n",
       "d9lRwFQAd38FOClt205ghLvvTD4uJTj6khNeW7yed5dvZNBRXZT/IyIiErIw717WAdic9rjWzIrd\n",
       "vc7dE0AlgJn9K9DO3Z9taocVFe3DqXQ/7KrZzeQZ71FSXMTXLhlK9+7R15QSh/WJM61P47Q2mWl9\n",
       "Gqe1yUzr0zzCbFaqgPS/pWJ3r0s9SF7TciswAPhMNjusrNzSrAUeiMdfXM7aj7bzyVOOoE1xPGqC\n",
       "4BsiLrXEkdancVqbzLQ+jdPaZKb1adz+NnFhNisvAOcCD5rZcOCtetv/COxw9wtDrKFZ7cn/KS/j\n",
       "vBHK/xEREWkJYTYrU4CzzOyF5OOrkxNA7YB5wNXAbDObDiSAX7v7oyHWc9AeTOb/XDn+aMrbKP9H\n",
       "RESkJYT2jpu8LuWr9Z5e1BJfOwyL3t/Ey++upU/P9owcovwfERGRlqKZ2yyk5/9ceZbyf0RERFqS\n",
       "mpUszE7m/5x2nPJ/REREWpqalSZsr67hoZlLaV2m/B8REZEoqFlpwiOp/J+RfejcXvk/IiIiLU3N\n",
       "Sgar129T/o+IiEjE1Kw0IpFIcO+zi4L8nzOV/yMiIhIVvQM3Yp/8n/7K/xEREYmKmpUG1NTu5r7n\n",
       "FlNSXMSEcQMo0qiyiIhIZNSsNOCZOe+zfnM144YdTq+u7aIuR0REpKCpWanno6pqnngpyP85f6Ty\n",
       "f0RERKKmZqWeVP7PxWP6Kf9HREQkBtSspFm8Svk/IiIicaNmJamuLsGkfy4G4Arl/4iIiMSGmpWk\n",
       "2W+uYcXaLZx2XE/6K/9HREQkNtSsoPwfERGROFOzAjz6/HK27qjh3BFHKv9HREQkZgq+WVm9fhvP\n",
       "zVtF905t+cTJvaMuR0REROop6GYlkUhwXyr/Z5zyf0REROKooN+dX1+8nneWb2RQX+X/iIiIxFXB\n",
       "Nis1tbu5b1oy/2e88n9ERETiqmCblWfmvE/lJuX/iIiIxF1BNisbt+zkyZdWKP9HREQkBxRkszJ5\n",
       "xhJ21uzmM8r/ERERib2Ca1YWr9rEy++s5cie7Rml/B8REZHYK6hmJT3/58rxyv8RERHJBQXVrDz/\n",
       "1gfJ/J8e9D9c+T8iIiK5oGCale3VNTw4471k/k//qMsRERGRLBVMs6L8HxERkdxUEM3KmvXbmDY/\n",
       "lf9zRNTliIiIyH7I+2YlkUhw73OL2V2X4LJx/SkrLYm6JBEREdkPed+svL54Pe8s+4jj+nZhaP9u\n",
       "UZcjIiIi+ymvm5V98n/GKf9HREQkF+V1s/KPV/fm/xzaTfk/IiIiuShvm5WNW3byxIsraF9exvkj\n",
       "+0RdjoiIiBygvG1WUvk/F4/pR3mbsqjLERERkQOUl83KPvk/g5X/IyIiksvyrln5WP5PsS6qFRER\n",
       "yWV516yk8n+GK/9HREQkL+RVs7K9uoaHZgb5P5cq/0dERCQv5FWz8tgLy9myXfk/IiIi+SRvmpU1\n",
       "67fx3LxVVHRqo/wfERGRPJIXzUp6/s/lZw5Q/o+IiEgeyYtm5fUlafk/A5T/IyIikk9yvlmpqd3N\n",
       "fc8p/0dERCRf5Xyzksr/OfNE5f+IiIjko5xuVtLzfy4Y1SfqckRERCQEOd2sPKj8HxERkbyXs83K\n",
       "klWbeemdtRzZQ/k/IiIi+Swnm5W6RIK/P7sIgCvOGqD8HxERkTyWk83K829+wIoPg/yfAYd3iroc\n",
       "ERERCVHONSvK/xERESksOdespPJ/zjlN+T8iIiKFIKealfT8n0+eovwfERGRQlAa1o7NrAj4HXA8\n",
       "UA1c4+5L07afB/wnUAPc5e53Ztqf8n9EREQKU5hHVi4EWrv7COB64PbUBjMrTT4eD4wFrjWzikw7\n",
       "m/POh0H+T5/Oyv8REREpIGE2K6OAqQDu/gpwUtq2gcBid69y9xrgeeD0TDv782PvUFxUxOXjj1b+\n",
       "j4iISAEJs1npAGxOe1xrZsWNbNsCdMy0sw82bOPMYYdxmPJ/RERECkpo16wAVUD7tMfF7l6Xtq1D\n",
       "2rb2wKZMO3v8tgt0OKUJFRXtm/6kAqb1aZzWJjOtT+O0NplpfZpHmEdWXgDOBjCz4cBbadsWAP3N\n",
       "rJOZtSI4BfRSiLWIiIhIjipKJBKh7DhtGmhI8qmrgWFAO3e/08zOAX4EFAF/dvffh1KIiIiI5LTQ\n",
       "mhURERGR5pBTN4UTERGRwqNmRURERGJNzYqIiIjEmpoVERERibUw77PSLJrKGCp0yeiCvwB9gFbA\n",
       "ze7+eKRFxYyZdQfmAuPdfVHU9cSJmf0HcD5QBvzO3e+KuKRYSH5f3UPwfVULfFn/dgJmdirw3+5+\n",
       "hpn1A+4G6oC33f3rkRYXsXprMxT4X4J/PzuBq9y9MtICI5a+PmnPXQF8IxnN06hcOLLSaMaQAPA5\n",
       "YL27nw58GvhNxPXESvJN5/fA9qhriRszGwOclvzeGgsoynyvs4ESdx8J/BS4JeJ6YsHMvgf8CWid\n",
       "fOp24AfuPgYoNrMLIisuYg2sza+Ar7v7mcAU4D+iqi0OGlgfzOwE4IvZvD4XmpVMGUMCDxCkV0Pw\n",
       "91kTYS1x9Avg/4A1URcSQ58E3jazR4DHgCciridOFgGlySO7HYFdEdcTF0uAi9IeD3P32cmPnyYI\n",
       "py1U9dfmMndP3Qy1FNjR8iXFyj7rY2ZdgZuAb2bz4lxoVjJlDBU8d9/u7tvMrD0wGbgh6priwsz+\n",
       "BVjn7v8kuPmg7KsbwY0aLwG+CkyKtpxY2Qr0BRYCfyA4nF/w3H0KwWmNlPTvqyYz3vJZ/bVx97UA\n",
       "ZjYC+Drwy4hKi4X09Um+h98JfBvYRhY/n3PhTT9TxpAAZnYEMA24x93vj7qeGLkaOMvMpgNDgYnJ\n",
       "61cksAF4xt1rk9djVJtZt6iLiolvAVPd3Qiul5uYjAaRfaX/LG4y463QmNllBNdcnu3uG6KuJ0ZO\n",
       "BPoTHPW+FxhoZhkv8Yj9BbYEGUPnAg82kDFU8MysB/AMwbnR6VHXEyfJ8+gAJBuWr7j7ughLipvn\n",
       "gX8DfmlmhwLlBA2MwEfsPaW6ieBnZUl05cTWfDM73d1nEVwzNy3qguLCzD4HXAuMdXc1cXsVuftc\n",
       "YDCAmR0J3Ovu3870olxoVqYQ/O/4heTjq6MsJoauBzoB/2lmPwQSwKfdfWe0ZcWOciXqcfcnzWy0\n",
       "mc0hOAz7NXfXOgV+BfzFzGYRTEpd7+6Ffs1BQ74L/MnMyggCah+MuJ5YSJ7m+DWwAphiZglgprv/\n",
       "ONrKYuGAfsYoG0hERERiLReuWREREZECpmZFREREYk3NioiIiMSamhURERGJNTUrIiIiEmtqVkRE\n",
       "RCTW1KyIFBAzu8PMJtd77hNmtsTM2kVQTy8zCy2TyMyWmVnvsPYvIi1DzYpIYfkP4EQzOwfAzMoJ\n",
       "bgd+tbtva+li3P0Ddz83xC+hG0mJ5AHdFE6kwJjZOODPwLHAT4GEu3/XzE4GbgfaAusJ4glWmNkY\n",
       "gnTUtkBn4Pvu/pCZ3QV0BfoB3wfGEqTu7gYec/efNPB1/4cgT2YjMIEgT2aGu/dN7m8zQbjiYcBP\n",
       "3P1uM+ucrPcYoBr4jrtPN7NPAT8muBP3MuDL7r6x3tdcBswgyPfZkfwzvZ38WtPdfWLy8+rcvdjM\n",
       "fgQMB44AfgNcBswBRhMEP/6ruz9zoGsvIgdGR1ZECoy7P0eQJ3UXQXNxQ/J26X8CJrj7SQRNy53J\n",
       "l3wd+FLy+WuAH6btbr27H0eQ2fVpdz8BGAn0byD47waCZuEU4HGCMDPY9+jH4e4+Gjgf+EXyuZuA\n",
       "xe5+LHAVcFMycPFnwCfcfRjwD+DWxv/IfmJyPxMb+Zz0Glq7+yB3/33ycZm7jyBIiL25kdeLSIjU\n",
       "rIgUpu8CnwC+kcyROprgCMljZvYawRGQPsnP/Tww2MxuBL4DHJK2n1eSv68GtpvZ8wSJxTe6+656\n",
       "X/NR4BEzuwNY6O7PNlDXPwDc/W2CozgApwN/TT3v7iOBU4HewPRkvV9P1t+QPydf+zTQ28w6NLoq\n",
       "+/6ZUqYmf0+vSURakJoVkQLk7lsITsWsSD5VArzn7icmj46cSHDqA4J05pOBuQRHForSdrUjub/d\n",
       "BKdPbgS6AC+bWf96X/PXwBhgMXCrmV3fQGnVDTxXk/7AzCxZ7+y0ek8GLm3kj1tb7/EugiMpRcn9\n",
       "ldXbXj+wMFXTnteISMtSsyJSuNLfeBcCXcxsVPLxNcCk5PUi/YEfuvtU4JMEjcI+zGwoMBOY5e7f\n",
       "B94FrN7nvAx0cPf/BX7J3tNAjTUAqednAZcn93EM8DTB0Y/TzGxA8nN+BPy8kf1cmXztRQRHdKoJ\n",
       "rsk5Lrn9wkZel6kmEWlBpVEXICKR2XOdhrvvMrNLgf81s9ZAFXCVu280szuBd81sM/AS0NbM2tZ7\n",
       "/etm9iLwjpltA14jaCrSXQ/cbWa1wHbgunp11L/aP/X4R8CfzOx1gqMsn3P3tWb2ReABMysGVgGf\n",
       "a+TPeHTyVFEV8IXk8/8H3J/c5zRgTVNr1MhjEWkBmgYSERGRWNNpIBEREYk1NSsiIiISa2pWRERE\n",
       "JNbUrIiIiEisqVkRERGRWFOzIiIiIrGmZkVERERi7f8DTY2cDGSkKLIAAAAASUVORK5CYII=\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109819b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = range(15)\n",
    "pl.plot(list(t), [get_habitat_suitability(ti) for ti in t])\n",
    "pl.xlabel('Years since burn')\n",
    "pl.ylabel('Habitat suitability index');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System states\n",
    "\n",
    "Recall from the discussion of state transition matrices that we can project a state vector into the next state by multiplying it by a matrix of transition probabilities. Each row in the matrix represents a state that the system can start in, while the columns represent the states that the system can transition to. `PyMDPtoolbox` handles state transitions exactly in this way, by matrix multiplication. We will specify one transition probability matrix for each action, `no_burn` and `burn`. PyMDPtoolbox expects a NumPy array as the data structure, since it has fast, built-in methods for performing linear algebra operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reward function\n",
    "\n",
    "Here, the reward function returns a chosen measure of habitat quality. Depending on the implementation of the MDP, a reward function can be in terms of just the state, or as a function of state-action pairs. For this example, we only need to specify reward as a function of state. The reward is simple: where the population is still extant, the state recieves a one, otherwise it is zero.\n",
    "\n",
    "### State space representation\n",
    "\n",
    "Functionally, each state is uniquely identified by an index into the transition probability matrix, but in the real world, we think of the state as a tuple containing the population abundance class and the number of years since the last fire. Therefore we need functions to crosswalk between these two representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def state_to_index(population, fire):\n",
    "    \"\"\"Convert state parameters to transition probability matrix index.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    population : int\n",
    "        The population abundance class of the threatened species.\n",
    "    fire : int\n",
    "        The time in years since last fire.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    index : int\n",
    "        The index into the transition probability matrix that corresponds to\n",
    "        the state parameters.\n",
    "\n",
    "    \"\"\"\n",
    "    check_population_class(population)\n",
    "    check_fire_class(fire)\n",
    "    return population*n_fire_classes + fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_to_index(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def index_to_state(index):\n",
    "    \"\"\"Convert transition probability matrix index to state parameters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    index : int\n",
    "        The index into the transition probability matrix that corresponds to\n",
    "        the state parameters.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    population, fire : tuple of int\n",
    "        ``population``, the population abundance class of the threatened\n",
    "        species. ``fire``, the time in years since last fire.\n",
    "\n",
    "    \"\"\"\n",
    "    if not (0 <= index < n_states):\n",
    "        msg = \"Invalid index '%i', it should be in {0, 1, …, %d}.\" % (index, n_states - 1)\n",
    "        raise ValueError(msg)\n",
    "    population = index // n_fire_classes\n",
    "    fire = index % n_fire_classes\n",
    "    return (population, fire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_state(43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State transitions\n",
    "\n",
    "The dynamics of the transition probabilities are given in Section 2.1 and Figure 1 of Possingham and Tuck (1997):\n",
    "\n",
    "![figure 1](http://fonnesbeck-dropshare.s3.amazonaws.com/Screen-Shot-2015-03-15-16-25-39.png)\n",
    "\n",
    "Transition probabilities are calculated row-wise, since each row represents the transitions from the state corresponding to that row to all other states. Hence, it must sum to one.\n",
    "\n",
    "The first component of the state dynamics is the fire state transition, which resets the fire class to zero if burning is performed, or advances to the next fire state if no burning is performed (until the highest fire class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transition_fire_state(F, a):\n",
    "    \"\"\"Transition the years since last fire based on the action taken.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    F : int\n",
    "        The time in years since last fire.\n",
    "    a : int\n",
    "        The action undertaken.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    F : int\n",
    "        The time in years since last fire.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ## Efect of action on time in years since fire.\n",
    "    \n",
    "    if a == burn:\n",
    "        # When the patch is burned set the years since fire to 0.\n",
    "        return 0\n",
    "    \n",
    "    elif (a == no_burn) and (F < n_fire_classes - 1):\n",
    "        # Increase the time since the patch has been burned by one year.\n",
    "        # The years since fire in patch is absorbed into the last class\n",
    "        return F + 1\n",
    "    \n",
    "    else:\n",
    "        return F\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the abundance transistion dynamics depends on the current abundance: if the abundance is zero, the population is extinct, and stays that way; if the abundance is in its largest state, it can stay there with probability $1−(1−s)(1−r)$, or drop with a probability $(1−s)(1−r)$; if the abundance is at an intermediate state, it can stay in that state with probability $s$, increase with probability $(1-s)r$, or drop with a probability $(1−s)(1−r)$.\n",
    "\n",
    "The following function returns the transition probabilities, calling `transition_fire_state` to get the new fire state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_transition_probabilities(s, x, F, a):\n",
    "    \"\"\"Calculate the transition probabilities for the given state and action.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s : float\n",
    "        The class-independent probability of the population staying in its\n",
    "        current population abundance class.\n",
    "    x : int\n",
    "        The population abundance class of the threatened species.\n",
    "    F : int\n",
    "        The time in years since last fire.\n",
    "    a : int\n",
    "        The action undertaken.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    prob : array\n",
    "        The transition probabilities as a vector from state (``x``, ``F``) to\n",
    "        every other state given that action ``a`` is taken.\n",
    "\n",
    "    \"\"\"\n",
    "    # Check that input is in range\n",
    "    check_probability(s)\n",
    "    check_population_class(x)\n",
    "    check_fire_class(F)\n",
    "    check_action(a)\n",
    "\n",
    "    # a vector to store the transition probabilities\n",
    "    prob = np.zeros(n_states)\n",
    "\n",
    "    # the habitat suitability value\n",
    "    r = get_habitat_suitability(F)\n",
    "    F = transition_fire_state(F, a)\n",
    "\n",
    "    ## Population transitions\n",
    "    if x == 0:\n",
    "        # population abundance class stays at 0 (extinct)\n",
    "        new_state = state_to_index(0, F)\n",
    "        prob[new_state] = 1\n",
    "    elif x == n_pop_classes - 1:\n",
    "        # Population abundance class either stays at maximum or transitions\n",
    "        # down\n",
    "        transition_same = x\n",
    "        transition_down = x - 1\n",
    "        # If action 1 is taken, then the patch is burned so the population\n",
    "        # abundance moves down a class.\n",
    "        if a == burn:\n",
    "            transition_same -= 1\n",
    "            transition_down -= 1\n",
    "        # transition probability that abundance stays the same\n",
    "        new_state = state_to_index(transition_same, F)\n",
    "        prob[new_state] = 1 - (1 - s)*(1 - r)\n",
    "        # transition probability that abundance goes down\n",
    "        new_state = state_to_index(transition_down, F)\n",
    "        prob[new_state] = (1 - s)*(1 - r)\n",
    "    else:\n",
    "        # Population abundance class can stay the same, transition up, or\n",
    "        # transition down.\n",
    "        transition_same = x\n",
    "        transition_up = x + 1\n",
    "        transition_down = x - 1\n",
    "        # If action 1 is taken, then the patch is burned so the population\n",
    "        # abundance moves down a class.\n",
    "        if a == burn:\n",
    "            transition_same -= 1\n",
    "            transition_up -= 1\n",
    "            # Ensure that the abundance class doesn't go to -1\n",
    "            if transition_down > 0:\n",
    "                transition_down -= 1\n",
    "        # transition probability that abundance stays the same\n",
    "        new_state = state_to_index(transition_same, F)\n",
    "        prob[new_state] = s\n",
    "        # transition probability that abundance goes up\n",
    "        new_state = state_to_index(transition_up, F)\n",
    "        prob[new_state] = (1 - s)*r\n",
    "        # transition probability that abundance goes down\n",
    "        new_state = state_to_index(transition_down, F)\n",
    "        # In the case when transition_down = 0 before the effect of an action\n",
    "        # is applied, then the final state is going to be the same as that for\n",
    "        # transition_same, so we need to add the probabilities together.\n",
    "        prob[new_state] += (1 - s)*(1 - r)\n",
    "\n",
    "    # Make sure that the probabilities sum to one\n",
    "    assert (prob.sum() - 1) < np.spacing(1)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we loop over the states and actions, getting the transition probabilities and fill in the transition probability matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_transition_and_reward_arrays(s):\n",
    "    \"\"\"Generate the fire management transition and reward matrices.\n",
    "\n",
    "    The output arrays from this function are valid input to the mdptoolbox.mdp\n",
    "    classes.\n",
    "\n",
    "    Let ``S`` = number of states, and ``A`` = number of actions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s : float\n",
    "        The class-independent probability of the population staying in its\n",
    "        current population abundance class.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out : tuple\n",
    "        ``out[0]`` contains the transition probability matrices P and\n",
    "        ``out[1]`` contains the reward vector R. P is an  ``A`` × ``S`` × ``S``\n",
    "        numpy array and R is a numpy vector of length ``S``.\n",
    "\n",
    "    \"\"\"\n",
    "    check_probability(s)\n",
    "\n",
    "    # The transition probability array\n",
    "    transition = np.zeros((2, n_states, n_states))\n",
    "    # The reward vector\n",
    "    reward = np.zeros(n_states)\n",
    "    # Loop over all states\n",
    "    for idx in range(n_states):\n",
    "        # Get the state index as inputs to our functions\n",
    "        x, F = index_to_state(idx)\n",
    "        # The reward for being in this state is 1 if the population is extant\n",
    "        if x != 0:\n",
    "            reward[idx] = 1\n",
    "        # Loop over all actions\n",
    "        for a in (0,1):\n",
    "            # Assign the transition probabilities for this state, action pair\n",
    "            transition[a][idx] = get_transition_probabilities(s, x, F, a)\n",
    "\n",
    "    return (transition, reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mdptoolbox import mdp\n",
    "\n",
    "def solve_mdp():\n",
    "    \"\"\"Solve the problem as a finite horizon Markov decision process.\n",
    "\n",
    "    The optimal policy at each stage is found using backwards induction.\n",
    "    Possingham and Tuck report strategies for a 50 year time horizon, so the\n",
    "    number of stages for the finite horizon algorithm is set to 50. There is no\n",
    "    discount factor reported, so we set it to 0.96 rather arbitrarily.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sdp : mdptoolbox.mdp.FiniteHorizon\n",
    "        The PyMDPtoolbox object that represents a finite horizon MDP. The\n",
    "        optimal policy for each stage is accessed with mdp.policy, which is a\n",
    "        numpy array with 50 columns (one for each stage).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    return sdp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we solve the problem using backward induction via the `FiniteHorizon` class in `mdptoolbox`. Following Possingham and Tuck (1996), we set the number of stages to 50. We also set $\\gamma=0.96$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mdptoolbox import mdp\n",
    "\n",
    "P, R = get_transition_and_reward_arrays(0.5)\n",
    "sdp = mdp.FiniteHorizon(P, R, 0.96, 50)\n",
    "sdp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the model populates a `policy` attribute for the `sdp` object, from which we can extract a table that has the population class as rows, and the years since a fire as the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAh4AAAFgCAYAAAD0A3BmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAF1JJREFUeJzt3XmwJWV5x/HvvXcG9DJwXSiNKJuaehJX3EDQgCCIEFRQ\n",
       "IhUFlYDK4lpuoEJE4hIlblEcCxUHg1ZQAXeMKIIg7hgB8VHcS4wI6sXJddjm5I8+g1dyl+7x9HvO\n",
       "6fl+qqbm9Ll9+n3OU8zMj7ff7p7o9XpIkiSVMDnsAiRJ0qbD4CFJkooxeEiSpGIMHpIkqRiDhyRJ\n",
       "KsbgIUmSilkx7AJuMzc7uOt677AK1q0d2OE2GfatOXvW3AB7dtQW2w7kOKPuhMu/yskPfOSwyxgr\n",
       "9qy5Qfdsde+GiYXe7+aMx+TUsCsYT/atOXvWnD1r7J4PuN+wSxg79qy5Uj3rZvCQJEkjyeAhSZKK\n",
       "MXhIkqRiDB6SJKkYg4ckSSrG4CFJkooxeEiSpGIMHpIkqRiDhyRJKsbgIUmSijF4SJKkYgwekiSp\n",
       "GIOHJEkqxuAhSZKKMXhIkqRiDB6SJKmYFW0ePCKOA54IrAROzczT2xxPkiSNttZmPCJiD2DXzNwN\n",
       "eAywbVtjSZKk8dDmjMe+wBURcS6wJfCyFseSJEljoM3gsTWwHXAAcG/gE8DftDieJEkacRO9Xq+V\n",
       "A0fEG4BrM/Ot/e3vAHtn5nULfmD9rT0mp1qpRZIklXPUxFas7t0wsdDP2pzxuBh4AfDWiNgGmAau\n",
       "X3TvdWsHN/L0DMzNDu54mwr71pw9a26APTtqi01j6djq3g0cNbHVsMsYK/asuVI9a21xaWZ+Grgs\n",
       "Ir4OfBw4JjPbmV6RJEljodXLaTPzuDaPL0mSxos3EJMkScUYPCRJUjEGD0mSVIzBQ5IkFWPwkCRJ\n",
       "xRg8JElSMQYPSZJUjMFDkiQVY/CQJEnFGDwkSVIxBg9JklSMwUOSJBVj8JAkScUYPCRJUjEGD0mS\n",
       "VIzBQ5IkFWPwkCRJxUz0er1h11CZmx1cIdMzMDc7sMNtMuxbc/asOXvWnD1rzp41N+ieTc9MLPS2\n",
       "Mx6SJKkYg4ckSSrG4CFJkooxeEiSpGIMHpIkqRiDhyRJKsbgIUmSijF4SJKkYgwekiSpGIOHJEkq\n",
       "xuAhSZKKMXhIkqRiDB6SJKkYg4ckSSrG4CFJkooxeEiSpGIMHpIkqZgVbR48Ir4FzPY3f5KZR7Q5\n",
       "niRJGm2tBY+I2BwgM/dqawxJkjRe2pzxeDCwRUR8DpgCXpWZX2txPEmSNOLaXOMxB7w5M/cFjgbO\n",
       "jAjXlEiStAlrMwj8ADgTIDN/CFwP3KPF8SRJ0ohr81TLPwEPBI6NiG2ALYFfLbr3HVbB5NTgRp+e\n",
       "GdyxNiX2rTl71pw9a86eNWfPmhtUz+ZmF/3RRK/XG8wgtxMRK4HTge2B9cArMvOri35gbnZwhUzP\n",
       "LPmltQj71pw9a86eNWfPmrNnzQ26Z9MzEwu93dqMR2beDBza1vElSdL4cbGnJEkqxuAhSZKKMXhI\n",
       "kqRiDB6SJKkYg4ckSSrG4CFJkooxeEiSpGIMHpIkqRiDhyRJKsbgIUmSijF4SJKkYgwekiSpGIOH\n",
       "JEkqxuAhSZKKMXhIkqRiDB6SJKkYg4ckSSrG4CFJkooxeEiSpGIMHpIkqRiDhyRJKsbgIUmSijF4\n",
       "SJKkYgwekiSpGIOHJEkqxuAhSZKKMXhIkqRiDB6SJKkYg4ckSSrG4CFJkooxeEiSpGIMHpIkqRiD\n",
       "hyRJKsbgIUmSijF4SJKkYgwekiSpmBVtDxARdwO+CeydmT9oezxJkjS6Wp3xiIgVwGpgrs1xJEnS\n",
       "eGj7VMspwLuBa1oeR5IkjYHWgkdEPAu4NjM/D0y0NY4kSRofbc54HA7sExEXADsBZ/TXe0iSpE3U\n",
       "RK/Xa32Qfvh47pKLS9ff2mNyqvVaJElSy+ZmYXpmwbMdrV/V0rd8ulm3dnCjTc9UX1rN2Lfm7Flz\n",
       "9qw5e9acPWuuUM9qBY+I2Cwzb4qI+wIBfDYz19cdJDP32tgCJUlSdyy7xiMiTgTeGxHbARcBLwbe\n",
       "03ZhkiSpe+osLn0i8GzgacB/ZObewENarUqSJHVSneAxlZk3AgcAn4mISWCLdsuSJEldVCd4fCEi\n",
       "rgA2ozrVciHwiVarkiRJnbRs8MjMlwL7A7v2F5Q+LzNf0XplkiSpc+osLt0ZOBiYioj/As6PiKe0\n",
       "XpkkSeqcOqda3kH1dNmDqR729lDguDaLkiRJ3VQneExm5kXA3wMfy8xfUO7GY5IkqUPqBI+5iHgJ\n",
       "8FjgUxHxQuAP7ZYlSZK6qE7weDrV5bNPzszfAdsA/9hqVZIkqZPqXNXyS+CTVItLdwfOA/ZtuzBJ\n",
       "ktQ9y67ViIg1wG7AXYCrqB5xfwnw/nZLkyRJXVPnVMvuwP2AjwDPAXahupmYJElSI3WCxzWZeTPV\n",
       "bMeDMvNKYMt2y5IkSV1U57LYX0bE8cD5wJsiAmBVq1VJkqROqjPjcQTwk8z8BnA21RUtR7dalSRJ\n",
       "6qRFZzwiYrt5m1/pb3+8/0uSJKmxpU61XAj0gIl5723Y7gH3brEuSZLUQYsGj8zcccPriFiZmTdH\n",
       "xEpg88xcW6Q6SZLUKXWeTvsPwLf7m9sBV0XEk1qtSpIkdVKdxaUnAHsDZOaPgIcBJ7VZlCRJ6qY6\n",
       "wWOzzPz1ho3MvJY/X/chSZJUS537eFwcER8GzuxvPxW4tL2SJElSV9UJHscCzweeC9wMXASc2mZR\n",
       "kiSpm5YNHpl5I3BK/5ckSdJGq7PGQ5IkaSAMHpIkqZg6azyIiB2A+wPnAdtl5k/aLEqSJHVTnRuI\n",
       "HQJ8EngHcFfg0og4tO3CJElS99Q51fIKYDfghv49PB4CHN9qVZIkqZPqBI9bM/MPGzYy81fA+vZK\n",
       "kiRJXVVnjceVEfE8YGVE7AQcA3yn3bIkSVIX1ZnxOBa4J/BH4H3ALFX4kCRJaqRO8FgHXJqZjwD2\n",
       "Ba4C1rZalSRJ6qQ6weO9wFPmbe8JrG6nHEmS1GV11ng8PDMfCJCZ1wGHRcR32y1LkiR1UZ3gMRkR\n",
       "9+hfzUJE3I2aV7VExCRwGhD9zxyVmd/b2GIlSdJ4qxM8XgdcFhEXAxPAzsALax7/CUAvMx8dEXsA\n",
       "rwcO3KhKJUnS2Ft2jUdmfgh4KPBhYA2wc2aeXefgmflx4Dn9zR2A321cmZIkqQuWnfGIiDsBBwF3\n",
       "oZrx2CkiyMzX1hkgM9dHxAeoZjoO/gtqlSRJY26i1+stuUNEfJ7q3h1XALftnJknNRmovzbk68Df\n",
       "ZuYf/98O62/tMTnV5JCSJGkUzc3C9MzEQj+qs8bjrzJzn40Zt/8wuXtl5hup7gdyK4stTF03wFuD\n",
       "TM9UX1rN2Lfm7Flz9qw5e9acPWuuUM/q3Mfjsoh40EYe/2zgIRFxIfBZ4IWZeeNGHkuSJI25OjMe\n",
       "D6AKH7+mmrWYoLpS5d7LfTAz54BD/rISJUlSV9QJHge1XoUkSdok1Ake/wPsD6yimu2YAnYETmyx\n",
       "LkmS1EF1gsfZwDRwX+DLwO7ApW0WJUmSuqnO4tIA9gLOAd5EdefSe7ZZlCRJ6qY6wePXmdkDvg88\n",
       "KDOvATZvtyxJktRFdU61XBkR/w68GzgzIrYBVrZbliRJ6qI6Mx5HA2f1nyp7InAP4GmtViVJkjpp\n",
       "0RmPiNh9ge1Z4GNUz22RJElqZKlTLRuexXJX4D7AV6hueb4bcDnwqHZLkyRJXbNo8MjMPQEi4jPA\n",
       "kzPz6v729sB7ypQnSZK6pM4aj+03hI6+nwPbt1SPJEnqsDpXtXwrItYAZ1EFladR3UhMkiSpkTrB\n",
       "40jg+cBRQA84Hzi1zaIkSVI3LRs8MvOmiDiNasZjov/2NlSnXCRJkmpbNnhExCuB44DrqWY8Jvq/\n",
       "37vd0iRJUtfUOdVyBHCfzPxN28VIkqRuq3NVy8+B37ZdiCRJ6r46Mx4/BC6OiAuAdRvezMzXtlaV\n",
       "JEnqpDrB45f9X/CnxaWSJEmN1bmq5aTl9pEkSaqjzlUt66muYpnvmszctp2SJElSV9WZ8bhtAWpE\n",
       "rAQOBHZtsyhJktRNda5quU1m3pyZHwH2aqkeSZLUYXVOtTxj3uYEcH/gptYqkiRJnVXnqpY9573u\n",
       "AdcBh7RTjiRJ6rI6azwOB4iIrYCbMnPdMh+RJElaUJ1TLQ8AzgC2629/H3hmZv6o5dokSVLH1Flc\n",
       "+h7gVZm5dWZuDfwb8P52y5IkSV1UJ3jcMTM/u2EjM88BtmqvJEmS1FWLnmqJiO36L/87Io4D3gfc\n",
       "Ajwd+HKB2iRJUscstcbjQqqrWCaAxwDPnbe9OfCCtouTJEndsmjwyMwd52/371r6FKoAsnPLdUmS\n",
       "pA6qc1XLjlRh41nAnYHXAU9ttyxJktRFS63xOAg4CngocA5wGHBaZr62UG2SJKljlprx+BjwEWDX\n",
       "zLwabntSrSRJ0kZZKng8iOr0ysUR8VPgw8vsL0mStKSJXq+35A4RMQUcQBVC9gfOB96VmZ9Z5nMr\n",
       "qG40tgOwGfC6zPzkoh+Ym126kCamZ2BudmCH22TYt+bsWXP2rDl71pw9a27QPZuemVjo7WVvIJaZ\n",
       "t2bmxzPzIOBewBeAN9QY8lDguszcHdgPeGeDciVJUgc1OnWSmb8B3tL/tZyzqNaIQBVwbm5WmiRJ\n",
       "6prW1mxk5hxARGxJFUBe1dZYkiRpPCy7xuMvERHbAmcD78zMNUvuvP7WHpNTrdUiSZIKmZtddI1H\n",
       "azMeEXF34HPAsZl5wbIfWLd2cIO7qGjj2Lfm7Flz9qw5e9acPWuuUM/avDz2eOBOwAkRcSLVc172\n",
       "y8wbWxxTkiSNsDbXeLwIeFFbx5ckSeNn2ctpJUmSBsXgIUmSijF4SJKkYgwekiSpGIOHJEkqxuAh\n",
       "SZKKMXhIkqRiDB6SJKkYg4ckSSrG4CFJkooxeEiSpGIMHpIkqRiDhyRJKsbgIUmSijF4SJKkYgwe\n",
       "kiSpGIOHJEkqxuAhSZKKMXhIkqRiDB6SJKkYg4ckSSrG4CFJkooxeEiSpGIMHpIkqRiDhyRJKsbg\n",
       "IUmSijF4SJKkYgwekiSpGIOHJEkqxuAhSZKKMXhIkqRiDB6SJKkYg4ckSSrG4CFJkooxeEiSpGIM\n",
       "HpIkqZhiwSMidomIC0qNJ0mSRs+KEoNExMuAw4C1JcaTJEmjqdSMx9XAQYXGkiRJI6pI8MjMc4Bb\n",
       "SowlSZJGV5FTLbXcYRVMTg3ueNMzgzvWpsS+NWfPmrNnzdmz5uxZc4Pq2dzsoj8qHTwmFv3JugEu\n",
       "/5ieWfJLaxH2rTl71pw9a86eNWfPmivUs9KX0/YKjydJkkZIsRmPzPwZsFup8SRJ0ujxBmKSJKkY\n",
       "g4ckSSrG4CFJkooxeEiSpGIMHpIkqRiDhyRJKsbgIUmSijF4SJKkYgwekiSpGIOHJEkqxuAhSZKK\n",
       "MXhIkqRiDB6SJKkYg4ckSSrG4CFJkooxeEiSpGIMHpIkqRiDhyRJKsbgIUmSijF4SJKkYgwekiSp\n",
       "GIOHJEkqxuAhSZKKMXhIkqRiDB6SJKkYg4ckSSrG4CFJkooxeEiSpGIMHpIkqRiDhyRJKsbgIUmS\n",
       "ijF4SJKkYgwekiSpGIOHJEkqxuAhSZKKMXhIkqRiVrR58IiYAE4FHgysA47MzB+3OaYkSRpdbc94\n",
       "HAhsnpm7AccDb2l5PEmSNMLaDh6PBs4DyMyvAQ9veTxJkjTC2g4eWwGz87ZviQjXlUiStIlqdY0H\n",
       "cAOw5bztycxcv+Ced1gFk1ODG3l6ZnDH2pTYt+bsWXP2rDl71pw9a25QPZubXfRHbQePS4ADgI9G\n",
       "xCOByxfdc93awY06PbPkl9Yi7Ftz9qw5e9acPWvOnjVXqGdtB49zgH0i4pL+9uEtjydJkkZYq8Ej\n",
       "M3vA0W2OIUmSxocLPSVJUjEGD0mSVIzBQ5IkFWPwkCRJxRg8JElSMQYPSZJUjMFDkiQVY/CQJEnF\n",
       "GDwkSVIxBg9JklSMwUOSJBVj8JAkScUYPCRJUjEGD0mSVIzBQ5IkFWPwkCRJxRg8JElSMQYPSZJU\n",
       "zESv1xt2DZIkaRPhjIckSSrG4CFJkooxeEiSpGIMHpIkqRiDhyRJKsbgIUmSilkx7AIGKSImgFOB\n",
       "BwPrgCMz88fDrWq0RcQK4P3ADsBmwOsy85NDLWpMRMTdgG8Ce2fmD4Zdz6iLiOOAJwIrgVMz8/Qh\n",
       "lzTS+n8211D92bwFeLb/nS0uInYB3piZe0bEfYAPAOuBKzLz2KEWN6Ju17OdgHdQ/bd2I/CMzPxN\n",
       "G+N2bcbjQGDzzNwNOB54y5DrGQeHAtdl5u7AfsA7h1zPWOj/o7AamBt2LeMgIvYAdu3/2XwMsO1w\n",
       "KxoL+wNTmfko4GTg9UOuZ2RFxMuA04DN+2+9BXhlZu4BTEbEk4ZW3IhaoGdvA47NzL2Ac4Dj2hq7\n",
       "a8Hj0cB5AJn5NeDhwy1nLJwFnNB/PQncPMRaxskpwLuBa4ZdyJjYF7giIs4FPgF8asj1jIMfACv6\n",
       "M7kzwE1DrmeUXQ0cNG/7YZn55f7rzwJ7ly9p5N2+Z4dk5uX91yuAP7Y1cNeCx1bA7LztWyKia99x\n",
       "oDJzLjP/NyK2BD4CvGrYNY26iHgWcG1mfh6YGHI542Jr4GHAwcDRwIeGW85YWAvsCHwfeA/VNLgW\n",
       "kJnnUJ0i2GD+n8s/UAU3zXP7nmXmrwEiYjfgWOCtbY3dtX+UbwC2nLc9mZnrh1XMuIiIbYEvAmsy\n",
       "8z+HXc8YOBzYJyIuAHYCzuiv99Dirgc+l5m39NcprIuIrYdd1Ih7MXBeZgbVurUzImKzIdc0Lub/\n",
       "vb8l8PthFTJOIuIQqnWS+2fm9W2N07XgcQnVeVEi4pHA5Uvvroi4O/A54OWZuWbY9YyDzNwjM/fM\n",
       "zD2B71Atwrp22HWNuIuBxwNExDbANFUY0eJ+y59mcH9PNf09Nbxyxsq3I2L3/uv9gC8vtbMgIg6l\n",
       "mul4TGb+rM2xOnVVC9WCmH0i4pL+9uHDLGZMHA/cCTghIk4EesB+mXnjcMsaGz5lsYbM/HRE/F1E\n",
       "fJ1qGvyYzLR3S3sb8P6IuIjqSqDjM7O18+4d81LgtIhYCVwFfHTI9Yy0/pKEtwM/A86JiB5wYWae\n",
       "1MZ4Pp1WkiQV07VTLZIkaYQZPCRJUjEGD0mSVIzBQ5IkFWPwkCRJxRg8JElSMV27j4ekv1BEbE/1\n",
       "nJAr+29NUN2v5AnAc4BvZOZGPWslIg6mevjUiv5xP5iZp/R/9hrg85l5yRKfPwC4b2a+bWPGlzR8\n",
       "Bg9JC/llZj50gff/eWMP2L9j6SnATpn5+4iYBi6MiO/3g8weVLfuX8rD8KZt0lgzeEiqLSJOBy4A\n",
       "LqS61f5vqJ5i+XjgzVThYQr4QGa+/XYf35rq75xVwO8zcy4inkn13JbDqJ4m/d6IOKi/778AdwTu\n",
       "DLwc+B5wFNCLiJ9R3Y3yXcD9+2P+q88akkafazwkLeSeEfHtiLis//tLFtjnr4GnZebjgGcDvcx8\n",
       "OLALcGBEPGr+zpn5XeATwI8j4msR8UZgRWb+ODM/CHwTOCIzr6R6ZsQR/eMdCZyYmVcBq4HV/ecK\n",
       "vRr4ZmY+girwvDoidhh8KyQNkjMekhay2KmW+a7NzF/0X+8NPDgiHtvf3gJ4INWDG2+TmcdExMnA\n",
       "46hmSS6NiKdn5rn9XTY8zvww4ICIeCrwSKpZktvbG7hjRBzR356mmv34aZ0vKGk4DB6SNtb8B5ZN\n",
       "UT3h+FyAiLgrsHb+zhGxP7AqM88C1gBrIuJI4AjgXP7cxcAXgC/1fz9zgfGngEMz8zv9498Nn3gr\n",
       "jTxPtUhayMTyu/zZPl8EnhMRKyJiFVVw2OV2+88Br+9fNUNETAD3A77d//ktwIqIuDNwX6rTK+cB\n",
       "+/Knx8Hfwp/+h+mLwDH9Y90D+C6wXe1vKGkoDB6SFrLYlSO9RV6vproE9zLg68D7MvOi+R/MzC8B\n",
       "JwGfioirqBaLTgIn93c5r3+cAN4LfC8ivkW10HQ6Iu4IXAQ8PSKOBV5DdarlcuB84KWZ+ZON+raS\n",
       "ipno9bwyTZIkleGMhyRJKsbgIUmSijF4SJKkYgwekiSpGIOHJEkqxuAhSZKKMXhIkqRiDB6SJKmY\n",
       "/wN64TRIUiJ1bQAAAABJRU5ErkJggg==\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b7580b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl.imshow(np.array(sdp.policy[:, 0]).reshape(n_pop_classes, n_fire_classes), \n",
    "          aspect='auto', cmap='Reds', interpolation='nearest', origin='lower')\n",
    "pl.ylabel('Abundance class'); pl.xlabel('Fire State');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "1. Clark, CW and Mangel, M. Dynamic State Variable Models in Ecology: Methods and Applications, Oxford University Press, 2000.\n",
    "\n",
    "1. Cordwell, SAW. [Optimal fire management of a threatened species, part 1](http://sawcordwell.github.io/mdp/conservation/2015/01/10/possingham1997-1/), Jan 10, 2015.\n",
    "\n",
    "1.\tPossingham H, Tuck G. Application of Stochastic Dynamic Programming to Optimal Fire Management of a Spatially Structured Threatened Species. In *Proceedings International Congress on Modelling and simulation*; 1997.\n",
    "\n",
    "2.\tZipkin EF, Jennelle CS, Cooch EG. A primer on the application of Markov chains to the study of wildlife disease dynamics. Methods in Ecology and Evolution. 2010;1(2):192–198. doi:10.1111/j.2041-210X.2010.00018.x."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}