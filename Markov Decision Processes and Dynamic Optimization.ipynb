{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href='http://fonts.googleapis.com/css?family=Fenix' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Source+Code+Pro:300,400' rel='stylesheet' type='text/css'>\n",
       "<style>\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
       "    }\n",
       "    div.cell{\n",
       "        width:1000px;\n",
       "        margin-left:5% !important;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    h1 {\n",
       "        font-family: 'Alegreya Sans', sans-serif;\n",
       "    }\n",
       "    h2 {\n",
       "        font-family: 'Fenix', serif;\n",
       "    }\n",
       "    h3{\n",
       "\t\tfont-family: 'Fenix', serif;\n",
       "        margin-top:12px;\n",
       "        margin-bottom: 3px;\n",
       "       }\n",
       "\th4{\n",
       "\t\tfont-family: 'Fenix', serif;\n",
       "       }\n",
       "    h5 {\n",
       "        font-family: 'Alegreya Sans', sans-serif;\n",
       "    }\t   \n",
       "    div.text_cell_render{\n",
       "        font-family: 'Alegreya Sans',Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "        line-height: 135%;\n",
       "        font-size: 150%;\n",
       "        width: 900px;\n",
       "        margin-left:auto;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    .CodeMirror{\n",
       "            font-family: \"Source Code Pro\";\n",
       "\t\t\tfont-size: 90%;\n",
       "    }\n",
       "/*    .prompt{\n",
       "        display: None;\n",
       "    }*/\n",
       "    .text_cell_render h1 {\n",
       "        font-weight: 200;\n",
       "        font-size: 50pt;\n",
       "\t\tline-height: 100%;\n",
       "        color:#CD2305;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\t\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 300;\n",
       "        font-size: 16pt;\n",
       "        color: #CD2305;\n",
       "        font-style: italic;\n",
       "        margin-bottom: .5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\n",
       "    \n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "        }  \n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division, print_function\n",
    "import pylab as plt\n",
    "import book_format\n",
    "book_format.load_style(name='/styles/custom4.css')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Decision Processes and Dynamic Optimization\n",
    "\n",
    "So far we have seen a number of approaches for calculating optimal decisions from a set of competing alternative actions. However, making optimal decisions when outcomes or events occur over time is more difficult. This is particularly the case when there is uncertainty in the dynamics of the system. That is, the state transitions from one point in time to the next can be influenced by decisions made at each step.\n",
    "\n",
    "## Iterative Decision-making\n",
    "\n",
    "First let's try to characterize the iterative (or sequential) decision-making problem. \n",
    "\n",
    "A decision-maker (or **agent**) is required to make recurring decisions. In a natural resource management setting, this could entail the setting of annual harvest policies (bag or catch limits) or stocking decisions; in an epidemiologic setting, this could be deciding the composition of the annual influenza vaccine based on information from outbreaks in other parts of the world.\n",
    "\n",
    "In principle, sequential decisions may be made in continuous time; for simplicity we will constrain decisions to occur at discrete time steps:\n",
    "\n",
    "$$t = 0, 1, 2, 3, \\ldots$$\n",
    "\n",
    "the decision intervals may or may not be of fixed widths; they may be arbitrary successive deicision-making stages.\n",
    "\n",
    "At each time step $t$, the decision-maker receives some representation of the environment’s **state** $x_t$.\n",
    "\n",
    "$$x_t \\in X$$\n",
    "\n",
    "the state may be univariate or multivariate, and may range from precise low-level instrument readings to high-level categorical descriptors of the environment.\n",
    "\n",
    "Given this state, the decision-maker chooses an **action** $a_t$ from a set of actions whose composition may depend on the state.\n",
    "\n",
    "$$a_t \\in A(x_t)$$\n",
    "\n",
    "Actions too can be specific and fine-grained (*e.g.* setting of waterfowl bag limits and season lengths) or be more general, high-level policy decisions (*e.g.* initiate captive breeding program or build a wildlife refuge).\n",
    "The set of available actions may also be temporally dynamic.\n",
    "\n",
    "Partly as the result of taking this action, the decision-maker receives a numeric **reward**\n",
    "\n",
    "$$r_t \\in R$$\n",
    "\n",
    "and the system moves to a **new state** $s_{t+1}$ as the time step increments.\n",
    "\n",
    "\n",
    "![RL environment](http://fonnesbeck-dropshare.s3.amazonaws.com/Screen-Shot-2015-03-16-08-29-10.png)\n",
    "\n",
    "\n",
    "#### In general, the goal is to maximize the system reward received, over the long run\n",
    "\n",
    "The simplest case is the simple sum of rewards:\n",
    "\n",
    "$$r = r_t + r_{t+1} + \\ldots + r_{T}$$\n",
    "\n",
    "where $T$ is a final time step. This approach makes sense in applications in which there is a natural notion of final time step, that is, systems which are *episodic*. There may be just a single episode, or multiple episodes.\n",
    "\n",
    "In contrast, some problems entail a continual process-control task (or episodes that are so long that they may be considered so). We call these *continuing* tasks. This implies that $T=\\infty$, and the corresponding sum of rewards could itself easily be infinite.\n",
    "\n",
    "In continuing tasks (and even some episodic tasks), we must invoke a **discount rate** $\\gamma \\in [0, 1]$ which determines the present value of future rewards. The rate applies multiplicatively to future rewards:\n",
    "\n",
    "$$r = r_t + \\gamma r_{t+1} + \\gamma^2 r_{t+2} + \\ldots = \\sum_{k=0}^{\\infty} \\gamma^k r_{t+k+1}$$\n",
    "\n",
    "The notion is that a reward received $k$ time steps in the future is worth only $\\gamma^{k-1}$ times what it would be worth if it were received immediately. If $\\gamma < 1$, the infinite sum $r$ has a finite value. \n",
    "\n",
    "Smaller values of $\\gamma$ result in *myopic* behavior; In the special case where $\\gamma = 0$, the decision-maker is concerned only with maximizing current reward.\n",
    "\n",
    "\n",
    "## The Markovian Property\n",
    "\n",
    "It can be useful to model these problems as a discrete time Markov process. Markov processes have the property that the future depends on the current state, but not past states. In other words, the transitions are *conditionally independent* of past states, given the present state.\n",
    "\n",
    "$$\\begin{gathered}\n",
    "\\begin{split}Pr(X_{t+1}=x_{t+1} | X_t=x_t, X_{t-1}=x_{t-1},\\ldots,X_0=x_0) = Pr(X_{t+1}=x_{t+1} | X_t=x_t)\\end{split}\\notag\\\\\\begin{split}\\end{split}\\notag\\end{gathered}$$\n",
    "\n",
    "This is the Markovian property.\n",
    "\n",
    "A **discrete** Markov process is one where the state space is *countable*. It describes movement from state $i$ to state $j$ over some interval of time $\\Delta t$.\n",
    "\n",
    "$$p(X_{t + \\Delta t} = j | X_t = i)$$\n",
    "\n",
    "It is useful to think of the Markovian property as “mild non-independence”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Chains\n",
    "\n",
    "A Markov chain is a special type of discrete Markov process, where the time step $\\Delta t=1$ and the transitions are stationary. Stationarity implies that the transition probabilities are time-homogeneous.\n",
    "\n",
    "$$p_{ij} = p(X_{t + 1} = j | X_t = i)$$\n",
    "\n",
    "> **Homogeneity**: A Markov chain is homogeneous at step t if the transition probabilities are independent of time t.\n",
    "\n",
    "> **Stationarity**: A stationary Markov chain produces the same marginal distribution when multiplied by the transition kernel.\n",
    "\n",
    "The Markov chain wanders about the state space, remembering only where it has just been in the last time step. The collection of transition probabilities is sometimes called a *transition matrix* when dealing with discrete states, or more generally, a *transition kernel*.\n",
    "\n",
    "$$P = \\left[{\n",
    "\\begin{array}{c}\n",
    "  {p_{11}} & {p_{12}} & \\ldots & {p_{1k}}  \\\\\n",
    "  {p_{21}} & {p_{22}} & \\ldots & {p_{2k}}  \\\\\n",
    "  \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "  {p_{k1}} & {p_{k2}} & \\ldots & {p_{kk}}  \\\\\n",
    "\\end{array}\n",
    "}\\right]$$\n",
    "\n",
    "Row $i$ of the matrix are the probabilities of moving from state $i$ to each possible state $j$ (including $i$ itself); hence the rows sum to 1.\n",
    "\n",
    "### Example: stationary Markov chain\n",
    "\n",
    "Consider a Markov transition matrix\n",
    "\n",
    "$$P = \\left[{\n",
    "\\begin{array}{c}\n",
    "  {0.3} & {0.5} & {0.2}  \\\\\n",
    "  {0.6} & {0} & {0.4}  \\\\\n",
    "  {0} & {0.4} & {0.6}  \\\\\n",
    "\\end{array}\n",
    "}\\right]$$\n",
    "\n",
    "The three states in the space are all recurrent aperiodic, and therefore it has a stationary limiting distribution. We can show this by simulating the chain with an arbitrarily-chosen starting distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "P = np.array([[0.3, 0.5, 0.2],\n",
    "              [0.6, 0., 0.4],\n",
    "              [0., 0.4, 0.6]])\n",
    "\n",
    "x = [0.5, 0.3, 0.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a single transition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.33,  0.33,  0.34])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.T.dot(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two transitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.297,  0.301,  0.402])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.T.dot(P.T.dot(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Five transitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.261897,  0.305349,  0.432754])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for t in range(5):\n",
    "    x = P.T.dot(x)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fifteen transitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.26086929,  0.30434832,  0.43478239])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for t in range(10):\n",
    "    x = P.T.dot(x)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a Markov chain is stationary, we can express two-step (or more) transitions in terms of its constituent one-step transitions. The probability of moving from $i$ to $k$ in two steps is just the product of the probability moving from $i$ to $j$ in one step, and then from $j$ to $k$ in another step, summing over all $j$.\n",
    "\n",
    "$$ p(X_{t+2} = k | X_t = i) = p_{ik}^{(2)} = \\sum_{j=1}^{n_j} p_{ij} p_{jk}$$\n",
    "\n",
    "This generalizes to an arbitrary number of steps by:\n",
    "\n",
    "$$p_{ik}^{(r+s)} = \\sum_{j=1}^{n_j} p_{ij}^{(r)} p_{jk}^{(s)}$$\n",
    "\n",
    "which describes the probability of moving from $i$ to $j$ in $r$ steps, and then from $j$ to $k$ in $s$ steps. This relationship is known as the *Chapman-Kolmogorov* equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Disease dynamics\n",
    "\n",
    "One can simulate the dynamics of an infectious disease using a discrete Markov process. This example is from Zipkin et al. (2010), which examined an avian disease affecting house ﬁnch (*Carpodacus mexicanus*) populations. The *Mycoplasma gallisepticum* pathogen caused a major epidemic of conjunctivitis in house ﬁnches in 1994, and was modeled by Zipkin et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9 ,  0.05,  0.05],\n",
       "       [ 0.1 ,  0.7 ,  0.2 ],\n",
       "       [ 0.  ,  0.  ,  1.  ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = np.array([[0.90, 0.05, 0.05],\n",
    "                [0.10, 0.70, 0.20],\n",
    "                [0, 0, 1]])\n",
    "P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rows are the state of a process for a given individual (0 = susceptible, 1 = infected and 2 = dead) at time $t$ and the columns indicate the state of the process at the following time step $t + 1$.\n",
    "\n",
    "Let's use this transition matrix to simulate the disease dynamics of a population of 100 susceptible individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = [100, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each step in the process, the transition matrix will be multiplied by the current vector of states, to yield an updated vector of states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize list with initial states\n",
    "X = [x]\n",
    "\n",
    "for t in range(20):\n",
    "    # Calculate transistion\n",
    "    new_x = P.T.dot(X[-1])\n",
    "    # Append new vector to list\n",
    "    X.append(new_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x112021668>,\n",
       " <matplotlib.lines.Line2D at 0x112021908>,\n",
       " <matplotlib.lines.Line2D at 0x112021b38>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAaEAAAEBCAYAAADRtBosAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmYHEX9x/F37ZGE3DEQCGcKEu7IFeUIRyABFTlaRRSQ\n",
       "AHILdosKiIJCOEQQsFsFFEQOgUh+YEO4j3CGMyAQ5EqggChXCGEJubPbvz+qNzuZ7dnMzs70XN/X\n",
       "8/Szu909s8Uwmc9WdfW3VBRFCCGEEOXQUO4GCCGEqF8SQkIIIcpGQkgIIUTZSAgJIYQoGwkhIYQQ\n",
       "ZSMhJIQQomy6DCGl1K5KqWeVUhdl7BuvlHpcKfWYUmqv1e0XQgghclFd3SeklBoPDAB2iaLoNKWU\n",
       "Ap4AxgMKuC+Kot1z7S9564UQQlS1LntCURQ9BMzP2DUKeCOKoiVRFC0GZiulRnaxXwghhMipqZvn\n",
       "DwValFKXYns8LfG+hhz7ZxexrUIIIWpMd0NoHjAYOBEbNlfE+xpy7O+kpaVF6gQJIUSNGzRokMrn\n",
       "vHxDqP3JZmOH3tr3jYyiaLZSqiFpf76NFUIIUZ+6DCGl1OnAN4C1lVIDoyg6Xik1CXgQiIBzAKIo\n",
       "alNKnZO9XwghhOhKl7PjSiFzOO6sa49o/3Y5MD7wwsdTbUwdmTFjRgQwZsyYvLrIojjkdS8Ped3L\n",
       "I/PzPd/huEq5WbUZ+JfrO5uUuyFCCCHSUykhBHY23VTXdwaVuyFCCCHSUe4QOjvr5y2AW1zf6e6s\n",
       "PSGEEFWo3CE0CZictW8f4A9laIsQQoiUlTWEAi+MgB8Cz2QdOsn1nZPL0CQhhBApKndPiMALFwMO\n",
       "8F7WId/1na+VoUlCCCFSUvYQAgi88ENgf+CLjN0N2OtDW5anVUIIIUqtIkIIIPDCl4FDsDe7thsI\n",
       "3On6zlrlaZUQQohSqpgQAgi88E7g51m7NXCb6zu9y9AkIYQQJVRRIRS7DLgqa9+uwF9d35G7n4UQ\n",
       "ooZUXAjFM+ZOAh7OOjQROD39FgkhhCiVigshgMALlwMHAbOyDv3W9Z1vl6FJQgghSqAiQwgg8MJP\n",
       "gf1YdWVXgH+4vrNDGZokhBCiyCo2hAACL3wT2yNakbF7DeAO13fWK0+rhBBCFEtFhxBA4IXTsCu2\n",
       "ZloXG0T9ytAkIYQQRVLxIQQQeOHVwKVZu7cHrnd9pyr+G4QQQnRWTR/gpwF3Zu37NnBuGdoihBCi\n",
       "CKomhAIvbAUOBV7OOvRL13eOKkOThBBC9FDVhBBA4IULgAOAj7IOXe36zmFlaJIQQogeqKoQAgi8\n",
       "8F1s1e2lGbsbsNeHDilPq4QQQhSi6kIIIPDCp7HFTlszdjdg7yH6XnlaJYQQoruqMoQAAi/8F8lB\n",
       "dKPrO98tT6uEEEJ0R9WGEEDghVOAw4C2jN2NwM2u73ynPK0SQgiRr6oOIYDAC/8J/IDOQTTZ9Z1v\n",
       "ladVQggh8lH1IQQQeOHN2CrbmUHUhF2Z9cDytEoIIcTq1EQIAQReeCNwJKuuzNoETHF9Z/+yNEoI\n",
       "IUSXaiaEAAIvvAE4ilWDqBm41fWd/crTKiGEELnUVAgBBF54HXBM1u72INq3DE0SQgiRQ82FEEDg\n",
       "hdcAx2bt7gXc5vrO18vQJCGEEAlqMoRgZeXt47N29wZC13f2KUOThBBCZKnZEAIIvPCvdF6LqDdw\n",
       "u+s7E8rQJCGEEBlqOoQAAi+8Ejgpa3cfYKrrO3uVoUlCCCFiNR9CAIEXXg78OGt3H+BO13fGpd8i\n",
       "IYQQUCchBBB44Z+An2TtXgO4y/WdPcrQJCGEqHt1E0IAgRf6wE+zdvfFBtFuZWiSEELUtboKIYDA\n",
       "Cy8Dfp61ux9wj+s7u5ahSUIIUbfqLoQAAi+8BDg9a3d7EI1Lv0VCCFGfCg4hpdRRSqlnlFJPKKX2\n",
       "jPdNUEo9rpR6TClV0TPPAi+8CDgja3d/4H5ZKlwIIdLRk57QKcDOwL7A+UopBZwD7A18DTi7x60r\n",
       "scALLwTOzNrdjF2h9Zeu76gyNEsIIepGT0LoZWACcABwHzAKeCOKoiVRFC0GZiulRhahjSUVeOH5\n",
       "dB6aAzgf+IvrO00pN0kIIeqGiqJo9WclPVCp44HdsUF2MzAXOBhbwbq9BzE5iqJnMh/X0tKy8hfO\n",
       "mjWroN9dCmbuK0yfNZW2qHWV/esO3oQ9Nvs2zU29y9QyIYSoDqNGjVr5/aBBg/IaSSqoJ6SU2gTY\n",
       "K4qiw6IoOgQ7NPcFMBj4ZbwNAeYV8vzloNfamr23OpRejX1W2f/+Z29x7yvXs2jpgjK1TAghaleh\n",
       "Q00NwCAApVQzNnxmY4fkwPaERkZRNLurJxkzZkyFXXMZw32v3LAFcDcwon3v/IUf8X8z/DnAvoEX\n",
       "vlKu1vXEjBkzIqjE17y2yeteHvK6l0fmSFe+CuoJRVE0C3hMKfUU8Djwh/g60CTgQew1onMKee5y\n",
       "C7zwNeyEixlZhzYApru+Mz79VgkhRG0qeGJCFEUXRFG0cxRFO0VRdF287/4oinaNomi3KIoeKF4z\n",
       "0xV44YfAOGBq1qGBwL2u7xyReqOEEKLCaK37a6330lr/Umud/XmZF5n5lUPghQtd3/kWEAA/yjjU\n",
       "BFzr+s5GwLmBFxY2s0MIIaqI1loBmwI7YUeLdga2podFD+qyYkK+Ai9sBU4GTk04fA5wjes7zem2\n",
       "SgghSk9rPVBrvbfW+iyt9d3AJ8DrwLXYBUO/TBEyRHpCqxH3dH7v+s57wPXYRfHaHQms7/rOQYEX\n",
       "tpSjfUII0VNa6wZgczp6OTsBW9Fxu03JSE8oT4EX3oK9OffTrEMTgMdd31k//VYJIUT3aa37aK13\n",
       "i6/l3IO9neY/wN+AY7DDbPkGUGbvqNukJ9QNgRc+4frOzsA9wMYZh0YDz7i+s2/ghS+Vp3VCCJFM\n",
       "az0Q2AXYLd6+yqqjOvlqAZ4BngaeAp41xqz8w7ylpeUv3X1CCaFuCrzwzTiI7gB2zDi0LrZHdFDg\n",
       "hfeXp3VCCAFa62F0BM7uwDZ0f+QrAl7Fhk176LxujGkrYlMlhAoReOHHru/sBdwIOBmHBgB3u75z\n",
       "XOCF15SndUKIehLPWhvBqqGzaQFPNR8bNpm9nJJf65YQKlDghYtc3zkIuBRwMw41An9zfWdj4NeB\n",
       "Fxb1rwYhRH2LQ2dz7L2M7aGzXgFP9S7wGLbgwBPAG8Xu5eRDQqgH4incnus7BhtGmRfyfgVs5/rO\n",
       "4YEXZk9mEEKIvGmtRwDjgb3ibZ0CnuZVOkLncWPMnCI1r0ckhIog8MI/xFO4bwQyK6DuC7zg+s53\n",
       "Ay98rjytE0JUG631OsCedASP7uZTtAIvYAPnMWC6MeaTojaySCSEiiTwwtvi60R3AGtmHNoIW3Pu\n",
       "J8AVUmFBCJFNaz0E2AMbOOOBLbv5FEuw13LaQ+dpY8wXRW1kiUgIFVHghU+5vrM9cAv2Zq92zcCf\n",
       "gV3jSQtV8eYQQpSG1rofMJaOns72dG/22kJs4DyCDZ3njTHLitzMVEgIFVnghXNc39kDuAjwsg4f\n",
       "AmwbT+N+Nf3WCSHKQWvdhL03Z29s8OyE/eM0X8uAJ4FpwEPAc8aY5cVuZzlICJVA4IXLgJ+4vjMd\n",
       "uAbon3F4C+A513eODbzwprI0UAhRclrr9YCvAV/Hhs/gbjy8DbuczEPY4HnSGLOo6I2sABJCJRR4\n",
       "4RTXd14G/g9bBqNdX+BG13d2BU4JvHBpWRoohCgarXVvYFc6gmd0N59iJjZwpgGPpnGPTiWQECqx\n",
       "wAvfcH1nR+AKYGLW4ROBr8Sz595JvXFCiB7RWm+CDZyvY6/t9O3Gw9+io6fziDHmo+K3sPJJCKUg\n",
       "vrH1SOyFxD+xas2mMdhp3BMDL7yzHO0TQuQnnlAwjo7gGdmNh88D7gceAKYZY94tegOrkIRQSuKp\n",
       "2Ve7vvM8dnguswDqEGCq6zu/xVZZWFGONgohVhVXJ9iSjtDZHeiV58PbsMU+7423540xraVoZzWT\n",
       "EEpZ4IX/dn1nB2zp8wOzDp8B7Oz6ziHxEuNCiJRprXthy+EcEG8juvHw97GBcx/wYGaFaZFM1hMq\n",
       "g8ALPwO+hV2xNfsvo3HAv13f2T3tdglRr7TWQ7TWh2qtJwNzgQexNSFHrOahy7HXdE7DrjS6vjHm\n",
       "aGPMLRJA+ZGeUJlkrNj6DPBPYHjG4XWAaa7v/BK4WKosCFF88aSC/bG9nd2xxYfz8TYdQ2wPV0tl\n",
       "gkolIVRmgRc+7vrOdsDN2FpR7RqB3wFjXd85Iu49CSEKpLVuxN4w2j7Mlm9pnKXY3s7dwL3GmNml\n",
       "aWF9kuG4ChB44UfYm9nOTzh8APBSXJdOCNENWut+WmtHa/037PWaJ4FfsPoAmou90dwBhhpj9jXG\n",
       "/EkCqPikJ1Qh4mUhznR950ngH9gZc+02BB5yfeePwC8CL6zJO6eFKAat9bDjjjuOGTNmgJ0Wne8y\n",
       "1v8BpmKLED8rM9nSoaIo3csNLS0tK3/hoEGDVFfn1ivXdzYCpgBfSTg8Czgy8MInu/OcM2bMiADG\n",
       "jBkjr3mK5HVPR7z0wbeBg7DVqPMZ5WnFFv+8A5hqjHmrdC2sD4V8vktPqAIFXviu6zu7YYfnfsqq\n",
       "i+WNAh53fedi4DdS8kfUq7g2W3vw7Maq/05y+Rx7becO7PWd+aVrociH9IQqXBxG17Lqza3tXgGO\n",
       "CLzwhdU9j/xFXh7yuheX1noD4DvAd4Fd8nzYO9jQuQO7omhVLnlQDaQnVIPi2XPbYJeGODHr8NbA\n",
       "M67vnAv8NvDCmijtLkQmrbXGBs9BwI75PGbEiBHstNNOTJ48eTTwH2OM3OZQoaQnVEVc39kH+Buw\n",
       "fsLh54GJudYpkr/Iy0Ne98LE9/AcFG9j8nxYe0msW6dMmfImyOueNukJ1bjAC+93fWc08AfgiKzD\n",
       "O2ALoZ4JXBbPthOiamitR2GH2Q4CtsvzYc8SB48x5u32nfHMOFEFJISqTHzT6pGu7/wL+CswLONw\n",
       "b+BiwHF958jAC+WeBlHR4llt3wMOI3k2aJKnsLNHb5NK1NVPQqhKBV54e7xy6xXYvxwzjcXe4Hoq\n",
       "cGXghW2pN1CIHLTWA7C1Ew8DJrD66dQRMJ2O4PlvaVso0iQVE6pY4IWfAAcDhwDZU037An8G7nN9\n",
       "Z8O02yZEJq11s9Z6v7hA6EfAdcA+5P4MagMeAU7GFgXdzRgTSADVHukJVbm4uOlk13ceBa4Cvpl1\n",
       "ygRg5uyPXmKTYV9OvX2ifsVr8eyC7fEcDAzN42GPApOBf9XrSqP1RnpCNSLwwg+wFYGPBhZkHR74\n",
       "5OypPPzaLbi+M7zzo4UoHq31llrr87HVpp/A3lrQVQC9DJwObGiMGWeMuVICqH7IFO0aFJf9uQa7\n",
       "5n22z4GzgMtlBdfSq5cp2nH1gu9jez35zGx7D7gJuNEY80qx21Mvr3ulKeTzveCekFJqPaXUNKXU\n",
       "Y0qpS+J9E5RSj8f7pOpzmQRe+C62KvePgcVZhwcCPvCc6zs7pd02UTviCtVHaK0fAuYAv6frAJoP\n",
       "/AW7do82xpxRigAS1aXgnpBS6mYgiKLoqfhnhe16j8fWcLoviqJOq4NKTyhdru+Mwpb9yVXi5Gps\n",
       "Ze55qTWqjtTaX+TxdZ4dscO+3wf6r+YhS7CVqW8E7kmrZE6tve7VIrWekFKqARjZHkCxUcAbURQt\n",
       "iaJoMTBbKTWykOcXxRN44Sxg96/ofWhuTKxofwzwhus7R7u+I9cIRSKt9TCt9c+w9Qqfwr5vcgVQ\n",
       "G3Z57KOAtY0xBxtjbpeabSJJobPj1gL6KKX+hR3e+RPwIdCilLoU2xNqwV6MlBsmyyzwwtYZM2aw\n",
       "0Zpb8H/P+TcBh2adMhTbIzra9Z0TAy98Kf1WikqjtW4Cvobt9ezP6j8vnsf2eCYbYz4ocfNEjSho\n",
       "OE4p1QQ8jF23owl7I9kPscsOnIgNoSuA86IoWiWEMrtrs2bNKrjhonAffGZ49u17aVnceQROodh8\n",
       "+FfYZsM96NWU71pgopZ88MEHPPzwwzzyyCPMn9/1SgdDhgxhjz32YNy4cay33noptVBUqlGjRq38\n",
       "vqS146IoWqGUmgMMj6Lof0qpJdgeT3sLFHa4TnpBFWj4YM1+2x7Hq+8/zctzHqe1rWOSXETEax88\n",
       "yzufvMoYvTcj1twSe7lP1LIlS5bw9NNPM23aNF577bUuz21sbGT77bdn/PjxbLvttjQ2NqbUSlGL\n",
       "ejIxYUPgSuxw3C1RFAVKqX2AX2PLbEyKouiB7MfJxITyyHWh1vWdEdiCqAfmeOhDwEmBF75R0gbW\n",
       "qEq+QB5PMvgqHZMMBqzmIa9jq7jfUOn38VTy617LUq2iHUXRe8C+WfvuB+4v9DlF+gIvfAdb8HR/\n",
       "IABGZJ0yHpjp+s5FwAWBFy5Kt4Wi2LTWawITsUPoW63m9C+wFQyuAZ6WdXlEsclsKAFA4IVTsR9I\n",
       "5wPZi+M1A78C/uP6zn5pt030nNZaaa131FpfD/wXuISuA+gJ7Oy24caYY40xT0kAiVKQ2nFipbiX\n",
       "c6brOzdgi5+OzzplBDDV9Z3bAS++KVZUMK11X+xQ20nA9qs5/UNsYdG/G2Nk+FWkQnpCopP4+s/e\n",
       "2OrcSVNtDwRec31nkus7q7uOIMpAaz1Ka30p8D/sdZxcAbQCCIEDgA2MMb+QABJpkp6QSJRRnftu\n",
       "4BzAZdU/WtbA1qA73vWds4GrAy/MHsYTKdJaN2KrqJ+EXSahK29jS+hcV+mTDERtkxASXQq88HPg\n",
       "FNd3rgMuB3bOOmVYvN9zfed04I44wERKtNbDsDPcTgC6WjsqAu7C/v+6zxgjix2KspPhOJGXwAtf\n",
       "BHYFjgU+TjhlM+ywzqOu7+yYZtvqUTzRYBet9T+wxUMvIHcAzQN+B2xijNnfGHOPBJCoFNITEnmL\n",
       "lwm/2vWdfwKnAT/DDstl2g142vWdW4BfBl74VsrNrGla637Ysks/ArZdzelPY3s9U4wxS0rdNiEK\n",
       "ISEkui3wwgXAWa7vXAFMwk7lze5VHwx8y/Wdy4Hz4qXIRYG01iOxS10fCQzq4tTF2HV6LjfGvJBC\n",
       "04ToEQkhUbDAC98HjnF95w/Y4Z59s05pBjzgSNd3fgsEgRdmr28kcogrGozF9jgPxJbDymU2ttdz\n",
       "rTGm64JvQlQQuSYkeizwwlcCL/wm9r6ipL++BwEXYpeMmChLRnRNa92ktf4edjjtccAhOYDagNux\n",
       "la43M8ZcJgEkqo18GIiiCbxwGvAV4AfY5ZuzbYC9GfJ513cmpNm2aqC1Hqi1PgXbq5mMreuWZC52\n",
       "IsLGxhjHGHO/TDQQ1UqG40RRxZMXbnR951bsNYxfAYOzTtsWeMD1nXuB0wMvfDnlZlYUrfUG2Puw\n",
       "jsMWBM7lReBS4BZjzNI02iZEqUlPSJRE4IVLAi/8PTASuIzO9egAvg686PrO313f2TjVBlYArfUO\n",
       "WuubAAP8nNwBdBewF7C9MeYGCSBRS6QnJEoq8MJ5wE9d3/kjdgjp+1mnKOyMr8PjG2LPD7zw7XRb\n",
       "mR6tdQOwH3aywe5dnLoEuB64zBjzehptE6IcpCckUhF4oQm88BDsdY5HE05pxC4t8KbrO9e4vrNJ\n",
       "qg0sMa11X631CcBr2MkEuQJoLnA2sKEx5ngJIFHrJIREqgIvfA7YE9gf+4GcrRF739Eb8TDdyDTb\n",
       "V2zz589n8uTJYCdqXAFsmuPU17DVKDYyxpxjjJmbUhOFKKuCV1YtlKysWh6VuNKk6ztN2OG5s8j9\n",
       "4dwK/AN7w2vVLBevtR4BnN7c3HzC8uVd1nWdhl3b516Z4VY8lfh+rweFfL5LCNWJSv5H6fpOIzaM\n",
       "fk2Vh5HWejPgDOw09cYcp60AbgYuNca8mFbb6kklv99rmYSQyKka/lFmhNFZ2IKoSdroCKNZabVt\n",
       "dbTWX8ZOR/8uuSsbfAZcCfzJGPO/tNpWj6rh/V6LJIRETtX0jzIOo+9he0ZdhdGN2DB6M622ZdNa\n",
       "74gNn/1znbPWWmsxd+5cF7ti6RepNa6OVdP7vZZICImcqvEfZRxGB2PDaPMcp7VhC3aeF68IW3Jx\n",
       "TbfdgTOBrio/vHHSSSdttuuuu7LTTjtVzeteC6rx/V4LCvl8l9lxomIFXtgaeOHNwNbYpcaTZtM1\n",
       "YK+/vOr6zj9c38kVVj0Wr+HzDWw9t0fIHUAvY3tyW40bN46mJrkdT4hc5F+HqHiBF7Zilxqfgr3m\n",
       "8mtgi6zTGoDDgMNc35kKXAw8UYxVXuMbTA/E9ny27+LUZ4DzgTuNMRHAjBkzevrrhahp0hMSVSPu\n",
       "GU0GRmMnMLya49T9gcewi+t9Nx7W67a4mvWh2J7NbeQOoEeAvYGdjTFT2wNICLF60hMSVSfuGf0z\n",
       "7hkdBPwG2DLh1K8CtwDG9Z1Lgb8HXrhwdc+vte4FTAR+AXRVueEe4HxjzPRu/icIIWLSExJVK/DC\n",
       "tsALb8H2jA4Gns9xqgb+CMxxfec813fWSTxJ62at9THALOAqcgfQbcAYY8y+EkBC9IyEkKh6cRhN\n",
       "wa5lNA5bdTrJEOx06ndd37nK9Z0tALTWjVrrw7DDe1cBGyY8tn1K+NbGmO8YY3IFnhCiG2Q4TtSM\n",
       "eBLCo8Cjru9sCfwUOBzolXVqL+CYKIqOOeDo3WY0NjcMbV3epnM87XJsNesLjTEVW6lBiGolISRq\n",
       "UuCFrwLHuL5zJvBj4ERsT4goivj4nQW88dSHtHy8eEyOp1gG/BW42BiTtEqsEKIIJIRETQu88EPg\n",
       "V67v/BY46uN3P//lm898tM789xclnq8UDF6n75ONzQ0/fO7Rmanc/CpEPZMQEnVh6h9e2go4AEic\n",
       "lACw/hZD2HTHtek3uPcu2OndVwFX1vIie0KUm4SQqGla622Ac+mittvwUYPYbKd1GDC0T+buwcCp\n",
       "wM9d37kHuBy4N54eLoQoEpkdJ2qS1npzrfVk4EVyB9DdwA5jvjliywFD+1yNvQ6UTQH7AncCs1zf\n",
       "Oc31nTVL0mgh6pD0hERN0VprbFmfieT+I+th4ExjzJMZ+451fecs4CTgR8CXkp4e+B0wyfWdW4A/\n",
       "A88WozSQEPVKekKiJmit19VaXw68ARxJ8nv7GWCCMWavrAAC7CSGwAvPAjYAjgZeyPHremOnfj8N\n",
       "zHB952jXd/oW4T9DiLojISSqmtZ6gNb6XGA2dhp2c8JpL2GH5HY2xjy0uucMvHBR4IXXAGOAHbH3\n",
       "CS3Ncfr2wNXA/1zfudT1nVwrwwohEsh6QnWi1tZX0Vo3YXsrk4BhOU57HTs0d6sxpq0nvy++DnQU\n",
       "Nuhy3dja7gHsUN1dE8eeuRxq53WvFrX2fq8Wqa8npJTqpZR6Ryn1o/jnCUqpx5VSjyml9urJcwuR\n",
       "JF7T55vYytZXkhxA72CH5EYbY6b0NIAAAi/8JPDCi4GR2IkKdwG5/oLbGwiBt1+e8wSLl8liqkLk\n",
       "0qOekFLKBfYAHgKuAJ4AxmNnFN0XRdHu2Y+RnlB51MJfhlrr7YHfA3vmOOVj4Gzgb8aYpJluReX6\n",
       "jgaOB44BhuY6r0E10Ba13QZcA9wXeOGKUret3tXC+70apdoTUkqtAewD3B7vGgW8EUXRkiiKFgOz\n",
       "lVIjC31+IdpprTfUWl+PrZKdFECLsfcCjTTGXJFGAAEEXmgCL/wFsD52Nt7TSee1RW0A38ZO837P\n",
       "9Z3flXIFWCGqScE9IaXU6dgLvmsD/YB/Y8vpR9ieEMDkKIqeyXyc9ITKoxr/MtRaD8Ku6XMKdkZa\n",
       "tgi4FjjLGPO/FJuWk+s722OneB8KrLGa05/C9o5uCbzw81K3rZ5U4/u9FhTy+V5QCCmlBgI3RVG0\n",
       "n1LqCKA/9mLsGdgLtwo7PHdeFEWrVB7ObOSsWbO6/btF7VuxYgUPPvggt9xyCwsWLEg8Z/To0Uyc\n",
       "OJERI0ak27g8LV2xmLc+fpk3P3iez5d82uW5TQ3NbDh0c0auvQ1rD9wIpeRzU1SnUaNGrfw+3xAq\n",
       "9GbVXYHeSqmbgI2BRuBx7JAc2BAamR1AQnQliiJmzJjBDTfcwAcffJB4zgYbbMDhhx/OtttuW9Ef\n",
       "1r2b1mDLdXdki+FfZe6C/zL7o5d455NXWdHWeaRwRdty3p47k7fnzqR/78GMXHsbNh72Zfr3HlSG\n",
       "lguRrh5P0VZKTQT6R1F0uVJqH+yU2AiYFEXRA9nny3BceVT68ITW+ivYSQedJrPEPgTOBK41xlRN\n",
       "/bbM1931nX7Y5ciPwk7o6UoEPAj8HQgDL1xc0obWmEp/v9eq1IbjekJCqDwq9R+l1noEcAFwSI5T\n",
       "FgEXAZcYY6purnOu1931nU2w08iPwFZo6EoLcBM2kGZImaDVq9T3e61L/T4hIQoVVzq4EFtmJymA\n",
       "2rCVCEYaY86pxgDqSuCFb8UlgjR2lulkcldlGIS91vosMNP1nV/G08OFqHpSwFSkSmutsDPHLgLW\n",
       "zXHaPcBpxphXUmtYmcRLQzwAPOD6zhBsIB+FLRmUZCvgfOB813eeBm7Gzq77MI32ClFsEkIiNVrr\n",
       "bYE/Yie2JHkJONUY0+laYj0IvHA+dt2iy13fGY0Nox8Aa+V4yE7xdpnrO9OwgXRb4IWfpdFeIYpB\n",
       "QkiUnNZ6KPZm0uNJHgJ+H/gVcEM1TToopcALZwI/dX3nF9gyQT+MvzYmnN4ATIi3K1zfuRsbSHcG\n",
       "Xpi8jrkQFUJCSJSM1roROBY7fJS0Ps8y4BLgglq75lMsgRcuw9ahC13fWQv4LnbILldvshfgxNsX\n",
       "ru+E2EkNDwZeuDyFJgvRLRJCoiS01mOxQ2/b5TjlLuAUY4zcsZynwAvn0jFctxHwPWwgbZvjIf2x\n",
       "w3k/AOa5vjMFG0jTAy/scVFXIYpBQkgUldZ6OHbSwQ9ynPIW8BNjzJ3ptar2BF74LvZ1vsj1nS2w\n",
       "YXQItsp3kqHACfE2x/Wdf2Jn5L0gU75FOcl9QnWi1PdNaK17AR72ZuX+CacsAs4DLjXG5JqKXHPS\n",
       "vF/F9R2FnVV3CPB9YHgeD3sXuC3enopn61U9uU+oPAr5fJeekOgxrfXXAB/YLMcpk7Gz3v6bXqvq\n",
       "T9yjeQ54zvWdU7HVJw7BVmkYkuNhG2ELxJ4CfBRfQ7oNeFiuIYk0SAiJgmmtNwYuAw7IccpM4MfG\n",
       "mEfTa5Wim4bjAAAVtUlEQVSAlfcfPQw87PrOycDXsIF0INA3x8PWxs5gPB74zPWdqcCtwP1SNkiU\n",
       "ioSQ6DatdV9sxfRTSV5i4TPgLOBKY4ws4FZm8Qy7qcDUuH7dAdhJDV8D+uR42GDg8HhbFE/7vg24\n",
       "S5adEMUkISTyFlc7cLBDb0n1ziJsqZ1fGWPmptk2kZ/ACxdi7yG6OQ6kr2MX3NsfGJDjYX2xQ3oH\n",
       "Actc33kQG0h3xDP2hCiYhJDIi9Z6I+yU6/1znPI0duhtRnqtEj0RB9KtwK2u7/QGxmMD6UBgzRwP\n",
       "64W9aXZfoM31ncewgXR74IXvlb7VotZICIkuaa2bsLPeJpF8LeEj4DTgH8YYufekSgVeuBS4G7jb\n",
       "9Z0TsDfDfjve1svxsAZgXLwFru/MxC5hfhfwdK3MtBOlJSEkctJa7wj8Bdgm4fAK7LDcJGOMXCOo\n",
       "IYEXrgAeAR5xfecn2Gnf38EGUq77kABGx9sZ2Jtj78WG0n1xXTwhOpEQEp1orQdh1/hpX6o925PA\n",
       "CcaYmak2TKQurqzwLPBsXMduazp6SF/u4qFDgcPirdX1nel09JJekxtkRTsJIbFSPPHgu9gezjoJ\n",
       "p3wGnA5cLUNv9ScOjpnxdo7rOyPpmNSwC7nXJ2vE3rO0O7bKg3F95y5sKD0aeOGSUrddVC4JIQGA\n",
       "1lpj65J9PccpNwI/M8Z8lF6rRCULvHA2HaWDhmKnfO8HfAM7xTsXDZwcbwvj2XZ3AncHXvh+aVst\n",
       "Ko2EUJ3TWjcDP8OW21kj4ZTZwI/qdY0fkZ/AC+dhi6Pe5PpOE7AzNpC+iV2IL5d+2Nl4BwK4vvNv\n",
       "4F7gfmwZobop8VSvJITqmNZ6F+zEg60TDi8HfoddZkHulhd5iyc2PB5vp7u+MwIbRvsBe5J8g3O7\n",
       "7eLtDOxNso9gV569H7mWVJMkhOqQ1noIcCFwXI5THsNOPHgtvVaJWhV44TvAn4E/xzfIjqcjlHIt\n",
       "8Q72loD2e5IA3nd9535sKD0YeOHHJWu0SI2EUB2Jogit9aHYem/DEk6Zhy3Fc60xRv7iFEUX3yB7\n",
       "B3BHXPV7G2wY7Qd8leTZmO3WBY6MN1zfeRHbQ3oAeEImOFQnWcqhTkydOjW66qqrmDkz56zqa7GV\n",
       "rj9Jr1W1T5YUyJ/rO8OwS5TvDexD172kbEuAR4mH7g7f5VcvK6XkdU9ZIZ/vEkI1rn3iQXNz82+X\n",
       "L0+szP8GdujtkVQbVickhAoT95K2pCOQ9iB39e9O1mjuz/DBI3h77itHY2+8NXI9qfQkhMQqtNbb\n",
       "AteQvMT2UuwNqb+rp0Xm0iYhVBxxbbtd6Ail7el66C7bHOIqENglLt6RUCo+CSEBgNa6D3Am9sbS\n",
       "pOt+04ATjTFvptqwOiQhVBqu76yJneCwDzaYkqq6d+U9OkLpESSUikJCSLRPu/4bsHn2sQEDBrBg\n",
       "wYKJ2GKj8g8uBRJCpRcP3W1GRy9pHMlLzHdllVAKvNAUr4X1Q0Kojmmt+wPnAz8mYZhi7NixHHXU\n",
       "UYwfP15e8xRJCKXP9Z1eX9v68KUftrzLS3Meexg7jNfVvUlJ3mXVUHqnqI2sURJCdUprPQG4ChiR\n",
       "cPh94MQpU6bcDvJhmDYJofLIfN1d3+mDnf49Lt4KCaU5wPR4ewKYKUtVdCYhVGe01oOBS4Af5jjl\n",
       "auy068/kw7A85HUvj65e9ziUdqQjlHam+6G0ALuQY3swPRN44YLCW1wbCvl8l5tVq5TW+kDgCmB4\n",
       "wmEDHGuMeSjdVglR+eKbWh+Nt3MKDKUB2GtQe8c/t7m+8xIdoTQ98MI5RW98DZIQqjJa62HYZbYP\n",
       "TjgcYZdhONMYszDVhglRpYoUSg101L07GcD1ncwhvOnAyzKE15mEUJWI1/o5FBsyQxNOeQ042hjz\n",
       "VKoNE6LGJIRSb2AHYGzGtmYeT7UB8P14A1jg+s7TwFPECwUGXji3yM2vOhJCVUBrvQF26O2bCYdX\n",
       "YIuRnic3nQpRfPFyEk/G28XxlPBRwK50hNJmeTxV9hAeru8Y4BniUAJeCLywrqrWSwhVMK11A7bS\n",
       "9UXYN3C2F4AfGmNeSrVhQtSx+KbWN+PtGlh58+wudITSGPKb7KDjrb23tML1nZl0BNMzwOvxMus1\n",
       "SUKoQmmtN8bedDou4fBS4DfAJcaYFWm2SwjRWeCFnxBXB4eVZYYKGcJrouPa0gnxvgWu78wgI5hq\n",
       "aQVaCaEKE/d+TsT2fpIKNj4BHGOMeSPVhgkh8tbFEN7O2EkPX8UuY5HPZ/AA7GKAe7bvcH3nf9hQ\n",
       "eh47IvJCta6vVFAIKaWuxI6BKuCoKIqMUmo8cDZ2htbZURRNK1or64TWWmO79+MSDi/E1oK7whhT\n",
       "s11zIWpR1hDedbDyfqXtsIHUHkyb5PmU6wHfjjfi5/svcSBlbO9Xek28gkIoiqITAJRSewKnKqVO\n",
       "AiZhCwoq4D5skUyRh7j3czxwMdAv4ZT7geOMMe+m2jAhRMnEs/Ceijdg5bWlr9ARSl8leTZskvXj\n",
       "7YCMfR+5vpMdTO9WUjD1dDhuAbAM2818I4qiJQBKqdlKqZFRFM3uaQNrndZ6I+y1n/EJhxcAPwX+\n",
       "JgVHhah98bWle+KtvTjrxqzaW9qe/Cs8rA18I97azY+DaeVQHvBWuSY/9Khsj1LqCux9K0OwN09G\n",
       "dBTPnBxF0TPZj8ks6zBr1qyCf3e1i6KIhx56iOuvv57FizvPyBw9ejQnnngia621VhlaJ4SoVK1t\n",
       "rXy26GM+WfA+ny78kE+/+JD5iz6mLSr8Ptjmxl4M7juMIf3WZkjfYQzpN4whfYfR3NS9akajRo1a\n",
       "+X3Jy/YopfbD9n5eV0ptCgzGXlBX2Hta5hX63LXuk08+4corr+SllzrPrO7Tpw8TJ05kwoQJKCXl\n",
       "xoQQq2psaGRo/+EM7d9Rsau1rZWWRXOZF4fSpwvt1tqW3+TZ5a3LmLvgv8xd8N9V9vfvM5ghfde2\n",
       "oRQH1IA+Q4r62VRQT0gptQNwSBRFP49/bgAew64P3wDcH0XRrkmPrecCpnHVgx8ClwIDE06Zhq16\n",
       "8E6xf7cU0iwPed3LQ153cH2nCTuBbPuMbTuS7znsjoXATODleHsJW1W8Jc0CplOAOUqph4GXoyjy\n",
       "lFKTgAexQ3LnFPi8NUtrvT52uYWvJxxeCJwK/EVmvgkhiiHwwhXAf+LtBgDXdxqwM/B2YNVwGtKN\n",
       "p+4H7BRvK7m+8+65R17X7XYWOjtu44R992NncYkMce/nCOAPwKCEUx7BVj2QlRyFECUVTz6YFW+T\n",
       "YeXkhw2AL2ds2wCbYke28rVRIW2Sm1VLSGu9LvBXkmu+LcLe93O59H6EEOUST9d+L97ubN/v+s4a\n",
       "wJZ0hFL71y8V8/dLCJVA3Pv5ARBgJ2xkexw4yhjzVqoNE0KIPMWFVJ+PN2Blr2ldOveaNgcaC/k9\n",
       "EkJFprUeDvwF2D/h8GLgF8CfpPcjhKg2ca/pf/F2T/v+uFbeFsC/u/ucEkJFEvd+vg/8ieTu6hPY\n",
       "3o/cwCuEqClxrbwXW1pauv3Y7lx0EjnEq51OAW6icwAtAU4BxkkACSHEqqQn1ENa64OwN+cmlWl/\n",
       "Etv7eTPdVgkhRHWQECqQ1noodujt+wmHlwJnApcZY2RNeSGEyEFCqABa6wOwU6/XTjj8HHCEMea1\n",
       "dFslhBDVR0KoG7TWQ7AFWw9POLwcu9rpxbLaqRBC5EdCKE9a628AV2PnyGf7N7b3MzPdVgkhRHWT\n",
       "EFoNrfVAbMHRoxMOrwDOAy4wxixPtWFCCFEDJIS6oLWegF1ue4OEwzOBI40xL6TbKiGEqB0SQgm0\n",
       "1v2Bi7DrI2VrAy4EJhljlqbaMCGEqDESQlm01nsAfwd0wuHXsdd+nk23VUIIUZskhGJa677ABYCX\n",
       "cDgCLgHOMsYsSbVhBWoYGynsOvS9gd5Tz26mtU3RMDbaAHstqzXra/v3rW3TVeFrvgshRDdICAFa\n",
       "612Aa4FRCYdnYa/9PFnKNjSMjfoDw4F1sr4OxQZJHzpCJfP7XMd6ZT7//md/uf3b9/JoSxtdB9UK\n",
       "7A25i7AL8i3K2Bbm8X32zwuAz9umK5ncIUSdqesQ0lr3w/Z+fgwkLUUbAGcYYxYV8vwNY6NGbDmf\n",
       "pHDJ/tqvkN9RIg1khVgqv3RstBj4PN5aMr7vzs8tbdOVVKkQokrUbQhprcdjl9tOuvZjsDXfHs3n\n",
       "ueJezLbYJXN3ALbCBsswClxjo06tEW9JlSjy1jA2WgDMBz6Lt+58/4UMRwqRnroLIa31IOD3wDE5\n",
       "TrkCOM0Y80XSwYax0QBgOzoCZwdgM5J7UuW2DDtstnTY4GVrNqiID+f3/h82GJsyvmZ+XwuV1QfE\n",
       "24YFPLa1YWzUgg2lzO3TPH6WABOim+oqhLTW+wNXklz1wADHGGOmte9oGBsNpHPgbEppAmcZ8CHw\n",
       "QdbXj7GL4S3FLguxNM/vl7VNVysXzpsxY2YEMGbMmPW7akQ8oaGR5IDK3NcbO4TYN2Prl8f3SccG\n",
       "AAOpjABsxC7HUcgSxisaxkbtvar5wKf7bK8Z2HcF/+dF59I5wFZ+bZuuFhel9UJUmboIIa31mtia\n",
       "b4cmHI6A4NOBZ1y4oP+xmzeMjX5GR+CMoueBM5/kcMn+Or8S/oqO29A+CSG1+6Di8OuHDaOBwKCM\n",
       "73Pty/55cPy1XJqw1wBXLutx/wsrs+zMrh7YMDZaSnJA5dq3cmubrpYV8z9CiDTVdAjFq50eDPwR\n",
       "WCv7eETDm/MHnnnrgv5H7gS8T88C50061mN/AXgb+KhtuqqKKd3lFoffF/H2fqHPE08GaQ+kwcCQ\n",
       "bn7ft+D/iJ7pjZ2ksk53H9gwNlpEQjjls7VNV3LDtSirmg0hrfW6wOXAgdnHIlTbwjUOmjVv8Dkj\n",
       "UH3O6OZTR6waOM8D/26brj7vYZNFEcQz49o/ZLutYWzUG9vDGpKxfSnPn9foYfML1T60uV53H9gw\n",
       "NlpCx6SMpIkaXe37XGYiip6quRCKez9HYYuODso+vqxp89ZPhlzcuLx5q83yeLoIWyWhvXfTHjgL\n",
       "ithkUUHinsHH8dYtcYCtElK/OcxMXbCoiUv/tcE5Wccyg+xLQHNx/gu6rQ92JufwAh4bNYyNPqcj\n",
       "pFoSvu9qX4sMJYqaCiGt9QjsYnN7Zx+L6MVnA37M5/2Pa0Tl/Pf+OnZRuvYezott01XiLDkhssUB\n",
       "9mG8ATBjxqcA/P7nG56d63Hx9bC+dA6mpLAakrCVa0KHwv6hNwjYqJAniO8Nyw6o9u3zPL5vkSHF\n",
       "6lYTIaS1bgB+hC0s2ummz6XN2zFv8IUsb04qiMDbwI3AjW3T1RslbagQCeLrYQvjbU53HhsH2ACS\n",
       "w6mr7UvYa2Dlvo+t/d6wQnpiADSMjZaRFVB7jN6Yfn3auNuL/hjvW8CqNzcn/by4EiYH1ZuqDyGt\n",
       "9aYRTdcpVuyUfaxN9eGzAT9nQb8jQK3yb+0T4J/Y8Hla3niiWsXv3fYP0ne789iMGYmZkzOSJmzk\n",
       "msRRzpmImXphJx6tnHz06Mwh7d+e3I3naY2HF7NDakEe2xfZP8v1svxUbQgNGX1Z797LX7iqD02H\n",
       "KVZ0Go5Y0mtn5g2+gBVNK0cJFgEhNngekDplot5lzUj8b3cf3zA2asIG0RDskNzghK9J+zKPVcK9\n",
       "Ye0a6egp9lg8azFXUH2RtS1M2NfpnMx7/2pFVYbQ0K1/c3K/JY9f3Nxq+mQfa1P9mT/wDL7o+31Q\n",
       "qhV4APgHcLtc3xGieNqmqxXYe5c+LeTxWT2xzGDKvAdsUML32T9X6udY+6zFHpWhyhQHW2Zw5dpW\n",
       "dzx7W1SuEaFK/Z+X6EujL9qu17IXbxu47KkRSccX9d6TTwefR2vj8GewPZ5/tk1X3Z7lJIQovZ72\n",
       "xGBlkPUhK5wuPOqtBxYuaeTcm0d4rHpD8wA63wTdvq93j/6D0tEebMOK/cRxwOVT9T7nz/Pv7v7v\n",
       "rYoQGjL60n7Nre9MHrDkof0aos4FrVvVYD4beNqHX/Q9+EpUw01t09WsMjRTCJGyOMgWx1vGrMTP\n",
       "ADjnZB3k+1zxFPv2uoNJQdW+9c/6OWlf/x79h5VHe8ClquJDaOhWvz6939JHJjW3zklcWmBx713N\n",
       "F30PPXHRGl+/XyYYCCEKFU/1XoqduNQjDWOjBuxQY1Jgte/v7lZJy70UTcWG0JdGX7hL72X/vmXg\n",
       "smcT7wJf3rTJksW9d/vpvFd+c0XabRNCiK7EEwjaJyF8UIznjIOtL52Dqastn3P6YYc0y6LiQmjI\n",
       "6EsHNa9469YBS6aNb6Bz2bU2NSBa1GfvW1Y0rn/4/JmnyAw3IURdiIOt/RpaUcU1F9cg/8r3uY51\n",
       "KpO2OhUVQmtu9atJ/Zc+ckZT6/ud2hWhWNJ799eXNW/1rU9nnvp6OdonhBC1KL6nqccB19JCty+J\n",
       "VEQIfWn0b/fqvXTGzQOWv5A442NZ02YLl/Qee9K8V866Lu22CSGEKJ2ih5BSajxwNrb459lRFE3L\n",
       "de6Q0Zes1bxi9m0Dlzy0q6LzyFqrGhwt7jPh2hWN6x47f+YpcvexEELUmKKGkFJKAZOA8djihvcB\n",
       "OUOo/6IpHzS1fdSpdlVEA4t7j3tpefMWzqczf/5OMdsohBCichS7JzQKeCOKoiUASqnZSqmRURTN\n",
       "TvzlCQG0tHmrlqW9djp23itnTily24QQQlSYYofQUKBFKXUptifUEu9LDKFMrQ1rti3qM/6K1oa1\n",
       "fzx/5ilyv48QQtQBFUXF+7xXSm0KnAGciA2hK4DzMntCLS0tEjBCCFHjBg0apPI5r9gVbGdjh+TA\n",
       "hlDOoTghhBCiqMNxURS1KaXOAR7Ezo47p5jPL4QQorYUdThOCCGE6I5KWlBKCCFEnZEQEkIIUTYS\n",
       "QkIIIcom9RBSSo1XSj2ulHpMKbVX2r+/Himl/q6UekopNU0pNbHc7allSqldlVLPKqUuytgn7/kS\n",
       "y/G6y/u+xJRSVyqlHlZKPaKU0vG+br3fUy1g2t2yPqJoIuDgKIrmlLshdaA3cAGwC8h7PkWrvO4x\n",
       "ed+XWBRFJwAopfYETlVKnUQ33+9p94RWlvWJomgxMFspNTLlNtQjhQy9piKKooeA+Rm75D2fgoTX\n",
       "HeR9n6YFwDIKeL+nvZRDwWV9RI8sAG5SSs0DTomi6K1yN6iOyHu+fOR9n56jAZ8C3u9ph9A8YDCr\n",
       "lvWZl3Ib6k4URS6AUmpb4PfAt8rboroi7/kykfd9OpRS+2F7P6/Hpdu69X5Pu6sqZX3KawkkLNwk\n",
       "SqG9bpa859OVVK9M3vclopTaARgXRdEf4l3dfr+n2hOSsj7loZSaDAzHDk+cVObm1DSl1OnAN4C1\n",
       "lVIDoyg6Xik1CXnPl1SO113e96U3BZijlHoYeDmKIq+773cp2yOEEKJsZOaIEEKIspEQEkIIUTYS\n",
       "QkIIIcpGQkgIIUTZSAgJIYQoGwkhIYQQZSMhJIQQomwkhIQQQpTN/wMat40ugXR4twAAAABJRU5E\n",
       "rkJggg==\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111f0be80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pylab as pl\n",
    "\n",
    "pl.plot(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Markov assumption greatly simplifies the sequential decision analysis problem. If we had to model the process generally, we would be specifying:\n",
    "\n",
    "$$Pr(r_{t+1}, s_{t+1} | r_t, s_t, a_t, r_{t-1}, s_{t-1}, a_{t-1}, \\ldots, r_0, s_0, a_0)$$\n",
    "\n",
    "If we are able to assume conditional independence, then we can drop much of this, so the model becomes:\n",
    "\n",
    "$$Pr(r_{t+1}, s_{t+1} | r_t, s_t, a_t)$$\n",
    "\n",
    "By iterating this equation, one can predict all future states and expected rewards from knowledge only of the current state just as well as if one had the complete history up to the current time.\n",
    "\n",
    "## Markov Decision Process\n",
    "\n",
    "A Markov process where the transition probabilities can be influence by the actions of a decision-maker is called a Markov decision process.\n",
    "\n",
    "A Markov decision process (MDP) is defined by the available states and alternative actions, as described above, as well as by the state dynamics inherent to the environment.\n",
    "\n",
    "Given any state and action, $x$ and $a$, the probability of each possible next state, $x^{\\prime}$, is described by the **state dynamics function**:\n",
    "\n",
    "$$f(x^{\\prime} | x, a) = Pr(X_{t+1}=x^{\\prime} | X_t=x, A_t=a)$$\n",
    "\n",
    "These probabilities correspond to the elements in the transmission matrix, as described in the Markov chain discussion.\n",
    "\n",
    "For any current state and action, $x$ and $a$, together with any next state, $x^{\\prime}$, the expected value of the next reward is:\n",
    "\n",
    "$$r(x, a, x^{\\prime}) = E[r_{t+1} | X_t=x, A_t=a, X_{t+1}=x^{\\prime}]$$\n",
    "\n",
    "\n",
    "\n",
    "![MDP](http://fonnesbeck-dropshare.s3.amazonaws.com/markov_decision_process.png)\n",
    "\n",
    "\n",
    "In some real-world problems, the actual system state is not entirely known by the decision maker, rendering the states only partially observable. Such MDPs are known as **partially-observable Markov decision processes** (POMDP).\n",
    "\n",
    "The sequence of the decision rules to be used at each decision point can be summarized as a **policy**, which is a function that maps states to actions:\n",
    "\n",
    "$$\\pi_t : S_t \\mapsto A_t$$\n",
    "\n",
    "If the policy is stationary, then that $\\pi_t = \\pi$ (*i.e.* the policy does not change over time)\n",
    "\n",
    "We can denote the influence of a policy on the Markov transitions by:\n",
    "\n",
    "$$p_{\\pi}(X_{t+1} = j | X_t = i)$$\n",
    "\n",
    "Which implies that the state-specific decision at each step is taken from $\\pi$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value functions\n",
    "\n",
    "We can compare competing MDP policies by evaluating their performance in terms of value. A **value function** is a function of the system state that is an estimate of how good it is to be in that state. This value is in terms of *expected future rewards*. Since the expected future rewards, as shown above, are a function of the state-specific actions taken at each decision step, we can use the value function to discriminate among different policies that may be used to selection actions.\n",
    "\n",
    "The value of state $x$ under policy $\\pi$ is the total expected (discounted) system reward for starting in state $x$, and following policy $\\pi$ thereafter.\n",
    "\n",
    "$$V_{\\pi}(x) = E_{\\pi}[r | X_t=x] = E_{\\pi} \\left[ \\sum_{k=0}^{\\infty} \\gamma^k r_{t+k+1} \\big| X_t=x \\right]$$\n",
    "\n",
    "this is the state-value function for policy $\\pi$.\n",
    "\n",
    "Note that in some applications, the value function is in terms of state-action pairs, thereby describing how good it is to perform a particular action from a particular state, following policy $\\pi$ thereafter.\n",
    "\n",
    "$$Q_{\\pi}(x, a) = E_{\\pi}[r | X_t=x, A_t=a] = E_{\\pi} \\left[ \\sum_{k=0}^{\\infty} \\gamma^k r_{t+k+1} \\big| X_t=x, A_t=a \\right]$$\n",
    "\n",
    "Note that the value function can be written recursively:\n",
    "\n",
    "$$\\begin{aligned}V_{\\pi}(x) &= E_{\\pi}[r | X_t=x] \\\\\n",
    "&= E_{\\pi} \\left[ \\sum_{k=0}^{\\infty} \\gamma^k r_{t+k+1} \\big| X_t=x \\right] \\\\\n",
    "&= E_{\\pi} \\left[ r_{t+1} + \\gamma \\sum_{k=0}^{\\infty} \\gamma^k r_{t+k+2} \\big| X_t=x \\right] \\\\\n",
    "&= r(x, a, x^{\\prime}) + \\gamma E_{\\pi} \\left[\\sum_{k=0}^{\\infty} \\gamma^k r_{t+k+2} \\big| X_t=x \\right] \\\\\n",
    "&= r(x, a, x^{\\prime}) + \\gamma \\sum_{x^{\\prime}} f(x^{\\prime} | x, a) \\color{red}{V_{\\pi}(x^{\\prime})}\n",
    "\\end{aligned}$$\n",
    "\n",
    "This expression is the **Bellman equation** for $V_{\\pi}$. The Bellman equation averages over all the candidate next states $x^{\\prime} \\in X$, weighting each by its probability of occurring as specified by the state dynamics function. \n",
    "\n",
    "It states that the value of the start state must equal the (discounted) value of the expected next state, plus the reward expected along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing MDPs\n",
    "\n",
    "In order to solve our decision analysis problem, we have to identify a policy that maximizes the long-run expected rewards. We now have a way to achieve this: *optimize Bellman's equation*.\n",
    "\n",
    "An optimal policy $\\pi^*$ maximizes $V_{\\pi}(x)$ for all $x \\in X$. The value function under this policy is the optimal value function:\n",
    "\n",
    "$$V^*(x) = \\max_{\\pi}V_{\\pi^*}(x)$$\n",
    "\n",
    "Bellman's equation allows us to approach the optimization problem into smaller, recursive sub-problems. In fact, Bellman's **Principle of Optimality** states this explicitly:\n",
    "\n",
    "> An optimal policy has the property that whatever the intial state and initial decision are, the remaining decisions must constitute an optimal policy with regard to the state resulting from the first decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Iteration\n",
    "\n",
    "There are 2 fundamental DP algorithms to solve infinite-horizon discounted MDPs: \n",
    "\n",
    "1. value iteration \n",
    "2. policy iteration  \n",
    "\n",
    "Value iteration starts with an arbitrary value for each state and, at each iteration, solves Bellman's equation using the value from the previous iteration until the difference between successive values becomes sufficiently small.\n",
    "\n",
    "It starts with an **arbitrary decision rule** and finds its value; if an improvement in the current decision rule is possible, using the current value function estimate, then the algorithm will find it; otherwise, the algorithm will stop, yielding the optimal decision rule.\n",
    "\n",
    "in many situations, the stationary assumption is not reasonable, such as when the transition probability represents the probability of a disease outcome that is increasing over time or when agedependent mortality is involved\n",
    "\n",
    "Policy iteration algorithm finds the value of a policy by applying the backward induction algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Iteration\n",
    "\n",
    "Consider a simple, contrived example of a taxi driver attempting to maximize fares. The taxi serves two adjacent towns: A and B. Each time the taxi discharges a passenger, the driver must can choose from two possible actions:\n",
    "\n",
    "1. **Cruise** the streets looking for a passenger.\n",
    "2. Go to the nearest taxi **stand** (hotel, train station, etc.)\n",
    "\n",
    "Passengers picked up while cruising tend to stay in the same city, while those from the taxi stand have  higher probability of moving to the other city. \n",
    "\n",
    "City B pays higher fares, than city A.\n",
    "\n",
    "Cruising fares are higher than standing fares in city A, while the opposite is true in city B.\n",
    "\n",
    "*What is the optimal behavior in each state?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# States\n",
    "A, B = 0, 1\n",
    "CRUISE, STAND = 0, 1\n",
    "\n",
    "# State transitions\n",
    "T = {CRUISE: {\n",
    "    A: {A: 0.9, B: 0.1}, \n",
    "    B: {A: 0.1, B: 0.9}\n",
    "},\n",
    "    STAND: {\n",
    "    A: {A: 0.4, B: 0.6}, \n",
    "    B: {A: 0.6, B: 0.4}\n",
    "}}\n",
    "\n",
    "# Rewards\n",
    "R = {\n",
    "    CRUISE: {A: 8, B: 20}, \n",
    "    STAND: {A: 5, B: 22}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states = [A, B]\n",
    "actions = [CRUISE, STAND]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to intitialize the data structures for storing values, indexed by states and actions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "V = {}\n",
    "V2 = {}\n",
    "logs = {}\n",
    "\n",
    "for s in states:\n",
    "    logs[s] = {}\n",
    "    for a in actions:\n",
    "        logs[s][a] = []\n",
    "             \n",
    "for s in states:\n",
    "    V[s] = 0\n",
    "    V2[s] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model parameters, including tolerance for convergence and the desired discount rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convergence criterion\n",
    "epsilon = 0.0001\n",
    "# Discount rate\n",
    "gamma = 0.8\n",
    "# Maximum number of iterations\n",
    "max_iters = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 56\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(max_iters):\n",
    "    for s in states:\n",
    "        \n",
    "        value_candidates = []\n",
    "        for a in actions:\n",
    "            value = R[a][s] + gamma * sum(T[a][s][s2]*V[s2] for s2 in states)\n",
    "            value_candidates.append(value)\n",
    "            logs[s][a].append(value)\n",
    "            \n",
    "        # Choose the largest candidate value\n",
    "        V2[s] =max(value_candidates)\n",
    "        \n",
    "    # If there is no change from the last estimate, we are done\n",
    "    if max(abs(V2[s] - V[s]) for s in states) < epsilon:\n",
    "        break\n",
    "    else:\n",
    "        V, V2 = V2, {}\n",
    "        \n",
    "print(\"Iterations: %i\" % len(logs[A][STAND]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: A Action: CRUISE --> 67.473360\n",
      "State: A Action: STAND --> 72.368097\n",
      "State: B Action: CRUISE --> 92.104939\n",
      "State: B Action: STAND --> 86.210202\n"
     ]
    }
   ],
   "source": [
    "for s in states:\n",
    "    for a in actions:\n",
    "        value = R[a][s] + gamma * sum(T[a][s][s2]*V[s2] for s2 in states)\n",
    "        print(\"State: %s Action: %s --> %f\" % (['A', 'B'][s], ['CRUISE', 'STAND'][a], value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x11894cac8>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAaEAAAECCAYAAABXIGiCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xd8W9X5+PGPnTiDkAkkBBISmpTDCFBGCWAggxFCEYIa\n",
       "LFpGKYThb6BfqNgkLrjQQkHwLaQVBcr6lVIb3CAEhE0ZZhYokAIPe+8QyB6O/fvjXMU3ira1rPu8\n",
       "Xy+9JN17de85dqLH59xznlPV2dmJUkopVQrVpS6AUkop79IgpJRSqmQ0CCmllCoZDUJKKaVKRoOQ\n",
       "UkqpktEgpJRSqmR6pzvAGDMRuFREphhjxgE3Ax3AfBGZ6RxzInASsBq4RETuLVyRlVJKVYqULSFj\n",
       "zFnA9UBfZ9OVwPkiMgmoNsb4jTEjgNOAPYADgd8bY2oKWGallFIVIl133DvAYa73u4jIk87recD+\n",
       "wG7AUyLSLiKLgLeBHfJeUqWUUhUnZRASkblAu2tTlev1YmAQMBD43rV9CTA4XwVUSilVubIdmNDh\n",
       "ej0Q+A5YhA1G8duVUkqplNIOTIjzkjFmHxF5ApgOPAq8AFxijOkD9Ae2BuanOc8Kuu4zKaWUqhxV\n",
       "6Q/pkm0QOhO43hl48AZwp4h0GmOuBp5yLn6+iKxKc56+2Ra0gnSidfcar9YbtO5erXvGqkqURdvL\n",
       "vxytu/d4td6gdfdq3TOmk1WVUkqVjAYhpZRSJaNBSCmlVMloEFJKKVUyGoSUUkqVjAYhpZRSJaNB\n",
       "SCmlVMloEFJKKVUyGoSUUkqVjAYhpZRSJaNBSCmlVMloEFJKKVUyGoSUUkqVTLZLOSilctDmr6vC\n",
       "ZlSuTvJw769Ksi3Z+/gHKd4nek3c60Tbcnq9wxWX8eqZ5/yY9SXLLp3t9lSy/UxeM15vf+klvHbu\n",
       "BXvm85x58FZtpPWbUhfCTYOQ6jHa/HXVwAbAAOe5f4Lnftj1quKf+wJ9XI+auNexR++4172cZ/ej\n",
       "V9wjth5Klev1WjVDhwB8il2ZOPbodB5rnOf47R1xz9k+SPE+0WviXqd7zuj1Jy13AswisWTryGS7\n",
       "PRcFP9dnkSjAr/N4nXy4DZhb6kK46XpCxefJurf566on3nbLmueO+sV4YJjz2Mh5HoJdIn5w3PMg\n",
       "YENscAH7hbwMWOo8LwOWO4/Y6xXAStfzStf7VQkeqxM82l3P7dhA4X69xvW6ozbSmu4/kSd/5w6t\n",
       "u0pJg1DxVVTd2/x1fYHNgNHAKGBzYFNgODDCeWwMVPcftfmmyz/5tA34Nu6xEFgEfB/3vNh5rMjg\n",
       "i76cVdTvPEtad5WSBqHi61F1d7rANgfGA+Ncz1sCI7GtgU+Bj4FPnNdfAF8BXzqPb2ojrbFupx5T\n",
       "9zzyar1B6+7VumdMg1DxlWXdnWAzFpgAbO88TwA2wQaXd4B3ned3gA+Az2sjre1ZXKYs614EXq03\n",
       "aN29WveMaRAqvpLX3RmptSWwOzDReYwFPgTmA685z/OBL/PYFVbyupeIV+sNWnev1j1jGoSKr+h1\n",
       "b/PX9QZ+DEzBBp6dgc+BZ4HnnMe7tZHWjgIXxau/d6/WG7TuXq17xjQIFV9R6t7mrxsHHADsj23p\n",
       "vAI8AjwDvFwbaV1e6DIk4NXfu1frDVp3r9Y9YxqEiq8gdXfu6ewB1AM/wY44e8h5PF0baV2Z72vm\n",
       "wKu/d6/WG7TuXq17xjQIFV/e6u7c2/kxEAAOA94GmoG7y21WtMOrv3ev1hu07l6te8Y0Y0IP1Oav\n",
       "Gw2cDBwJfIQNPBNrI61fl7RgSimVJQ1CPYTT6pkEnAbsAFwP7FUbaf2ipAVTSqlu0CBU5tr8dQOA\n",
       "o4GZ2Imf1wD3OpM/lcpYUzCaaTLTvCUwPeeS6Vx2wbyBCYpTjglM83qus347jctnPzAsj2XIh0WN\n",
       "IV82c/sKToNQmWrz122AbfX8DxAFArWR1jdKW6ry0hSM9sLmlUuVwDT2uk+KR3cTmLof1a7naqDX\n",
       "xiM25Jsvl7xJ4szZ7tcxCROhZrAvk+OLkcB0reuvegLgxWw+k2J7Mrnc2C74zfCb57QBPFmKa6cQ\n",
       "Am4q4fXXowMTii9l3dv8dTXA8cA5wF3A7yvoXk9nUzBajU1Kmk0C0wFxz7HM1Z2sm7w0lsA0URLT\n",
       "WALT1WSfwNT9WJPhoyP2fNZvp31z+ewHBpM6i3ZnY8jXk/PjJaP/11VKGoSKL2HdnSHW9cCFwNPA\n",
       "hbWR1o+KW7TcON08m5A8gekIYPiGg/pus2TRyi+wSUmzSWC6FFjiPJaVW3dCBvTfuzd5ue4Z0+64\n",
       "MtDmr9sTe6/nA+Cwcut2c4LMpqyfwHQUNnv2AOBr1k1g+iV2yHgskelXZ8ze/5uq6qqRRa+AUqps\n",
       "aUuo+NbW3bnvczEwDTipNtLaVsqCOfdYxrFuElODbdV8ybpJTD/AyZzdGPItzvASXv29e7XeoHX3\n",
       "at0zpi2hEmnz1+0NXAdEgF1qI60rinn9pmC0NzbQ7A7shh32vRnwHl0JTP8EvAl8WaH3K5RSJaYt\n",
       "oSJbs2JF57OBo64GpgIn1EZany/GdZuC0Y2BfbBBZ3fgh9hAE0tg+grwcYGDjVd/716tN2jdvVr3\n",
       "jGlLqIja/HV79N98M7A32HctZD63pmC0L7AnXUlMhwCPYROY3gy82RjyFTprtlJKpaQtoSJp89cd\n",
       "B1ywwxWXjR/4w/EFqXtTMDocqAN8wI7YFs6DwEONId+7hbhmljz3e3d4td6gdfdq3TOmLaECa/PX\n",
       "9QIuBWqBvQb+cHxe0+w0BaMbAT/FJjHdEmjFDnZ4vgcOZVZKeUzWQcgY0xu4BbsSZztwInbC3c3Y\n",
       "SXjzRWRm/orYc7X56wYBtwPfAFPy1f3mdLUdARwFbI2d1DoLeE4HECilepJcWkIHAb1EpNYYsx/w\n",
       "O2yKk/NF5EljTNgY4xeRSF5L2sM4i8rdhQ3YoXwskd0UjI4CTgGOwS5Q9zugTe/tKKV6qlyC0FtA\n",
       "b2NMFTa9ympgoojEciTNw94I92wQavPXTcLmZ/pVbaT1nu6cy5koug9wKrATNnv2zo0h34JuF1Qp\n",
       "pUoslyC0BHvv4U1s7i8fsLdr/2JscPKkNn/dFGygOKQ20jo/1/M4wecQbBqfb7EZFY5sDPk0e7ZS\n",
       "qmLkEoTOAO4XkQuMMZsD/8JmIo4ZCHyXwXkq7t7FojfepO+I4Ww7+wI2GD3qtRSHpqz7B+9+w+Zj\n",
       "htKvf2+mTt+akaOGgJ1XVAkq7veeIa/WG7TuXpPViMBcgtC32C44sMGmN/CyMWaSiDwOTAcezeA8\n",
       "FTV0sc1f92PsCqeHbjB61KspDk06bLMpGN0Ze59nEHBeY8j3eN4LWlpeHbLq1XqD1t2rdc9Y1vOE\n",
       "jDEDgBuBkdgBCf+HXS/kBuf9G8CJIpLqxBX1y2nz1/0I+CdwRG2k9cU0h69X96ZgdDRwObAdcAEQ\n",
       "rdBRbhX1e8+CV+sNWnev1j1jOlm1m9r8ddthF507qjbS+kwGH1lbd+e+zwxs4GkCbqnwez4V83vP\n",
       "klfrDVp3r9Y9YzpZtRva/HU/BO4GfplhAFqrKRgdgx3AsBzYozHk+7wARVRKqbJWXeoC9FRt/roR\n",
       "wH1AQ22kNeN7N50dnTQFo6cAj2Mn+B6qAUgp5VXaEspBm7+uNzYTwu9rI60PZvq5pmB0zNjxG4Gd\n",
       "R7V7Y8iX1xQ+SinV02hLKDe/Bd6rjbTemOkHmoLRvYHHdp44BuBwDUBKKaUtoay1+ev82OUR9sr0\n",
       "M03B6AnAOcChE3be/JUJO29eiSPflFIqaxqEstDmrxuPHZK+b22kdXm6453VS/8A/BjYqzHk+6rA\n",
       "RVRKqR5Fu+My1Oav2wC4AzitNtL6Xrrjm4LRIcA92BRG+2oAUkqp9WkQykCbv64K+DNwbyYJSZuC\n",
       "0R8CTwH3AzMaQ75VBS6iUkr1SNodl5kZwCjghHQHNgWjWwP3Aqc2hnzzCl0wpZTqyTRjQhpt/rod\n",
       "sCl59qiNtH6d6timYHQc8ABwUmPIlyx/Xo+pewF4te5erTdo3b1a94xpd1wKbf66auAvwMwMAtAY\n",
       "7FpKp6YIQEoppVw0CKV2IvBhbaT1gVQHNQWjm2NbQGc1hnz3F6VkSilVAfSeUBJOWp7zgD1THdcU\n",
       "jI7ABqDGxpDPs6vJqu6pb26owv5RWI3twok9x7/O5EGK94leE/c63XPGr6+a/hvOmHfR1gmqnKyb\n",
       "Ktvuq1y6u4rRRVZ1xbRZnPnAxdsX4VrZ+LAlEF5U6kK4aRBK7grgitpI62fJDmgKRjcGHgT+0Bjy\n",
       "tRStZB7mfFn3BzZwnuNf9wP6Jnjui118MdGjBvt/oSbudW+gl/PsfvRyPcc/qp3ntTdbB/cbxPcr\n",
       "FiXLD9jpeu5wnuNfxz9S7euMO2ei94leJypP/LZE+xMdv9YNL94OEE60L8U1kkl2TD5vbOftXLf+\n",
       "pxUglK/zJZFteW/ErntWNjQIJdDmr9sX2Bo4LtkxTcHoAOw9oD81hny3FqloPdqajjX87I5TNwGG\n",
       "OY+NnOch2PlUg5zn2OtBwIbAAGygiVkOLHOe41+vcB4rXc+x10uwCzKucj1WJ3i0u57jH2syeHS2\n",
       "BMLxX7Ajc/7B9WydwJRSF6JEOrHZVVQKOjouTpu/rh/wEnBMsgXqnHWAbgXebwz5GrO8RNnWPRdO\n",
       "y2QYMBo7jH1zYFNgODDC9Ri4Uf+hmy5YvvBV7Oq87sdCYBHwfdzzYuexFFjeEgh3FK9meVVRv/Ms\n",
       "ad1VStoSWt/ZwENpVkg9Bfsle1xRSlRi9c0NQ4BxwHjX81hs4BkILAA+Bj4BPgW+AF4DvgS+cp4X\n",
       "hw/5XQewY5GLr5QqYxqEXJxF6n4B7JTsmKZgdDfg19iF6CpqFdT65oaNgQnA9s7zBGBLbGvkXeAd\n",
       "57kV+AD4uNxuciqlehbtjnM4qXkeAK6vjbTekegYZyDCM8BRjSHf8zleqizqXt/csAkwEdgd2A3Y\n",
       "FtsFNh/bipnvPN5rCYTzFWzLou4l4NV6g9bdq3XPmLaEutRjbyrfmWhnUzDaC7gNuLIbAagknPs2\n",
       "22FvEO+ODT6rgeecx7nA6y2B8IqSFVIp5UkahFi7UupFwGG1kdZkTcPZ2Psb1xatYN1Q39ywKbAf\n",
       "dhXXycBHwCPYARWntgTCC0tXOqWUsjQIWUcCL9dGWt9ItLMpGJ0OHAbs2RjyleWCdE5rZwIQAHzY\n",
       "eTEPY+/fnKb3bpRS5cjzQajNX9cLOB84ItH+pmB0NHYZh2mNId/SYpYtE/XNDdtgA88R2Hs6zYC/\n",
       "JRD+oJTlUkqpTHg+CGHvBc2vjbT+N8n+OcBFjSHfW0UsU0rOKLbjgaOwEy6bgYNaAuEPS1owtR5f\n",
       "MFJ91x98HHp2tA9daXni0/Mke93j0/ZcdupenDPnqVrWl23anrJNz5Nsx+8aajk/3Da5CGXIxhvR\n",
       "kP/LUhfCzdNByMmSfQHws0T7m4JRP3b2/i3FLFcy9c0NOwOnAVOx93Z+2hIIv1vaUhWPLxjpw7oZ\n",
       "FPoneE6UrqcfyVP2xNL2xKfsSZe2p1eCIlaxfiqazhmXPATwFjbdTuwRS5uzhq5UPInS9mSSoqeQ\n",
       "aXtSpedJm3Yn8sS7AGdk85kU25PJpYu84N3q9z/zAcDJWX6s0OX6B3B3ga+RFU8P0W7z19UDgdpI\n",
       "a138vqZgdEPgP8DBjSHfm3m8bFZ1r29u6APUAadiv/jmAHe0BMIr81imgvMFIzX/78IDVx1z4f3b\n",
       "0JWux522J5ayx/0cS9sT+8Jfic2esJTc0vbE0vTkJW1PNOTP9D9PWfx7LxGtu0rJsy0hpxU0Czg2\n",
       "ySEXArfnOQBlrL65oQa7outZ2KXCT28JhF8oRVlS8QUjA7Dpetxpe9zpeoYDQ4H22X95Guz9tfi0\n",
       "PR+TPG3PkmjI3168GimlismzQQg72u292kjrf+J3NAWjOwIHkyJzQqHUNzdUY0fr/QZ4EpjUEgh/\n",
       "XOxyxPiCkd7AGNZN2TMOm0lhOLYV8gnrpu15G5uqJ5a2Z6HTaujEdiUqpRTg0SDktIJmY2/ur6Mp\n",
       "GK3GzgX638aQb3mxyuQMsZ4OXIJNj+NvCYSL1gpzgs04ulL2xJ43BD6kK23PS0ALNm3PV9GQv6cm\n",
       "FVVKlQFPBiHgEODj2kjrSwn2nQh82BjypVxNNZ/qmxt2BK7B3rs4qdDdbr5gpBrYinXT9myGDTKx\n",
       "tD1/BOZHQ/5vC1kWpZS3eS4IOTniZpNg1IqzSup5wB7FKIsz6OA87FDr01oC4YIEPmdU2R50pe3Z\n",
       "AXgfeBZ4DLgU+CiLG+1KKZUXngtC2Hs9X9RGWv+dYF8IuLwx5Eu2Cmbe1Dc37IRd5fBpYJeWQHhx\n",
       "vs7tC0aqsIvyHYBN27MT8AI2bc8s4NVoyL8qX9dTSqlceTEInc+68xYAaApGpwKxpRwKZvWa1Rx1\n",
       "569+i50ke0pLIPxYPs7rC0Z6AXtjsydMBz4DHgJ+DzwfDflX5+M6SimVT54KQm3+uh2A3rWR1mfd\n",
       "252VUi8FTivkGkH1zQ07jhm8Odh5MLu0BMJLunM+597OntjAcwj2Xk4zcF405P+um8VVSqmC81QQ\n",
       "wg46uD7B9unAgsaQ77lCXbi+uaEOuPy4nevZbvhWv+rOuXzByJbY1V2PwM7EbwYaoyG/ZsZWSvUo\n",
       "nglCbf66/sCh2O64tZxW0IVAtwJDMs7Q69nOtSdvN3yrnPK7Ofd59sOm7TFAGNgtGvJ/k6+yKqVU\n",
       "seUUhIwx52K7f2qwM+CfAG7G5rmaLyIz81XAPDoceKA20ho/AOBAYGFjyPdsgs90S31zwwbATdif\n",
       "894tgXDWWbh9wcgg7H2qBuzcnGuAB3R+jlKqEmQdhIwxk4A9RGRPY8wA4EzgSuB8EXnSGBM2xvhF\n",
       "JJLvwnbTidgUOGs5raDfAL/O98Xqmxs2B+4C5gEXtgTCWQUNXzCyIXYAxYnYNYEOiYb87+S7nEop\n",
       "VUq5tISmAfONMXcBA4GzgRki8qSzfx52WHDZBKE2f93W2MEA8ctyHwAsagz5ns7n9eqbG3YDbgcu\n",
       "aAmE/5HNZ33BSF/gJCCIvdfzI50wqpSqVLkEoY2BLbDzbX6ATQte7dq/GPuFX05mANe7l+52tYLO\n",
       "SvqpHNQ3N+wB3AYEssl84Ayx/jnQiJ3PUxsN+T/NZ9mUUqrc5BKEFgBviEg78JYxZgU2e3LMQKBs\n",
       "hge3+ev6Yufk7Bi3az9gWWPI15avaznr/fwdOKwlEF4vMWoyvmBkH+wSDa8DB0VD/rfzVSallCpn\n",
       "uQShp7Ajya4yxmyGXWDsEWPMJBF5HDvc+dEMzlOUFDFbnflrFv77RbY641dru7Q6OzsZPXYoU3+y\n",
       "Td7K8dF3nzJ8wEacvscMxm809uU0h3cCLF/Zzq33vs7YkYM4rf5HbLXF0O2xc34qmVdTA3m13qB1\n",
       "95qs1lDKOgiJyL3GmL2NMc87F4uN2rrBGFMDvAHcme+C5uqtK658GLhoqzN+FbtnxW/PvGdf4IIx\n",
       "P9goL8sK1Dc3bA3cBxw7fqOxT6U5vBOo8gUjU7DZupuBS7baYmiPWqQuR15d5Mur9Qatu1frnrGc\n",
       "hmiLyLkJNk/uXlHyr81fNw4YiW29AevcC5qdj2vUNzeMB+4BZrQEwukCEMtWrCZwwX1/xiYUPTIa\n",
       "8qdrNSmlVMWq9MmqJwB/dQ9IwAbLjsaQ7/Hunry+uWEMdjTgqS2BcNouSF8wsvfIjQeAXextoiYR\n",
       "VUp5XcUGoTZ/XQ12tNmucbtmAU3dPX99c8Mw4H7grJZA+P50x/uCkRnAWeccsyvjRg25qLvXV0qp\n",
       "SlCxQQg7hPzZ2kjr2rQ2TcGowQ4x71bmamcJ7r8Bf2oJhO9KdayzYukV2OUU9ho3ashX3bm2UkpV\n",
       "kur0h/RYiZKVngRc3xjydXfEygXYYeh/SnWQLxgZih2wMADYPxryf93N6yqlVEWpyJZQm79uU+za\n",
       "QGtbPE3BaD9s1ukdunPu+uaGA5zz7NkSCCcNZr5gZCtgLnAdcLWuWqqUUuuryCAE+IG7aiOt7nxt\n",
       "PwUebgz5cp5IW9/csAXwF2B6qrWAfMHIvsANwCnRkL8gS3YrpVQlqNTuuMOwrRC3k7GtkpzUNzf0\n",
       "Be4Azm4JhN9MdpwvGNkfO/9nugYgpZRKreJaQm3+usHAtsDapRmagtGtgSFAdxatuxJoawmE70h2\n",
       "gC8YmYRd52e6pt5RSqn0Ki4IAQcB8+K64k4Crst1QEJ9c8PR2HtJSTMs+IKRPbBrBx2sAUgppTJT\n",
       "iUHoMODG2BtnQMLhwPa5nMxJydME7NUSCK9OdIwvGNkVmzn7sGjI/3ou11FKKS+qqHtCbf66fsCe\n",
       "rDsPqA47IOH7bM/nLM39F+CMlkD4s0TH+IKRHYAWIBAN+V/JvtRKKeVdFRWEgH2BJ2sjre5koCdj\n",
       "A0kujgUWtgTCCRfo8wUj22BXTz0mGvJnvHaQUkopq9K64w7DBgUAmoLRbYBBrL+ialr1zQ0bARcC\n",
       "kxLt9wUjI4EocEI05M/bmkRKKeUlFdMSavPX9cIu1z3Ptbk7AxIuA+a0BMIfxe/wBSM12CUYLoyG\n",
       "/N1KAaSUUl5WSS2hPYHXaiOtiwCagtH+2AEJE7I9UX1zw17YxKcNSQ75PTA/GvL/LceyKqWUorKC\n",
       "0DpdcdgBCQ9mOyChvrmhBvgzcHKi0XC+YORwYG9gn26UVSmlFBXSHdfmr6sCDgHudm3OdUDCr4Gn\n",
       "WwLhZ+J3+IIRA1wO1EdDfi+shKqUUgVVKS2hHYDPayOtXwI0BaPjgMFAViPW6psbxgKnADvH7/MF\n",
       "IwOwaXsaoiH/h90tsFJKqQppCbF+V9wRQEs2AxKcOUFzgNktgfBC9z5fMFKFzTvXGg350y5gp5RS\n",
       "KjOVFITcCUsPB+7M8hyHAv2xmQ/iNQDDgN/mVDqllFIJ9fjuuDZ/3Q8AaiOt7wE0BaM/APo0hnxJ\n",
       "M13Hq29u6AVcDBwZv0aQLxjZCTgd2CMa8nck+rxSSqncVEJL6FDWHxWXbSvocOD1lkD4NfdGXzDS\n",
       "C9sNd0o05F/QrVIqpZRaTyUEofiuuCPIIgjVNzdUA7NI3NXWALwZDfkf7VYJlVJKJdSju+Pa/HXD\n",
       "gZHAKwBNwehYYIPGkC+bTNZ1wNstgfCr7o2+YGQz4ExgYn5Kq5RSKl6PDkLAgcB9tZHW2H2crLri\n",
       "nFbQbGyi0nhXAb+LhvxfdruUSimlEurp3XGTAXdXWVZdcdj7Se+1BML/cW/0BSMHAqOBG7pbQKWU\n",
       "Usn19CC0D/AEQFMwugU2Y/Z/M/mgqxXU5N7uC0b6A3/EDkbQ0XBKKVVAPTYItfnrxgBLaiOt3zqb\n",
       "6oA7s5igegjwcUsg/FLc9llAJBryv5rgM0oppfKoJ98TmgT8y/X+CGzKnbSc7AiNwInu7b5gZFug\n",
       "HvhRfoqolFIqlR7bEsLeD/oXQFMwOhoYCryW4ni3g4HPWgLhF2MbnNQ8YeDX0ZB/aV5LqpRSKqGe\n",
       "HITW3g8Cfgq0ZtIV52oFXRS36xjg22jIH81rKZVSSiXVI7vjEtwPOgI4NcOPHwR83RIIr82w7ayU\n",
       "OguYnteCKqWUSqlHBiFc94OagtHNgU1wJqxm4HwgGLftWOCpaMj/br4KqJRSKr2eGoQm07WAXTZd\n",
       "cTsANS2B8LOxbU4r6By0FaSUUkXXU+8J7U3X/aBsJqieiE1I6nYM8LS2gpRSqvh6XEuozV+3BbC0\n",
       "NtL6bVMwOhLYFHg53efqmxs2APzAebFtrlbQTwpUXKWUUin0xJaQe37QIcBdGU5QPQK4ryUQXuLa\n",
       "djTwbDTkfye/RVRKKZWJnFtCxpjhwL+B/YA1wM1ABzBfRGbmpXSJTQZiw6gPBi7P8HMnAafF3viC\n",
       "kd7Auc45lFJKlUBOLSFjTG/gWmCZs+lK4HwRmQRUG2P8eSpfIvsATzQFoxsAOwNPp/tAfXPDBKBv\n",
       "XIqeo4DnoiH/24UpplJKqXRy7Y67Aptd4DOgCthZRJ509s3Dto7yzn0/CJgCPN4Y8rVn8NF1BiQ4\n",
       "raDzsEt6K6WUKpGsg5Ax5jjgKxF5CBuA4s+zGBjc/aIl5L4f9BPgnnQfqG9u6I9dffV21+afAy9E\n",
       "Q/638l1ApZRSmcvlntAvgQ5jzP7AjsCt2MmiMQOB7/JQtkQmA9GmYLQKO69nVgafORx4oCUQXgxr\n",
       "W0HnY0fKKaWUKqGsg5Bz3wcAY8yj2MzVlxtj9hGRJ7DB4dFkn3fJdMmFtfqN3JQdLr/0+PGLO7nv\n",
       "n6/xy1NrF6T7zNYbj+PYHx0OMAPgjJ/tzEtvfsWZR+/yZrbXz6Os615BvFp3r9YbtO5eU5X+kC75\n",
       "mid0JnC9MaYGeIPMJo9mVVDnftDdNQMH/ugvF0bPw47EuyzVZ+qbG7YFbjv/4ct2bgmEO51M2a8B\n",
       "R5x59C5vZHP9POoky7pXEK/W3av1Bq27V+uesW4FIRGZ6no7uXtFSct9P+hg7JDrdE4ErmsJhGN/\n",
       "jewNfB4N+UsVgJRSSrn0pIwJk7H3gzbGZkl4PdXB9c0N/bCrrW7v2nwKdmi5UkqpMtCTMibE1g+a\n",
       "DszLIEtCHfBQSyD8PYAvGNkY2JOuxKdKKaVKrEcEoTZ/3Wi65gdlNDQb213nTlZ6HPC3aMi/Ov8l\n",
       "VEoplYseEYRw7gc1BaM12Ps6/0p1cH1zw5bARsDzAL5gpBo7Ou76whZTKaVUNnpKEKoFnnKe/90Y\n",
       "8q1Ic3wdcIdrQMIU4L1oyP9hAcuolFIqSz0lCG0PvErmXXF1QKvrvQ5IUEqpMlT2QajNX1cF/AB4\n",
       "FxuE7kt1fH1zwyhgCPBfAF8wsimwS7rPKaWUKr6yD0LAZsCXj4w/biywojHk+zTN8YcBc11dcccD\n",
       "t0RD/kwSnSqllCqinjBPaAIwn+y64oIAvmCkFzYITS5U4ZRSSuWuJ7SEtsMGoYNJE4TqmxuGA6OA\n",
       "2LpBBwDzoyH/JwUtoVJKqZz0hCA0YWnNoPeArbEruaZyKBBxdcWdDPylkIVTSimVu54QhLZ7fcTe\n",
       "w4BHGkO+jjTHrh0V5wtGRmFbUQ8WuHxKKaVyVNZBqM1fVw1ssajvxruSflTcUMAAzzqbTgBuiob8\n",
       "awpbSqXVtN1xAAAYeklEQVSUUrkq6yAEjAE+oqpqCunXKDoEuKclEO5wBiT8Arix0AVUSimVu3IP\n",
       "Qtst7jPsA2BxY8iXbgE79wTVSdgBCV8UsnBKKaW6p9yD0ITPBv2wA3gk1UH1zQ0DgR8BTzqbjgT+\n",
       "UeCyKaWU6qZyD0LbLRgwahPSd8X9BLi/JRBu9wUjNdjlHqIFL51SSqluKevJqp0wYXnvAZvQ1cJJ\n",
       "pg64wXm9L/BcNORfXNDCKaWU6raybQm1+et6La0ZvDlUfdQY8iUNKPXNDRsAuwOPOZsCQHMxyqiU\n",
       "Uqp7yjYIAeO+2XCLRVRVpeuKmwY82hIIr/IFI32B/YF7C188pZRS3VXOQWjCNxuMriL9/SD3qLhp\n",
       "wBPRkH9ZQUumlFIqL8o2CHVQNWFJ36HDgGeSHVPf3NAXm5w0lhVBu+KUUqoHKdsg9F3/EbXVnWve\n",
       "bwz5lqc4bArQ1hIIr/AFIxtg5wfdX5wSKqWU6q6yDULf9xuxI+kDyoF03f85CHg4GvKvLGjBlFJK\n",
       "5U1ZBqE2f12f7/oPH7y6V7906wcdADzkvNauOKWU6mHKMgit7NV/28V9N6oGXkh2TH1zwxbA6pZA\n",
       "+HNfMLIhdpj2w8Uqo1JKqe4ryyD0xcAfHNy3fennjSHf6hSHHUDXgAQfMC8a8qc6XimlVJkpy4wJ\n",
       "S/oOm9p/9eJ0C9hNo2vBuiOBqwtbKqVUoRljzgH2A2qANcBZIvKSMWYCMFREkmZPMcbMFJE/ZXGt\n",
       "uwFE5JAMjh0JvAMcKyKtKY7rCxwtIn+dO3cu55577sEiku62QqrrjgJCwCZAf+BF4HQRaTfGrAKe\n",
       "AqqwP69q4Gci8qEx5n3AiMgq5zwGuFZEphhjbgJuF5EHjTG/AI51naNJRB4yxvwG+DnwqbOvE3hI\n",
       "RH6fa12SKcuW0NKawRMGrPo+6YTT+uaGXsAewFO+YGQINnnp48Uqn1Iq/4wx2wCHiMj+IjIZOAP4\n",
       "q7O7Dtg2zSlmZXGt0cAAYLAxZmwGH/kl8EdgZprjRgIzAA477DC6GYCqgQhwuYhMFZE9gHagyTnk\n",
       "G2f7FBHZC7gZCDr7Otc7Ydw2Y8wg7M9smohMBY6g6+cNEHKdf2ohAhCUYUuoKRjt16f3gKGbLn4v\n",
       "kuKwHwOvtQTCK3zPRwLAPdGQv71IRVTKE3zByDxgx+6cY9igvny7aOVnzttXoiH/9BSHfw+MNsYc\n",
       "D9wvIq8aY3YzxmwGHAesNMa8iF1nbCb2+6sTOAw4BRhmjJkDnA5cC4zH/qE9W0Ti/0g9HrgLWO6c\n",
       "66w0VTka2BuIGGO2FZHXjTH9gJuc8tQApznn3cYYM+u0007jmmuuOUlErjPGXAHs5ZT37yJyjdMi\n",
       "WQmMBTYFjhOR/7iuuRfwkYi4e4XOpqvxUBVXxjHAwiT7ElnplLvBGHOviLxnjBnn2p/JObqt7IJQ\n",
       "n/Zl+wxcuWD1AXfe+G2Kw9z3gwJAQSK0Ul6WJmBkqhPYLJMDReQzY8wh2C/z3xhjlgKzROSfxpib\n",
       "gc9F5N/GmP2Ag0RkhTHmWuxf8r8zxpwqIqcaY04BvhaRGcaYYcATwITYdYwxVdiupolABzDfGDNL\n",
       "RBJO7zDG7Au8JiILnMBxKvA/2MD3voj8zPny/glwMTBBRC6eM2fOb53P/wQYKyK7G2N6A08aY2K5\n",
       "Lj8QkVOMMTOAk5zzxmwGvBf3M1rlejvMGPMoMBgYhs0cc4mzL21LSERWGmOmYlucpxljaoDLsAEc\n",
       "4NfGmABd3XGXiEjKZXVyUXZBqHfHqsMHrVzwQZrDpgEn+oKRjYBtgLaCF0wpVVDOF/liETnBeb8L\n",
       "MM/5onX7GrjFCVJbA0/H7d8e2MsYMxH7BdrLGDNMRGJ/2E4DNgT+7uyPBaWbkhTtRGBLY8x9QF9g\n",
       "B2PMuYAB7gMQkXeBq40xYxJ8fhuclQCceznP0dW1+LLz/DGwZ9znPsR2Q67lBNU9nW6+BSIy1Qmq\n",
       "NwOrRCSWsmy5U9ZY0NrQ2eY+10hgAxE5zXk/HnjAGBO77xYSkeuS/EzypuzuCbVX95k0ZPmXzyXb\n",
       "X9/cMATYHHgD2wy/KxrydxSrfEqpgtkBmOP8RQ7wNrZ7aQ22xVLt3Me4CDsYaQb2izXWbRR7fhN7\n",
       "430qdm2xO1wBCOdzJ4jIQSIyHdubcmqiAhljNgYmishuzvH7Av8EfgG8DuzmHPcDY8xtTjl7xZ3m\n",
       "dWxXHk7d9gTecvYlarHEPAuMNcbs6ny2CrgQ2023tr4i0gmcDPzUGBNrvb4EHO4613TWn/KyKfA3\n",
       "Y8yGzvuPsQE+FriK0h1XVkGoKRjdsKOq18ihyz9/IsVhU4FHWgLhTuyNtDuKUzqlVCGJyFxs19kL\n",
       "zl/j84AzRWQxdlTYqcBO2BFhz2JbF8vo6u573RhzK7Y7aRtjzL+wvSQfxq5hjBmODRyx7nxE5Gmg\n",
       "rzFmd2PMVcaYHVzFOoauBMkxNwANwHXAD5zr3AxcAXwF1Bhj1t4iEJH7gPeNMU9jW20tzr2fVAEo\n",
       "FlyOAC5yuu9if5zHBmB0uo5dgQ2u1xhj+gPnAHXGmOeMMW3AVsDl7s+JyMvYUcVPGGOeAv4FXC8i\n",
       "bzvHnWGMedT1CKcqb66qOjtT/hwKpZMEUbYpGD1w2LJP/7rTZw8dWhtpTThRtb654VrgseXPH/gw\n",
       "8G9gXA9rCSWsu0d4te5erTf0sLobY2YC80TkvbQHp9ej6l4qZdUSAqZuvPTjPtiutvXUNzdUYecQ\n",
       "PAwcCkR6WABSSpW3SJ4CkMpQWQWhqs6OicOWfbasNtK6JMkhPwS+bQmEFwD1aFecUiqPROSTUpfB\n",
       "a7IeHecMMbwRO7a9D3ZI4OvYPtEOYL6IpJvQldBuH9/dOGD1ojNTHHIA8IAzKs6QYq0hpZRS5S+X\n",
       "ltDR2Jm6+2CXUpgDXAmcLyKTsCNY/LkUZsNV340H5qc4ZBr2hqJ2xSmlVAXIJQi1ALOd172waSR2\n",
       "duV0moe9b5OLCSQJQvXNDX2AnbGjYnRUnFJKVYCsg5CILBORpcaYgdhAcAHrjgBZjJ3Bm4vtgP8m\n",
       "2bcn8MLy5w8ciO2Ki5+gppRSqofJKWOCk/zvn8AcEfmHMeYPrt0Dge8yOM16Y8PHzWxg+JRJLyc6\n",
       "+NBtprHxBkOpGjt2wfufL+KkQ7dfk0vZy0RJxsWXCa/W3av1hizqft111/HMM8/Q3t5OdXU1Z599\n",
       "Nttttx1vvfUWixYtYtddd0362dtuu42jjjoq40KdcsopAFx77bVpjoSvvvqKAw44gMsuu4xp06Yl\n",
       "PW7VqlVEIhGOOOII5s6dy5AhQzqnTJmScZni3XXXXcydO5fOzk7a29uZOXMmtbW1HHfccaxZs4b3\n",
       "33+fYcOGMWTIEGprazn55JO57777uOCCC3jwwQfZZJNNAJgzZw6PP/44zc3NVFfbtkcgEOCqq67i\n",
       "k08+4fTTT2f8+PFrr3PssccyfXrOWZuyGpae9TwhY8wI4DFgpog85myLYFM8POFMaHpURFJ1l2U9\n",
       "fr6+ueFFoH758wfOAS6JhvxPZVXw8uHluQNerbtX6w1Z1N3Jon2DiNQ673cAbhGRnZylBb4Qkb+k\n",
       "+PznIjIyw2uNxg6m6g38QkQ+SHP8+djUN7s7mRiSHTcWm61hD7r5e3eyQ7wIbOOk+9kUeF5EtnAd\n",
       "cyPwDxF50LXtQWx2hFUicpGz7TfYCbZzRORiZ9vT2MwTWwIni8jPne0DsKsSHC8ir+Za/kzl0hI6\n",
       "DxgCzDbGNGJ/0P+Lnalbg53jc2f+igj1zQ2bAIOWP3/gQmweJu2KU6rA6psbup1Fe2i/wSxc8f3a\n",
       "LNotgbBm0c48i3a6LNcQF+ScIDgUm4j0JWPMxSIS6zX6AzDDGBMVkVfiPxvj3G75CzbtT/kFIRE5\n",
       "HftLjje526VJbn/gIcAP3K2j4pQqvDQBI1OaRTvHLNoZZLlO5ATgRhFZZIx5BvgpXYO4ljjXuNlJ\n",
       "7prKl9gUSQVXVpNVU5iKzZKgo+KUqlDuLNoiMgabt+1aY8yQuENjWbRvxCY9rYnbvz1wkJN9uxUn\n",
       "i7ZrvzuLdjNdWbSTcWfR/jlwhNNVtnauooi8KyJXk7h1sU4WbWwOuERZtPvF/TzWZrkWka2wf4yf\n",
       "ZYzZLlEhjV0E72jgcGPMPOzk/nUSs4rIU9jv0iZS36sbAxRl4m5PCUIT27/e/HXsL06XbVCqMmkW\n",
       "7XWly3Id7yfYe0b7ish0EdkdGGGM2T7uuFnAQdjuypi1wdP5GZ9Ikf7gL/sgVN/cMBAYuPr97XcH\n",
       "otoVp1Rl0iza6/08EmW5vsGV5Zq4c8wA/l+Css5k3YzbK7HLlbun0kxxMmU/jF1SfHbcdQqmrLJo\n",
       "J1Lf3DAFmLn8+QM3AC6NhvyplnnoCXSklPd4td7Qw+quWbSLr+xbQsDEzvaaV7ETWbUrTilVSJpF\n",
       "u8h6QhDarf2zLfthu+J68gRVpVSZ0yzaxZdTxoQi26X969GDgd+UuiBKKaXyq6xbQvXNDaM6O6qW\n",
       "sqZmFNoVp5RSFafcW0ITO5YOWYLtivNy7i2llKpIZd0S6uxktzXfbjqK9YcdKqWUqgDl3RJa03v/\n",
       "jiWDP46G/B+UuihKqcIzxpyDXY+sBjtJ9SwReckYMwEY6lq3LNFnZ4rInzK8zirsfKNqYADwfyJy\n",
       "W5rP/Bk7cXWXNMftDSwUEYwxd4rI4ZmUKcX5TsRmQujAfmfPEpHHnaSkPwc+xQ4FH4ZNZvp7Y8wv\n",
       "gK1F5DzXeW4Hwth5U/8QkT2cybjXYjNIDMROrD3VSRkU+xnFhpl3AkeJyOfdqU+8sg1C9c0NvaC3\n",
       "6Vw2MKelwpVSPYuTRfuQ+Cza2AmqdcAXOOlvkpgFZBSEsKtDT3WuMwibwSBpEDLG9AdqgdeMMZMS\n",
       "JER1Ox74B0AeAlAAG5SniEiHk6D0cWNMLK9bSESuc47tg52we72zL9UtjNi+s4AHXee4EpsT74+4\n",
       "fkaFVLZBqGNlv506V/XrRWevvGbkVkplps1f1+0s2jVDh7J64cK1WbRrI63lkkXbPYl0MPAtqdVj\n",
       "c67Nw2ZueBzAGHMw0Ogc8xI2i8KBwE6ff/45kydP/lxERjpB42rsStQrsGlxegG3Ax85ZX1eRP6H\n",
       "dZ0MnCEiHQAi8oEx5kcistAYE1+PjZ2fyfI0dXH7Eptr7l3s4K+zsC2u+HMXTPkGoSVDTqSz6u1o\n",
       "yL+k1GVRyovSBIxMlV0WbccwJ8FpL2ff1WmKF8tyLdikqiOxKXquAXZ1Mmyf6WybB9w+cuTIB+lq\n",
       "cVyHXZ/nNaeOVwFnYpOM7ocNTO8ZY4aLyFeu624GrDN5VkQWut7+2hhzJLAFtlvuBGcphmT1iG8d\n",
       "XYUNwGdhc8U9ic3k/anrZxQLRp+IyDGpfki5KNsgVFXVMb2TXteVuhxKqeJwZ9F23u8CzHO+CN1i\n",
       "WbSXAluz/vpi2wN7OcsVVOFk0Y5LYrrA1R23IfCMMeYhJ49cfLm2xgaqkHO+DmzL68/AtyKyAEBE\n",
       "rnCOr2L9VsRmIvKa8/oJIJZb7h0RWeZ87jPiMmkDHwCjsfdqYuU5gK51fkLOekU7Y1tVsXxvy4G+\n",
       "cefakPVbSVOBW0XkZie56jnA/2FXLFhQjO64shwd5wtGNqvqv3REr8Ff31TqsiiliqZYWbTdxwIs\n",
       "Bb4D+iQp1wzgfFfW7X2x932+BYbElpowxvzRGPPjWFnjrvOpK5v1ZLqyaCcrU8xN2AVEeznX2Aq4\n",
       "Htutt5aIvIRda6jZ2fQfYH9jV0nFaRFuhyuYOX4FHOWcYzXwX+xiesnKk3fl2RKqWfnLqpqVy+84\n",
       "6ppPS10UpVRxiMhcp9XxgjFmMfaL/EwRWezcC/oDduXmWBbtdmwgiM+ifQJwg5PdeiC2xRJvqKuF\n",
       "1Rd7P+ZfxpgdsSucngFrl144EhsgY+X82BjzCnawxP8A9xlj2oGXReQF5/7Ppe+++y50dX+dhA2w\n",
       "VcBqp4zu/fGvY9dqdrr+nnJGq1VjR6h9E9/lJiI3GmPqjTENIhJ2RvM9ZYxZhLPyq4gsi/vcKcCf\n",
       "jTGnYwP619gM4fE/oyqnfOeJyHMJfp45K7ss2r5gpKp68Nfv9hn3ylt3HHXNgUUuVzF4ObOuV+vu\n",
       "1XpDD6u7MWYD7Bft7DycrkfVvVTKsTtul+qB31LVuz2+H1gppQqtN7ZbSxVJOXbHHddr6FcLsUvg\n",
       "KqVU0YjIolKXwWvKKgj5gpG+gL+q39JO7EqKSimlKli5dccdXNVvyfNVVXzXEgjr/CCllKpwZdUS\n",
       "Ao7uvdl7/yH97GWllFIVoNxaQpf22uiz/uj9IKWU8oSyaglFQ/7n6pvvvxT4e6nLopQqPs2ivd65\n",
       "4rNc/xc7wfRw7FyjfsC2dN1DP0pEPjfGvAw8JSKnuc7VAfhFJOq8nwYcKSK/dOZU9QOWYSftvgec\n",
       "nmCSb96VVUvIZs5ma+wPWinlIa4s2vuLyGTgDOCvzu467JdtKrOyuNw3IjLVuc6+2JQ8qcoWy6L9\n",
       "hjFmUppzHw9sDt3Pok1XlusDneziS4CTReRvIjIFO5H2v05dpjoBaE/gNWBqLGOCYxlwpZM9IabT\n",
       "9XyMc469gPux+e4KrqxaQsA2gLQEwmtKXRClvK4pGO12Fu0NB/VlyaKVa7NoN4Z8mkU7uyzaqbJc\n",
       "J3MiNhnpR9ifW6x1uBgbbK916hNv7c9ERP5ujLnYGNNHRFaluV63lFsQmojeD1KqLKQJGJnSLNpW\n",
       "rlm0E2W5ngl8kqiQxpiBwF7Yrro3gbl0BaFOEbnWGHOoMeZnpA+83wFDnDoVTFl1x6FBSCnPcmfR\n",
       "FpExwDHYL/whcYfGsmjfiM3pVhO3f3vgICfItOJk0Y47ZoHT9TQJ27I63OnGSlQudxbte+nKor0x\n",
       "cVm0ReQTbIsiXRbtWNfiOyKyzFkvKFEW7ViW6wOBEcAL2CzXyRztXPsebGDd1BgzJe6YE4CLSf/H\n",
       "wYi4gFgQ5RaExqFBSCmv0iza60uU5XpFis+dABzsKuuvsN2Ha48TkU+B3wCXJqkvxpgZwCPJ9udT\n",
       "uXXHTWsJhNvTH6aUqjSaRTvhctwnA+EkWa7X+ZxzXUTkTde+VuxghFHu84vI34wxh8Vd81anC7QK\n",
       "2903M0F58q7ssmh7gNbde7xab+hhddcs2sVXbt1xSilVSppFu8i0JVR8Wnfv8Wq9Qevu1bpnTFtC\n",
       "SimlSkaDkFJKqZLJ2+g4Z9THn7EzrFcAM0TkvXydXymlVOXJZ0voUKCviOwJnAdcmcdzK6WUqkD5\n",
       "DEKxpHeIyHPArnk8t1JKqQqUzyA0CJuAMKbdGKP3nJRSSiWVzyCxCDs7ee25nXxISimlVEL5DEJt\n",
       "wEEAxpjdsetZJOPlsfNad+/xar1B667SyGfuuLnA/saYNuf9L/N4bqWUUhWoVBkTlFJKKZ2sqpRS\n",
       "qnQ0CCmllCoZDUJKKaVKRoOQUkqpkinqyqpezC9njJkIXCoiU4wx44Cbscv/zheRoqxcWGzGmN7A\n",
       "jcBY7JLJlwCv4426VwPXAwZb11OAlXig7jHGmOHAv4H9sEtz30yF191Z+TU2Wf994Hd4oN4Axphz\n",
       "gUOAGuz3+xNkUfdit4Q8lV/OGHMW9gupr7PpSuxa9ZOAamOMv2SFK6yjgW9EZB/gQGAO3qm7D+gU\n",
       "kb2A2dgvI6/UPfYHyLXAMmdTxdfdGNMXQESmOo8T8EC9AYwxk4A9nO/0ycAWZFn3Ygchr+WXewc4\n",
       "zPV+FxF50nk9D/uXYiVqwX4BA/QC2oGdvVB3EYkAJzlvxwAL8UjdHVcAYeAz7GRNL9R9R2CAMeYB\n",
       "Y8zDTu+HF+oNMA2Yb4y5C7gbuIcs617sIOSp/HIiMhf7BRzjnkG9GBhc3BIVh4gsE5GlxpiBwB3A\n",
       "BXik7gAi0mGMuRm4Gvg7Hqm7MeY44CsReYiuOrv/f1dq3ZcBl4vINKABuA2P/M6BjYFdgMPpqntW\n",
       "v/NiBwCv55dz13Ug8F2pClJoxpjRwKPALSLyDzxUdwAROQ7YCrgB6O/aVcl1/yU2a8pj2NbBrcAm\n",
       "rv2VWve3sF++iMjbwAJghGt/pdYbbF0fEJF2EXkLe6/fHXTS1r3YQSib/HKV6CVjzD7O6+nAk6kO\n",
       "7qmMMSOAB4CzReQWZ/PLHqn70c6NWrD/IdcA/3b6zqGC6y4ik0RkiohMAf4DHAPM88Dv/XggBGCM\n",
       "2Qzb4/OgF37nwFPY+76xug8AHsmm7kUdHYfmlzsTuN4YUwO8AdxZ4vIUynnAEGC2MaYR6AT+F7jG\n",
       "A3X/J3CTMeZx7P+vXwFvAjd4oO6JeOHf/F+xv/MnsS3+47AthIr/nYvIvcaYvY0xz2O7IBuAD8ii\n",
       "7po7TimlVMlU7KAApZRS5U+DkFJKqZLRIKSUUqpkNAgppZQqGQ1CSimlSkaDkFJKqZLRIKSUUqpk\n",
       "NAgppZQqmf8P4eg1A/69knEAAAAASUVORK5CYII=\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118a7bfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pylab as pl\n",
    "\n",
    "x_axis = range(1, 1 + len(logs[A][STAND]))\n",
    "for s in states:\n",
    "    for a in actions:\n",
    "        pl.plot(x_axis, logs[s][a], label=\"State %s, Action %s\" % (['A', 'B'][s], ['CRUISE', 'STAND'][a]), \n",
    "                linewidth=0.9)\n",
    "pl.legend(loc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Programming: Backward Induction\n",
    "\n",
    "\n",
    "Initialize the optimal value fuction (lookup table) $v^*_{t+1}(x\\_{t+1}) = v_T(x_T)$\n",
    "\n",
    "For each value of $x_t$, $a_t$, $z_t$ compute the next state:\n",
    "\n",
    "$$x_{t+1} = f_t(x_t, a_t, z_t)$$\n",
    "\n",
    "along with the associated probability \n",
    "\n",
    "$$Pr[x_{t+1} = f_t(x_t a_t, z_t)] = p(z_t | x_t, a_t)$$\n",
    "\n",
    "Compute the optimal value function for the current time step\n",
    "\n",
    "$$V_t^*(x_t) = \\max_{a_t \\in A_t} \\left[ \\sum_{z_t \\in Z_t} p(z_t|a_t,z_t)[v^*_{t+1}(x_{t+1}) + r_t(x_t, x_{t+1},a_t,z_t)]\\right] $$ \n",
    "\n",
    "However, we cannot evaluate $v^*_{t+1}(x\\_{t+1})$ directly, since it is a function of discrete values of $x_t$. Thus, an interpolation must be performed:\n",
    "\n",
    "$$v^*_{t+1}(x\\_{t+1}) = L(v^*_{t+1}(X\\_{t+1}), x_{t+1})$$\n",
    "\n",
    "where $L$ is the linear interpolation function.\n",
    "\n",
    "We then substitute the state dynamics function into the value function, so that it is expressed in terms of values at time $t$:\n",
    "\n",
    "$$V_t^*(x_t) = \\max_{a_t \\in A_t} \\left[ \\sum_{z_t \\in Z_t} p(z_t|a_t,z_t)[L(v^*_{t+1}(X\\_{t+1}), \\color{red}{f_t(x_t, a_t, z_t)}) + r_t(x_t, x_{t+1},a_t,z_t)]\\right] $$ \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mangel and Clark example\n",
    "\n",
    "Marc Mangel and Colin Clark applied stochastic dynamic programming to address behavioral ecology problems. In this case, the \"decision-maker\" is an individual organism that presumably is optimizing some measure of biological fitness in the face of various constraints and tradeoffs.\n",
    "\n",
    "Consider a simple patch dynamics model: an organism has three patches available to it. Two patches are feeding patches, and a third is a reproductive patch, where it can lay eggs. In the feeding patches, the food resources are used to enhance both survival and reproduction. At the end of the season, the organism may reproduce prior to dying. Each of the three patches has different costs and risks. There is an energetic cost $a_i$, a mortality risk $m_i$, a feeding probability $p_i$, and an energetic value of food $y_i$ for each patch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m</th>\n",
       "      <th>p</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 0.01</td>\n",
       "      <td> 0.2</td>\n",
       "      <td> 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 0.05</td>\n",
       "      <td> 0.5</td>\n",
       "      <td> 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 0.02</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      m    p  y\n",
       "1  0.01  0.2  2\n",
       "2  0.05  0.5  4\n",
       "3  0.02  0.0  0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = [.01, .05, .02]\n",
    "p = [.2, .5, 0]\n",
    "y = [2, 4, 0]\n",
    "\n",
    "pd.DataFrame({'m': m, 'p': p, 'y':y}, index=(1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def V(n,x,t,f):\n",
    "    \"\"\"\n",
    "    Calculate the reproductive success for behaviour n at energy x, time t\n",
    "    in the fitness array f.\n",
    "    \"\"\"\n",
    "    if n<2:\n",
    "        # forages\n",
    "        x1 = chop( x+y[n]-cost, 0, xmax ) \n",
    "        x2 = chop( x-cost, 0, xmax )\n",
    "        return (1.0 - m[n]) * (p[n] * f[x1,t+1] + (1.0 - p[n]) * f[x2,t+1])\n",
    "    else:\n",
    "        # tries to reproduce\n",
    "        if x < xrep: # can't reproduce\n",
    "            reproduction = 0\n",
    "            x1 = chop(x-cost,0,xmax)\n",
    "        elif x < xrep+c3: # limited reproduction\n",
    "            reproduction = x - xrep\n",
    "            x1 = chop(xrep-cost,0,xmax)\n",
    "        else: # full reproduction\n",
    "            reproduction = c3;\n",
    "            x1 = chop(x-cost-c3, 0, xmax)\n",
    "        return reproduction + (1.0 - m[n]) * f[x1,t+1]\n",
    "    \n",
    "def chop(x, min, max):\n",
    "    \"\"\"\n",
    "    Return x, pushed into the range [min...max]\n",
    "    \"\"\"\n",
    "    if min<=x and x<=max:\n",
    "        return x\n",
    "    elif x<min:\n",
    "        return min\n",
    "    else:\n",
    "        return max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "listmax = lambda x: (np.max(x), np.argmax(x))\n",
    "\n",
    "def update(f, dec, t):\n",
    "    \"\"\"\n",
    "    Calculate the values for time t in the arrays f and dec.\n",
    "    \"\"\"\n",
    "    f[0,t] = 0.0\n",
    "    for x in range(1,xmax+1):\n",
    "        choices = [];\n",
    "        for n in range(3):\n",
    "            choices.append( V(n,x,t,f) )\n",
    "            \n",
    "        (f[x,t], dec[x,t]) = listmax(choices)\n",
    "        \n",
    "    return f, dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize(f):\n",
    "    \"\"\"\n",
    "    Initialize the last column (t=tmax) of f.\n",
    "    \"\"\"\n",
    "    for x in range(xmax+1):\n",
    "        f[x,tmax] = acap*x/(x + x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xmax = 30\n",
    "xrep = 4\n",
    "tmax = 20\n",
    "\n",
    "cost = 1\n",
    "c3 = 4\n",
    "acap = 60.0\n",
    "x0 = 0.25*xmax\n",
    "xint = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = np.zeros((xmax+1,tmax+1), float)\n",
    "dec = np.zeros((xmax+1,tmax+1), int)\n",
    "initialize(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "output = []\n",
    "for t in range(tmax-1,0,-1):\n",
    "    f, dec = update(f, dec, t)\n",
    "    for x in range(1,xmax+1):\n",
    "        output.append(( x, dec[x,t]+1, f[x,t], t ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = pd.DataFrame(output, columns=['x', 'dec', 'f', 't'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sb.heatmap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x118bf39b0>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAaYAAAENCAYAAABEqsEuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAHCJJREFUeJzt3X2wXXV97/F3SMAiTYkFhTKo0XLzBVqnEexYeUgQoQop\n",
       "Uiwz3KYUaQSuECuK4AQoFKo4jhUEUSKXZ+WhPNyGGBnIUIM0oMWBBq/48EkULniHFiRKGomExKR/\n",
       "rLUPh8PZJ+ecvdda37335zXDzN5nn/P5fcl5+O211ve3flO2bt2KmZlZFts1XYCZmdlwnpjMzCwV\n",
       "T0xmZpaKJyYzM0vFE5OZmaXiicnMzFJpdGKKiHdGxH1N1mBmZrlMa2rgiDgL+GvgV2N93ubT5nVt\n",
       "odW0K+5i82nzuhWXOi9zbdnzMtc2aHmZa8uel7m2Vh4wZbTXmjxi+glwTIPjm5lZQo1NTJKWAJub\n",
       "Gt/MzHJy84OZmaWSYWIa9RyjmZkNpgwTk+8ia2ZmQxrrygOQ9CRwQJM1mJlZLlPq3vYiIqYB1wIz\n",
       "gR2AiyQtG+NLfERlZtafRr2U08QR0/HAc5JOiIjXAY8CbSem7H34WfMy15Y9L3Ntg5aXubbseZlr\n",
       "a+W1fa1ro4zfbcDt5ePtgE0N1GBmZknVPjFJ2gAQEdMpJqhz667BzMzyaqQrLyLeCKwAbpB0axM1\n",
       "mJlZTrUfMUXEbsByYKEk38DVzMxeoYlrTGcDM4DzIuJ8iq67IyRtbKAWMzNLpol28e2Aq4AAtgAf\n",
       "lvTDMb7E7eJmZv0pTbv4UcBWSQdFxFzgM8Cft/vk7O2OWfMy15Y9L3Ntg5aXubbseZlra+W1U3vz\n",
       "g6SlwCnl05nAL+uuwczM8mrklkSStkTE9RRHSsc2UYOZmeXU5H5MJwKzgKsjYsem6jAzs1xqn5gi\n",
       "4viIWFQ+fRH4DUUThJmZWSOn8v4ZuC4i7i/HP92t4mZm1lJ7u/gkpC/QzMwmJU27OAAR8QbgYeAw\n",
       "SavbfV72dseseZlry56XubZBy8tcW/a8zLW18tpp6l5504CvABuaGN/MzPJqqivv88Bi4OmGxjcz\n",
       "s6Sa6Mo7EXhW0r20Ob9oZmaDq4kjpr8BDo+I+4DZwFfL601mZmaNbBQ4t/W4nJz+l6Rn667DzMxy\n",
       "auzODyW3gpuZ2Ss0so4pIh4B1pVPn5D0oTE+3ZOXmVl/yrGOKSJeAyDp0PF8fvY+/Kx5mWvLnpe5\n",
       "tkHLy1xb9rzMtbXy2r7WtVHG74+AnSJiOTAVOFfSQw3UYWZmCTVxjWkD8I+S3gucCtxU7mprZmbW\n",
       "yMS0GrgJQNIaYC3wew3UYWZmCTUxMS0ALgaIiD2A6cB/NFCHmZkl1MQ1pmsotr1YSbEP0wJJ3o/J\n",
       "zMyA5trFFwHvB7YHrpB03Rif7nZxM7P+lKZdfC7wLkkHRMROwCfG+vzs7Y5Z8zLXlj0vc22Dlpe5\n",
       "tux5mWtr5bV9rWujjN97gcci4k6K60tnNVCDmZkl1cTEtCvwJuDPgLcCXwf2bqAOMzNLqImuvLXA\n",
       "ckmby51rX4yIXRuow8zMEmpiYnoAeB8MtYu/lmKyMjMzq39iknQXsCoivgssBU6T5M47MzMDmrnG\n",
       "hKRFTYxrZmb51b6OKSI+CJxIsT5pR4qbuu4u6b/afImPpszM+tOo65gaWWDbEhFfAlZJuqbd52w+\n",
       "bV7XCuyFvv5BWsOQNS9zbYOWl7m27HmZa2vl0WZiauyu3hHxDmDfsSYlMzMbPE1uN3E2cGGD45uZ\n",
       "WUKNTEwRsTMwS9L9TYxvZmZ5NXXENAf4ZkNjm5lZYk1NTAE83tDYZmaWWBPt4tOAG4CZwGbg5PLW\n",
       "RO24XdzMrD/l2PYCOBKYKunAiDgM+AxwbLtPzt7umDUvc23Z8zLXNmh5mWvLnpe5tlZeO02cylsN\n",
       "TIuIKcDOwEsN1GBmZkk1ccT0K+AtwI+BXSi2vzAzMwOaOWL6OHCPpKC4HdFXI2KHBuowM7OEmjhi\n",
       "+gWwqXz8fFnD1AbqMDOzhJqYmC4Fro2IfwW2B86W9OsG6jAzs4Rqn5gkvQAcV/e4ZmbWG5pYx7QD\n",
       "cB3wVmAdsFDST8f4Eq9jMjPrT2nWMZ0MrJf0roiYBXyZcqv10WTvw8+al7m27HmZaxu0vMy1Zc/L\n",
       "XFsrr50muvL2Be4GKO/4sE8DNZiZWVJNTEyPUq5diog/AfYoF9uamZk1MjFdC6wvu/KOBh6R5OtI\n",
       "ZmYGNDMx/THwTUlzgDvwXcbNzGyYJpof1gCfiohzgV8CH2qgBjMzS6rydvGIeCfwWUnvjojfB64H\n",
       "tgCPSVo4jgif5jMz60/1t4tHxFnAX1PcuBXgEuAcSSsjYnFEHC1p6VgZ2dsds+Zlri17XubaBi0v\n",
       "c23Z8zLX1sprp+prTD8Bjhn2fH9JK8vHdwOHVTy+mZn1mEonJklLKHapbRl+2LaeYj8mMzOzIXV3\n",
       "5W0Z9ng6xd3FzczMhtQ9Mf17RMwpHx8BrBzrk83MbPDU3S5+JnBVRGwP/IhiHZOZmdmQ2u8uPgnp\n",
       "CzQzs0kZtV28tlN5EfHOiLhv2PNjIuKmusY3M7PeUMupvJHrmSLiUuBPKW7oOqYPT/mdrtXxla3/\n",
       "NTB5mWvLnldFbdnXk2TNy1xb9rzMtbXy2qnriGnkeqYHgVNrGtvMzHpILRPTyPVMkm6vY1wzM+s9\n",
       "Tdxd3MzMrK26JyZvCGhmZmOqe2Jy67eZmY2p7m0vZgNfpLjetBE4QdLPtxHhyczMrD+l2PbiUmCh\n",
       "pO9HxCnAIuATY2VkbSnOnpe5tux5mWurKi9rW3EvtDxnzctcWyuvnbq3vThO0vfLx9OAX1c8vpmZ\n",
       "9Zhat72Q9AxARBwALAS+UOX4ZmbWe2pvF4+I44ArgCMlra17fDMzy63Wu4tHxPHAKcAhkrwXk5mZ\n",
       "vUqdN3HdDrgM+G1gSUSsiIi/r2t8MzPrDXW3i+8LXFm+tAY4SdKW9l8NuF3czKxfpWgXvwhYJOnB\n",
       "iLgOOApYOlZG9jbbrHmZa8uel7m2qvKythX3Qstz1rxK2rs3rOtaHq/due1LdbeLf6CclHYAdge6\n",
       "+H9pZmb9oO528a0R8SbgMWAX4HtVjm9mZr2n9nZxSU9JmkVxrcnrmMzM7BVqnZgiYmlE7FU+XQ/8\n",
       "ps7xzcwsv1rXMQGfBa6PiI3ABuCkmsc3M7PkKp+YJD0JHFA+/g5wUNVjmplZ76p1HdOwj80HPiLp\n",
       "gHFEeB2TmVl/SrGOiYh4O7BgvBnZ139kzctcW/a8zLX1Sl7mtTjZ87q2Vui1O3d/3VE/rmOKiF2A\n",
       "TwOnVzyumZn1qNrWMZX3yrsaOAN4gTaHcGZmNtjqbBffD9gLWAzcAuwTEZfUOL6ZmfWAutrFp0h6\n",
       "GHgbQES8GbhF0hk1jW9mZj2iriMmd9aZmdm41L3txWzgG8Dq8uXFkm7fRoQnNTOz/pSiXXx/4GJJ\n",
       "475HXva22Kx5mWvLnpe5tl7JG6iW56x5mWtr5bVR97YX+wPzIuL+iLg6InaqeHwzM+sxtW57ATwE\n",
       "nCVpLvA4cEGV45uZWe+pe9uLOyWtKh8vAWbXPL6ZmSVX98S0PCLeUT5+D/BIzeObmVly25yYRrsO\n",
       "VK5DmoxTgUsjYgXFHcc/PckcMzPrU+PpylsVESdI+jeAiDgVOA/YYzwDjNj2YhXe9sLMzMawzXVM\n",
       "EXEQcBXwdYrbCm0A/lbSU+MZYMQ6pteXWTOAqcAJkp7YRoTXMZmZ9afJrWOS9EBEXA58DlgHvH8C\n",
       "k9LIdUyfA26UdEdEHALsDYw5MWVfr5E1L3Nt2fMy19YreQO1FidrXubaWnltjOca0/3AXwB/CPwV\n",
       "cEtEXDzOoUeuYzoQ2DMi7gXmA98aZ46ZmQ2I8XTl3SHpPZL+n6RvUZzO+63xhI+yjmkm8AtJhwM/\n",
       "AxZNrFwzM+t34zmVd/mI578CFk5yvLXAsvLxMtyVZ2ZmI9S9jmklcGT5eA7wg5rHNzOz5Oraj6nl\n",
       "TODqsuV8HcV1JjMzsyF1b3txC7AbRYvgTOA7krY1Obld3MysPzW/7YWkvyw/PgNYAXxsWxnZ22Kz\n",
       "5mWuLXte5tp6JW+gWp6z5mWurZXXRt3bXrRcCFwu6dmKxzczsx5T97YXlHd/OBS4vsqxzcysN9Xd\n",
       "lQdwLHCzJF87MjOzV6lrYhp+gesw4O6axjUzsx5T18Q0/OhoFsXutWZmZq9S+Tqm4dtelM/fVvWY\n",
       "ZmbWu+pexzQbWAxsAlZLOmkcEb4WZWbWn5pfxwScD1wgaXlE3BgR8yTdNVZG9vUaWfMy15Y9L3Nt\n",
       "VeWlXe/SC2txsuZlrq2V10bd65hWAbtGxBRgOsWRk5mZ2ZC61zGtAb5IcfPWN+D9mMzMbIS61zFd\n",
       "BhwoaV/ga8AlNY9vZmbJ1T0xrQXWl4+fBmbUPL6ZmSVX97YXJwO3RsQm4KXyuZmZ2ZC628X3o2gX\n",
       "fxF4VNLp44hwu7iZWX9K0S5+JfARSQ9FxD9ExHxJN4+Vkb3NNmte5tqy52Wuraq8tG3FvdDynDWv\n",
       "gtq6/nPXRt3t4ntKeqh8/G3goIrHNzOzHlN3u/hPI+Lg8vFRwE5Vjm9mZr2n7uaHBcBlETENWElx\n",
       "rcnMzGxI3e3i84D5kg4HdgXurXl8MzNLru6JaQ2wIiIeANZJuqfm8c3MLLnK28W7IH2BZmY2KfW2\n",
       "i5fXka4FZgI7ABcBPwSuB7YAj0lauK2c7G22WfMy15Y9L3NtVeUNUsvzwORV0N7dD+3ixwPPSZoD\n",
       "vA/4EsW98c6RNBfYLiKOrnB8MzPrQVVOTLcB55WPp1K0je8naWX5sbuBwyoc38zMelBlp/IkbQCI\n",
       "iOnA7cC5wOeHfcp6oP1OUWZmNpAq7cqLiDcCK4AbJP0TxbWllunA81WOb2ZmvaeyiSkidgOWA5+U\n",
       "dEP54VURMad8fATFIlszM7MhVd754WyK/ZbOi4jzKdq+Twcuj4jtgR8Bd1Q4vpmZ9aA6tr14Vdu4\n",
       "pGXla5cAP5b0v8eI8DomM7P+VP+2F6VW2/gJEfE64NGI+DbF1ur/A/jxWF+cvQ8/a17m2rLnZa6t\n",
       "lZd27Uy38zLXVlHeQP0ct1HHxHQbRVceFNe0NgG/Dfw9xXUmMzOzIZVPTKO1jUt6EngyIo6senwz\n",
       "M+sttdzEdUTb+K11jGlmZr2p8iOmYW3jCyXdV/V4ZmbW2+q4xjRa2/gRkjbijjszMxuhsnbxNncX\n",
       "fwq4nOK+eRuBEyT9fBtRnrzMzPpT7e3iw9vEZwDfAx6nOKX3/Yg4BVgEfGKskOztjlnzMteWPS9z\n",
       "ba287C3PmdvFs39vB+rnuI0qJ6bhbeJTKdrEj5P07LCxf13h+GZm1oNqvbt4a1KKiAOAhcCc9glm\n",
       "ZjaI6ry7+K3lx44DrgCOlLS2yvHNzKz3VLm1+qvaxCPieOAU4BBJ3vLCzMxepc67i08F/gB4ElgS\n",
       "EVuB+yVdWGENZmbWY6q8xvQx4GNV5ZuZWX+qex3TT4DWFhdrgJMkbRk14GVex2Rm1p9SrGN6BFgk\n",
       "6cGIuA44Clg6Vkj2PvyseZlry56XubZWXtp1R2XeIH0vsuZlrq2V106t65gkfQAgInYAdge6+Ntg\n",
       "Zmb9oNZ1TOXzNwH/AjxPcRRlZmY2pPZ1TJKekjQLuBL4QpXjm5lZ76lsYhq2jumTkm4oP7Y0IvYq\n",
       "P2U98Juqxjczs95U5zqmrRSn866PiI3ABuCkCsc3M7MeVGu7uKRl5WvzgY9IOmAcUW4XNzPrT422\n",
       "i78OeBRYFhFvBxaMNyR7u2PWvMy1Zc/LXNug5WWuLXte5tpaee1U2fxwG3DesHE2RcTvAp8GTq9w\n",
       "XDMz62F1toufB1wDnEGxe+2oh3BmZjbYamsXp7gd0V7AYuAWYJ+IuKTK8c3MrPfUuu0F8LbytTcD\n",
       "t0g6o6rxzcysN9XdLn6EpI0VjmlmZj2ukW0vJD0JjKdV3MzMBkzd2178DPgGsLr8tMWSbh814GVe\n",
       "x2Rm1p9SrGO6ELhY0rjvkZe9Dz9rXubasudlrm3Q8jLXlj0vc22tvHbq2vZiO2ATsD+wd0T8OcVG\n",
       "gadLeqHCGszMrMdU1i4uaYOkF4atY/o74LvAmZLmAo8DF1Q1vpmZ9aY6t734J+BOSavKl5cAs6sc\n",
       "38zMek+t214AyyPiHeXj91BstW5mZjak7nVMHwcujYiXgP8ETqlwfDMz60F1t4v/G3AVxYQ1FThB\n",
       "0hPbiHK7uJlZf0rRLr4CuFHSHRFxCLA3MObElL3dMWte5tqy52WubdDyMteWPS9zba28dupsF99M\n",
       "cbeH/xsR91JMSN7+wszMXqHOdvFzgbcAayUdTnEXiEVVjW9mZr2p7nbx54Bl5cvLKBbcmpmZDam7\n",
       "XfwB4Mjy8RzgB1WNb2ZmvanudvEPAtdExKnAOmB+heObmVkPamLbiz+takwzM+t9da9jmg/sRtG7\n",
       "PhP4jqRtHTV5HZOZWX9qfh2TpDcDRMQMiqaIUTcSHC57H37WvMy1Zc/LXNug5WWuLXte5tpaee3U\n",
       "ve1Fy4XA5ZKerXB8MzPrQVVeY9oAMGIdExHxeuBQxnG0ZGZmg6fOdUy3lh8+FrhZkq8dmZnZq9S9\n",
       "jgngMODuqsY1M7PeVvc6piOBWRS715qZmb1K3e3iTwFfoWiEWC3ppHFE+ZSfmVl/arRdfAbwPeBh\n",
       "4EJJ90TEjRExT9JdY4Vkb3fMmpe5tux5mWsbtLzMtWXPy1xbK6+dutrFp1IcJa0CdomIKcB0XtlC\n",
       "bmZmVmu7+N+VL32ZonV8HfCtqsY3M7PeVPe2F5cBB0raF/gacEmV45uZWe+pu118LbC+fPw0Rdee\n",
       "mZnZkLrbxU8Gbo2ITcBL5XMzM7MhlbWLd1H6As3MbFLqbRdvs47p/1OsY3qR4m7jp28rJ3u7Y9a8\n",
       "zLVlz8tc26DlZa4te17m2lp57VTZ/NBaxzQHeB/wJeBK4KOS5gLrIsI72JqZ2StUOTHdBpxXPp4K\n",
       "bAb2lPRQ+bFvAwdVOL6ZmfWgyiYmSRskvTBi24vHI+Lg8lOOAnaqanwzM+tNda9jWgCcExH3As8A\n",
       "z1U5vpmZ9Z661zHNA+ZLOhzYFbi3qvHNzKw31b2O6WJgRUS8ANwn6Z4Kxzczsx5U5bYX2wFXAQFs\n",
       "AT4MbASuL58/JmnhOKK8jsnMrD/Vvu3FUcBWSQdFxFzgM2UR50haGRGLI+JoSUvHCsneh581L3Nt\n",
       "2fMy1zZoeZlry56XubZWXjtVduUtBU4pn74Z+CWwn6SV5cfupthm3czMbEilXXmStkTE9cAXgZt5\n",
       "5WHbemDnKsc3M7PeU+nEBCDpRGAWcDWw47CXpgPPVz2+mZn1lirbxY+PiEXl0xeB3wAPl9ebAI4A\n",
       "Vo76xWZmNrCqbH74Z+C6iLi/HOejwI+BqyNie+BHwB0Vjm9mZj3I216YmVlTam8X75ZRCzczs/5U\n",
       "efODmZnZRHhiMjOzVDwxmZlZKp6YzMwsFU9MZmaWiicmMzNLpRfaxbcpIt4JfFbSuzvMmQZcC8wE\n",
       "dgAukrSsg7xXbf0h6Ycd1vgG4GHgMEmrO8x6BFhXPn1C0oc6zFsEvB/YHrhC0nUdZH0QOJFiHduO\n",
       "wB8Bu0tqf0visfOmATdQfG83AydP9t8vInYArgPeSvHvt1DSTyeZNfSzGxG/z8S3hRkzs3x+DHCs\n",
       "pL/qoLbZFPe83Eyxfc0Jkn7eQd6+wJXlS2uAkyRtmWzesI/NBz4i6YCJZI1S32zgG0DrZ2SxpNsn\n",
       "mfV6ir8DM4CpFP92T3RQ2y3AbhRLaWYC35E0v4O82cBiYBOwWtJJE8kaJW+/Mu9F4FFJp080r+eP\n",
       "mCLiLIpv+mu6EHc88JykORS3TPpSh3lDW38A51Fs/TFp5R/XrwAbOqyLiHgNgKRDy/86nZTmAu8q\n",
       "/yAcAryxkzxJN0h6t6RDgUeAv53spFQ6Epgq6UDgU3T2vTgZWC/pXRR3NPnyZEJG+dm9hGJbmLnA\n",
       "dhFxdKeZEXEpcBETXA84Sm2XUkzAhwJLgEXtvnaceRcBiyQdXNZ2VId5RMTbgQUTyRkjb3/g4mG/\n",
       "HxOZlEZmfQ64UdIhFH8H9u6kNkl/WX4fjqHYteFjneQB5wMXlH/3fisi5nWYdyXw0fLneF35ZmFC\n",
       "en5iAn5C8Q3qhtsofnCg+LfZ1EnYiK0/ZlL8EHXi8xTvRJ7uMAeKI5CdImJ5RPxL+Y6nE+8FHouI\n",
       "O4GvU7zb7FhEvAPYV9I1HUatBqZFxBSKu9q/1EHWvhTbtlAede0zyZyRP7v7d2FbmJGZDwKndiHn\n",
       "OEnfLx9PA37dYd4HJD1YHn3uzstH7pPKi4hdgE8DE3533qa+/YF5EXF/RFwdETt1kHUgsGdE3AvM\n",
       "B77VYW0tFwKXS3q2w7xVwK7l78Z0Jv53b2TenpIeKh9/Gzhognm9PzFJWkJxeqEbWRskvRAR04Hb\n",
       "gXO7kNna+uMy4KbJ5kTEicCzku6lO3fD2AD8o6T3Uvzhuqk89ThZu1L8Mh9b5t3ceYkAnE3xC9ip\n",
       "XwFvobhf45UUp6Um61HgzwAi4k+APcpf6gkZ5We3421hRmZO5J3+NnKeAYiIA4CFwBc6zNsaEW8C\n",
       "HgN2Ab432bzy5/Zq4AzgBSbx+zHK9+Ih4KzyXf/jwAUdZM0EfiHpcOBnTPBoc7S/ceXpwUMpTv1O\n",
       "yCh5ayh+H34AvIEJTpyj5P00Ig4uHx8FTGRSB/pgYuq2iHgjsAK4QdKt3cgcvvVHROy4jU9v52+A\n",
       "wyPiPmA28NXyetNkraacKCWtAdYCv9dB3lpguaTN5VHEixGxawd5RMTOwCxJ93eSU/o4cI+koDha\n",
       "/Gr5bn0yrgXWR8S/AkcDj0jqxj0dh19jSbctTEQcB1wBHClpbad5kp6SNIvijcKEJroR9gP2ojib\n",
       "cAuwT0Rc0mF5d0paVT5eQvE7N1lrgda16mUUb+A6dSxwc5d+7i4DDpS0L/A1ilPKnVgAnFMeIT4D\n",
       "PDfRgH6amDo+ioiI3YDlwCcl3dCFvNG2/pjQBd4WSXPLay7vpnjHfsIkDuGHWwBcXNa5B8Ufwv/o\n",
       "IO8B4H3D8l5L8QvZiTnANzvMaPkFL58uep7idNTUSWb9MfDN8pz8HRTvqLvh3yNiTvm4021hunqP\n",
       "yYg4nuJI6RBJT3Yhb2lE7FU+XU/xuzEZUyQ9LOlt5XWX/wn8UNIZHZa4vDyNDPAeiuuck7WS4hon\n",
       "FD/TP5hkzvDv6WGUp5O7YC3F9wCKywQzOsybB8wvjxB3Be6daEBfdOWVuvHO4WyKb8p5EXF+mXmE\n",
       "pI2TzBu59cfpHWQN143/12soaltJMVkumGhX1HCS7oqIgyPiuxS/QKd14d1c0L0/+pcC15ZHOdsD\n",
       "Z0ua6HWSljXApyLiXIrrhh01jgxzJnBVl7aF6dpd+ctTZZcBTwJLImIrcL+kTk6xfha4PiI2UpxW\n",
       "nnAnWKmq3QdOBS6PiJeA/+Tla8WTcSbF2ZJTKd4cTbgZoDT8/3UW3fvdOBm4NSI2UVx7PbnDvDXA\n",
       "ioh4AbhP0j0TDeiFbS/MzGyA9NOpPDMz6wOemMzMLBVPTGZmloonJjMzS8UTk5mZpeKJyczMUvHE\n",
       "ZJZARPxORCxpug6zDDwxmeXwuxS3SjIbeJ6YzHK4jOJmsP+n6ULMmuaJySyHjwJPS/qLpgsxa5on\n",
       "JjMzS8UTk5mZpeKJySyHzfTX3f7NJs0Tk1kOzwBPRUS39p8y61ne9sLMzFLxEZOZmaXiicnMzFLx\n",
       "xGRmZql4YjIzs1Q8MZmZWSqemMzMLBVPTGZmloonJjMzS+W/AeBTG7Xe1AiBAAAAAElFTkSuQmCC\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118bfd240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sb\n",
    "\n",
    "sb.heatmap(output.pivot(index='x', columns='t', values='dec'), linewidths=0.01, cmap='Reds', cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mdptoolbox.example\n",
    "P, R = mdptoolbox.example.forest()\n",
    "vi = mdptoolbox.mdp.ValueIteration(P, R, 0.9)\n",
    "vi.run()\n",
    "vi.policy # result is (0, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study: Optimal fire management of a threatened species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will apply dynamic optimization methods implemented in **PyMDPtoolbox**, a Markov decison process (MDP) toolbox for Python. An early application of these methods to wildlife biology was by Possingham and Tuck (1997), which examines the problem of deriving an optimal fire managment strategy for the conservation of endangered vertebrates.\n",
    "\n",
    "The Possingham and Tuck model models the spatial structure of the populations in question, but for simplicity, we will simplify the model to a single patch here.\n",
    "\n",
    "First, we need to specify the dimensions of the problem. In the Possingham and Tuck problem, there are seven population abundance classes (`pop_classes`), including exctinction (0), there are 13 fire classes (`fire_classes`), which represent the number of years since the last burn. The system state is made up of all pairwise combinations of population and fire classes. Since there is no population structure in this problem, there are only two possible actions, `burn` or `no_burn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_pop_classes = 7\n",
    "n_fire_classes = 13\n",
    "\n",
    "states = [(p, f) for p in range(n_pop_classes) for f in range(n_fire_classes)]\n",
    "n_states = len(states)\n",
    "\n",
    "no_burn, burn = 0, 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input validation\n",
    "\n",
    "The key to reliable scientific computing is to write tests for all the important steps in your program. To facilitate this, we need test functions to validate the inputs to various functions that we will define. We’re going to want to send the action, population class, fire class, and a probability as input to multiple functions. Each of these functions will raise an exception for invalid entries, and let us know what was passed to the function, versus what was expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_action(x):\n",
    "    \"\"\"Check that the action is in the valid range.\"\"\"\n",
    "    if not x in [0,1]:\n",
    "        msg = \"Invalid action '%i', it should be in {0, 1}.\" % x\n",
    "        raise ValueError(msg)\n",
    "\n",
    "def check_population_class(x):\n",
    "    \"\"\"Check that the population abundance class is in the valid range.\"\"\"\n",
    "    if not (0 <= x < n_pop_classes):\n",
    "        msg = \"Invalid population class '%i', it should be in {0, 1, …, %d}.\" \\\n",
    "              % (x, n_pop_classes - 1)\n",
    "        raise ValueError(msg)\n",
    "\n",
    "def check_fire_class(x):\n",
    "    \"\"\"Check that the time in years since last fire is in the valid range.\"\"\"\n",
    "    if not (0 <= x < n_fire_classes):\n",
    "        msg = \"Invalid fire class '%i', it should be in {0, 1, …, %d}.\" % \\\n",
    "              (x, n_fire_classes - 1)\n",
    "        raise ValueError(msg)\n",
    "\n",
    "def check_probability(x, name=\"probability\"):\n",
    "    \"\"\"Check that a probability is between 0 and 1.\"\"\"\n",
    "    if not (0 <= x <= 1):\n",
    "        msg = \"Invalid %s '%i', it must be in [0, 1].\" % (name, x)\n",
    "        raise ValueError(msg)\n",
    "        \n",
    "def check_states(x):\n",
    "    if not (0 <= x < n_states):\n",
    "        msg = \"Invalid index '%i', it should be in {0, 1, …, %d}.\" % (x, STATES - 1)\n",
    "        raise ValueError(msg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Habitat suitability\n",
    "\n",
    "The core of our habitat model is a simple relationship between habitat suitability and the number of years since the last fire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_habitat_suitability(years):\n",
    "    \"\"\"The habitat suitability of a patch relatve to the time since last fire.\n",
    "\n",
    "    The habitat quality is low immediately after a fire, rises rapidly until\n",
    "    five years after a fire, and declines once the habitat is mature. See\n",
    "    Figure 2 in Possingham and Tuck (1997) for more details.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    years : int\n",
    "        The time in years since last fire.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    r : float\n",
    "        The habitat suitability.\n",
    "\n",
    "    \"\"\"\n",
    "    if years < 0:\n",
    "        msg = \"Invalid years '%s', it should be positive.\" % str(years)\n",
    "        raise ValueError(msg)\n",
    "    if years <= 5:\n",
    "        return 0.2*years\n",
    "    elif years <= 10:\n",
    "        return -0.1*years + 1.5\n",
    "    else:\n",
    "        return 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the form of this relationship by passing a range of values to `get_habitat_suitability`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAisAAAFkCAYAAADhSHsMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmcFPWd//HXXByD3AyHB4KAH1FAFA/kEBTM4W3UKJqY\n",
       "NTHGHLvZnL81uskmUbNroknWJJvDRCUJHqh4i4lyeiLgLXwAuQQUBgSGa2CG6d8f1Q3NONPTwNRU\n",
       "dff7+XjwYLpruubDF2b6Q1V96l2USCQQERERiaviqAsQERERyUTNioiIiMSamhURERGJNTUrIiIi\n",
       "EmtqVkRERCTW1KyIiIhIrIXerJjZqWY2vYHnzzOzOWb2gpldE3YdIiIikptCbVbM7HvAn4DW9Z4v\n",
       "BW4HxgNjgWvNrCLMWkRERCQ3hX1kZQlwUQPPDwQWu3uVu9cAzwOnh1yLiIiI5KBQmxV3nwLUNrCp\n",
       "A7A57fEWoGOYtYiIiEhuKo3o61YRNCwp7YFNmV6QSCQSRUVFoRYlEqZNW3Zy3X8/y7bqWoqLi7ju\n",
       "osF8ekTfqMsSEYnCfr2ht1SzUr+oBUB/M+sEbCc4BfTzjDsoKqKycktI5eW+ior2Wp8M4rA+dz+9\n",
       "gG3VtYw94TDm+Tp+99CbvPf+Ri4d25/i4uga8TisTZxpfRqntclM69O4ior2+/X5LTW6nAAwswlm\n",
       "do271wLfBv4BvADc6e4ftFAtIi1u+YdVzH7jAw6raMeVZw3ghqtOolfXcp6Z8z6/nfIWO3ftjrpE\n",
       "EZHYKsqh1OWEOtTGqYPPLMr1SSQS/Oxv81myejPfu3woA/t0AWBbdQ2/m/I2C1ZspE/P9vzbJUPo\n",
       "dEjrJvbW/PRvJzOtT+O0NplpfRpXUdF+vw4n66ZwIiF7+d21LFm9mWFWsadRAWjXpoxvffZ4Rg3u\n",
       "xfIPt3DTxLmsWrc1wkpFROJJzYpIiKp31TJ5+hLKSou57Iz+H9teWlLM1Wcfw8VjjuKjqp3c8rd5\n",
       "vL10QwSViojEl5oVkRA9+dIKNm3dxadO6U23Tm0b/JyioiLOOa0P111wHLW7E/xq8ptMf211C1cq\n",
       "IhJfalZEQrJu43aembOSLh1ac/ZpRzb5+acM7MH3J5xAeZtS/vqMc/+0xdTlzjVlIiKhUbMiEpL7\n",
       "py2hdneCz57Rn9ZlJVm9pv/hHbnxC3snhX435W121mhSSEQKm5oVkRC8s+wjXlu8nqOP6MTJx3Tf\n",
       "r9d279SWH3x+GMf07sT8RZX8z9/ns3nrzpAqFRGJPzUrIs2sdncdk55dRFERXDF+AAdy5+V2bcr4\n",
       "9mVD950UqtSkkIgUJjUrIs1s2vzVfLBhO2OGHkbvHvt3l8Z0qUmhz5x+FBuqdnLLXzUpJCKFSc2K\n",
       "SDOq2r6LR59fRnnrUi4affC5P0VFRZw7Yt9JoRmaFBKRAqNmRaQZPTxzKTt21nLh6L60L2/VbPtN\n",
       "nxSaqEkhESkwalZEmkmQ/7OGw7q144wTD2v2/fc/vCM3XjWMnl00KSQihUXNikgzSCQSTHp2MQmC\n",
       "i2pLisP51ureuZwbrto7KXTrJE0KiUj+U7Mi0gxeeXctS1ZtZtjR++b/hCE1KTRycE+WfaBJIRHJ\n",
       "f2pWRA5S9a5aJs94L8j/OfPj+T9hKC0p5otnD9wzKfSzv83j7WWaFBKR/KRmReQgPfnSCjZu2Zkx\n",
       "/ycMqUmhr5x/HDW1CX71wJvMeF2TQiKSf9SsiByEdZt28Myc9+ncvjVnD286/ycMpx6bNik01Xlg\n",
       "2hJNColIXlGzInIQ7n9uMbW764L8n1bZ5f+EIX1SaOqclZoUEpG8omZF5ADtyf85vCOnDNy//J8w\n",
       "aFJIRPKVmhWRA7BP/s9ZRx9Q/k8YNCkkIvlIzYrIAZieyv85/tCDyv8JQ2pS6CJNColInlCzIrKf\n",
       "qrbv4pFU/s/pR0VdToOKioo4T5NCIpIn1KyI7Kew8n/CcOqxPfjehKF7J4Wma1JIRHKPmhWR/bDi\n",
       "wy2h5v+EYcDhnfZOCr2ykv/TpJCI5Bg1KyJZSiQS/P3ZRSSACSHm/4She+dyfvD5YFJoniaFRCTH\n",
       "5M5PW5GIpef/HBty/k8YDmmbnBQapEkhEcktalZEsrBz124mz3iP0pJiPttC+T9hKC0p5ovn7Dsp\n",
       "NN/XRV2WiEhGalZEsvDky8uD/J9Te1PRgvk/YUhNCl17/rHU1Cb48Z0vM1OTQiISY2pWRJqwbtMO\n",
       "pr4S5P+cE1H+TxiGH9uT700YSrs2ZdyjSSERiTE1KyJNiEv+TxgGHN6JX3xzND1Sk0KPaFJIROJH\n",
       "zYpIBu8sj1f+TxgO7XYIN3x+GHZEJ+Z5JbdOek2TQiISK2pWRBpRu7uOe59dTBEwYXx88n/CcEjb\n",
       "Mr5z+VBGDOrJsg+quGniPFZrUkhEYkLNikgjps9fzZr12xgz9FCO7Bmv/J8wlJYU86VzBnLR6L5s\n",
       "qKrmlr/N451lH0VdloiImhWRhuRC/k8YioqKOG9k3+SkUB2/fOANTQqJSOTUrIg0YMqsIP/nghzI\n",
       "/wlDMCl0AuVtSrlnqjNZk0IiEiE1KyL1rPhwC7NeX8Oh3dpxxgm5kf8ThgGHd+KGq4bRo0s5T2tS\n",
       "SEQipGZFJE39/J/SksL+FunRufzjk0LbdkVdlogUmML+SSxSzysLgvyfE4+u4LgczP8Jw8cmhe6Z\n",
       "q0khEWlRalZEknbu2s3k6UH+z2U5nP8ThgYnhZZrUkhEWoaaFZGkfMr/CUP9SaFfPfAGs95YE3VZ\n",
       "IlIA1KyIkL/5P2EYfmxPvnv5CbRtXcrdTy9k8gxNColIuNSsiAAPTFtC7e46Lj2jX97l/4Th6CPS\n",
       "JoVeXsnvH3mbXZoUEpGQqFmRgvfO8o+Yv6iSAYd35NSBPaIuJ2ekJoWOPqITc72S/9GkkIiERM2K\n",
       "FLT0/J8r8jz/JwyHtC3jO5cN5bTj0iaF1m+LuiwRyTNqVqSgTX8tyP85vUDyf8JQVlrMNecO5MLU\n",
       "pNBf52pSSESalZoVKVhV23fxyOxltC2w/J8wFBUVcf7Ivlx7niaFRKT5qVmRgpXK/7lwdF86FGD+\n",
       "TxiGH6dJIRFpfmpWpCAp/yc8eyaFOrfVpJCINAs1K1JwEokEk5T/E6oencu54aqT9kwK3XqvJoVE\n",
       "5MDpp7QUnFcWrGXxqs2cMKCb8n9ClD4ptHRNFTdP1KSQiBwYNStSUPbJ/xk3IOpy8l76pND6zdXc\n",
       "8ldlConI/lOzIgXlyZdXJPN/jqC78n9axL6TQrs1KSQi+03NihSMIP9nZTL/p0/U5RSc+pNCD854\n",
       "T5NCIpIVNStSMPbk/4xV/k9U0ieFnnp5Bb9/9B1NColIk9SsSEF4fdE65i+qpP/hHTn1WOX/RGmf\n",
       "SaGF67j13teo0qSQiGRQGtaOzawI+B1wPFANXOPuS9O2Xwl8G6gF7nL334dVixS22t11/PGRtykC\n",
       "rlT+TyykJoXufnoBL72zlpsmzuWblx7PYd3aRV2aiMRQmEdWLgRau/sI4Hrg9nrbfw6cCYwCvmNm\n",
       "HUOsRQrY9NdW8/7aLYw+Xvk/cRJMCh3LhaP2Tgq9q0khEWlAmM3KKGAqgLu/ApxUb/sbQGcgNZKh\n",
       "K+2k2W3ZvotHZy+jXZtSPjNG+T9xU1RUxPmj+vLl5KTQLzUpJCINCO00ENAB2Jz2uNbMit29Lvn4\n",
       "HWAesBV42N2rmtphRYX+V5yJ1ufjHnjwDbbvrOXLFwyi35Fdoy4ntqL+t3P+2Pb0692Fm++aw91P\n",
       "L2Trzt18/tMDKS6Oxym7qNcnzrQ2mWl9mkeYzUoVkP63tKdRMbPBwDnAkcA24O9mdrG7P5Rph5WV\n",
       "W8KqNedVVLTX+tSz4sMtPPPScg7t1o6zR/bV+jQiLv92urdvxQ8+dyK/mvwGD05bzPI1m7nmnIG0\n",
       "Kot2cisu6xNHWpvMtD6N298mLszTQC8AZwOY2XDgrbRtm4HtwE53TwDrCE4JiTSLffJ/xin/J1f0\n",
       "6LLvpNDPNSkkIoTbrEwBdprZC8BtwLfMbIKZXePuK4E/As+b2SygI3B3iLVIgZmzYN3e/J++yv/J\n",
       "JXszhXrw3poqblKmkEjBC+00UPKIyVfrPb0obfsfgD+E9fWlcO3ctZsHpi9R/k8OS00K9ehcziPP\n",
       "L+OWv87j6xcN4lgFT4oUJB0bl7yTyv/55CnK/8llmhQSkRQ1K5JXKtPzf047MupypBmclswUatOq\n",
       "RJlCIgVKzYrklfT8nzatwhx2k5Z09BGduPGqk5QpJFKg1KxI3nh3+UfMU/5P3tKkkEjhUrMieWF3\n",
       "XR33PrtY+T95rqFJoTWaFBLJe2pWJC9Mn7+a1eu3Kf+nAKQmhS5IZgrdrEwhkbynZkVyXtX2XTwy\n",
       "exltWyv/p1AUFRVxwai+fPncvZNCszUpJJK31KxIzntk1lK276zlglF96VDeKupypAWdNmjvpNBd\n",
       "Ty/koZmaFBLJR2pWJKetXLuFma+voVfXcs488bCoy5EIpE8KPfmSJoVE8pGaFclZiUSCSf8M8n+u\n",
       "GH+08n8K2J5JocM7alJIJA/pp7vkrDkL1rFI+T+SdEjbMr5z+QmaFBLJQ2pWJCftzf8p4rIz+0dd\n",
       "jsSEJoVE8pOaFclJT+3J/+lN987lUZcjMaJJIZH8o2ZFck7lph08/cpKOh3SSvk/0qjTBvXkO5cN\n",
       "1aSQSB5QsyI5Z0/+zxn9lf8jGVnvztx41Ul016SQSE5TsyI5ZUEq/+ewjgxX/o9koUeXcm7UpJBI\n",
       "TlOzIjljd10dk1L5P2cp/0eyl5oUGq5JIZGcpGZFcsbe/J9eyv+R/VZWWsyXNSkkkpPUrEhO2JKe\n",
       "/3N6v6jLkRyVPim0q0aTQiK5Qs2K5IQps5ftzf9pp/wfOThBppAmhURyhZoVib2Va7cw87XVyv+R\n",
       "ZlV/UugPmhQSiS01KxJr6fk/E8YPUP6PNKvUpNCAwzvyqiaFRGJLP/kl1l5duDf/Z1DfrlGXI3no\n",
       "kLZlfFeTQiKxpmZFYkv5P9JSUpNC54/ss2dSaIEmhURiQ82KxNZTL6/goyrl/0jLKCoq4sLRR3HN\n",
       "uQPZVbOb2zUpJBIbule5xNL6TTuYOkf5P9LyRgzqRdcObfjNw29x19ML2bprN5886XCKdRNCkcjo\n",
       "yIrE0v3Tl1BTq/wfiUb6pNDk5xZrUkgkYmpWJHYWLP+Iea78H4lWjy7l3PD5YRzbt4smhUQipmZF\n",
       "YmV3XR2Tngvyf644a4DyfyRS7ctbcdN1IzQpJBIxNSsSKzNeW8PqyiD/p0/PDlGXI0JZaYkmhUQi\n",
       "pmZFYiPI/1mq/B+JnQYnhd7UpJBIS1GzIrExZfYytlXXcsHIPsr/kVgaMajX3kyhp5QpJNJS1KxI\n",
       "LKxcu4WZryfzf4YdHnU5Io2y3p25IS1T6I+PaVJIJGxNNitm9t9mVpr2uKeZPR5uWVJIEokEk55d\n",
       "TCKh/B/JDT2Tk0IDDu/InAXr+Pl9r1G1XZNCImHJ5l2hCzDHzI41s88Bc4Dp4ZYlheTVhetY9P4m\n",
       "hvZX/o/kjvblrYJMoWN78N7qKm66R5NCImFpsllx92uBW4E3gJ8DY9z99rALk8Kws2Zv/s/l45T/\n",
       "I7mlrLSYL5+3d1LoFk0KiYQim9NAVxM0KTcAU4HJZjY07MKkMDyt/B/JcalJoS+dM5CdmhQSCUU2\n",
       "9zG/DjjL3RcCmNk5wCNAnxDrkgKwftMOnn5F+T+SH0YO7kW3jslMoacWsm7jDi46/ShlCok0g2yu\n",
       "WTnN3ReaWWcAd38SOD7csqQQ7Mn/Gav8H8kP1rszP/j8MLp32jspVFOrSSGRg5VNszLYzBYCb5jZ\n",
       "YWa2BNAdu+SgLFixkXleSb/DOjD8OOX/SP7o1bUdN1w1jP7JSaFb79WkkMjByqZZuQO4CNjg7quB\n",
       "rwK/D7UqyWu76+qY9OyiIP9n/NHK/5G80768Fd+7fOieSaGbJ87lgw2aFBI5UNk0K+XuviD1wN3/\n",
       "CbQOryTJd6n8n1FDetG3l/J/JD+VlZbsmRSq3FTNzRPnsWDFxqjLEslJ2TQrH5nZ8UACwMyuBDSb\n",
       "Jwdk646aZP5PCReP0dlEyW8fmxS6/3Wef/ODqMsSyTnZXNX4VeAe4Dgz2wQsBj4XalWSt6bMWsq2\n",
       "6louP7O/8n+kYKRPCv3lqQWs27SdC0drUkgkW9ncFO49dx9FcCfb3u5+srt7+KVJvlm5dgszlP8j\n",
       "BSp9UuiJFzUpJLI/Gj2yYmbTSZ76qfc8AO5+ZnhlSb7ZJ/9nnPJ/pDClJoXuePgt5ixYx0dVO/nG\n",
       "xYPpUK6jjCKZZHrH+C/gx8Aa4D3gh8APgLeAJaFXJnlln/yfo5T/I4UrNSl06rE9WLJ6syaFRLLQ\n",
       "6JEVd58JYGa/cPeT0za9bGZzQ69M8kZ6/s9lyv8Roay0hGvPO5bundry+IvLuXniPL7xmcEcc2Tn\n",
       "qEsTiaVsjsW3NbOjUw/MbDBQFl5Jkm9S+T+fOLk3PZT/IwIEk0IXnb53Uui2+1/nhbc0KSTSkGym\n",
       "gb4NzDCz1UAJUAFcEWpVkjfWbw7yfzoq/0ekQSMH96Jrhzb8dspb/PnJBazduIOLRvfVzRJF0mQz\n",
       "DfQPgtDC64BrgL7uPjvkuiRPPDAtyP/57Nj+tG2t/B+RhhxzZDApVNGpDU+8uJw/aFJIZB9NvnuY\n",
       "2ZHANwhGl4uSz+HuXwy5NslxC1ZsZK7yf0SyEkwKncRvHtKkkEh92Vyz8gBBkzIbmJn2S6RRyv8R\n",
       "2X8dylvxvQlDOWVgd00KiaTJ5rh8mbt/d393bGZFwO+A44Fq4Bp3X5q2/WTgtuTDD4HPubuiSfOE\n",
       "8n9EDkxZaQnXnn8c3TuX88SLy7nlr/P4+kWaFJLCls2RlefN7Dwz299jkRcCrd19BHA9cHu97X8E\n",
       "/sXdTwemArr6Mk8o/0fk4BQXFfGZ5KRQ9S5NColk06xcAjwKVJtZXfJXNld+jSJoQnD3V4CTUhuS\n",
       "o9AbgG+b2Qygi7sv3t/iJZ5S+T/nj+xLR+X/iBywkYN78Z3LhtK6rIQ/P7mAh2ctJZH42I3FRfJe\n",
       "k6eB3P3QA9x3B2Bz2uNaMyt29zqgG3Aa8DVgKfCEmc119xkH+LUkJt5ft5UZr6+mZ5dyxin/R+Sg\n",
       "HXNkZ264ahi/mvwGT7y4nMpNO/ji2cdQVloSdWkiLSZTNtC17v5HM/thQ9vd/SdN7LsKaJ/2ONWo\n",
       "QHBUZYm7L0p+rakER15mZNphRUX7TJsLXtTrk0gkuH3yGyQScN3FQ+jVs2Ok9dQX9frEmdYms6jX\n",
       "p6KiPb/8VmduvmsOr7y7lqrtNdxw9Sl0PKR1pHWlapPGaX2aR6YjK0X1ft9fLwDnAg+a2XCCTKGU\n",
       "pcAhZnZU8qLb0cCdTe2wsnLLAZaS/yoq2ke+Pq8uXMfb721gaP9u9O5aHnk96eKwPnGltcksTuvz\n",
       "75cM5s9PLmDOgnV8+5cz+ealQ+jVtV1k9cRpbeJI69O4/W3iisI6/5k2DTQk+dTVwDCgnbvfaWZj\n",
       "gf9JbnvR3b/VxC4T+ktvXNTfFDtrdnPDn16matsufnrNqbG7rX7U6xNnWpvM4rY+dYkEj8xexhMv\n",
       "Lqddm9JIJ4XitjZxo/VpXEVF+/06EBLaLUXdPQF8td7Ti9K2zwBODevrS8tK5f+cPfzI2DUqIvkk\n",
       "NSnUvVNb7pm6kNvuf51/+fQxjBzcK+rSREKTzTSQSEbK/xFpeaOG7DspNEWTQpLHmmxWzOx7Ztaz\n",
       "JYqR3JTK/7l0bD/l/4i0oNSkUEWnNjz+4nL++Pi7yhSSvJTNkZW2wEwze9LMLjWzsrCLktyxJ//n\n",
       "0A4MP049rUhLS2UK9T+sI6+8u5af3/c6W7brZuCSX7JJXf6JuxvwM+AM4A0z+42ZDQ29Oom13XV1\n",
       "3JvK/znraIqV/yMSiX0yhVZt5uaJ85QpJHklq2tWzKwc6AscBdQBG4H/NbOfhVibxNyM19awqnIb\n",
       "I5X/IxK5VKbQuSOOZN2mHdzy13n4yo1RlyXSLLK5ZuXvwHvAWOAmdx/k7v8JnAV8JdzyJK6U/yMS\n",
       "P8GkUD++eHaQKfSL+5QpJPkhm6shnwOudfc9xxTNrJW77zSzY8MrTeJsyuwg/+eyM/sr/0ckZkYN\n",
       "6UXXjm347cNv8ecnF1C5aQcXjOpLkU7VSo7K5jTQl+s1KsXAPAB3/zCswiS+3l+3lRmvKf9HJM4G\n",
       "pk0KPfbCcv6kSSHJYZmygaYRnPrBzOrSNtUCj4VblsRVIpFg0j8XkUjAhPEDKC3RrXpE4io1KXTH\n",
       "Q2/y8rtr2VBVzTc+M5j25ToaKrml0WbF3c8EMLNfu/s3W64kibO5Xom/v4mh/bsx+KiuUZcjIk3o\n",
       "UN6K7084YU+m0M0T5/Hvnz2enl10p2nJHZmOrJzr7k8A883sqvrb3X1iqJVJ7Oys2c0D0xZTWlLE\n",
       "ZeP6R12OiGQpNSnUvXNbnnhxBTdPnMs3PjMY6x1NppDI/sp0DP/k5O9jCe6vUv+XFJinX17Bhqqd\n",
       "nHXyEcr/EckxqUmhq88+Zs+k0Itva1JIckOm00A/Sv5+dcuVI3GVnv9z7ml9oi5HRA7Q6CGH0q1j\n",
       "W3778Fvc+cQC1m3UpJDEX6bTQMuARlOx3P2oUCqSWHpg+nvK/xHJE6lJoV8+8AaPvbCcdRt3cPXZ\n",
       "Aykr1QXzEk+Z3nXGtlQREm8LVmxk7sJ1yv8RySO9urbjxi9oUkhyQ6Y2erC7rwDGNPJLCkAq/weU\n",
       "/yOSb1KTQqcM7M7iVZu5+a/z+PCj7VGXJfIx2Vxg29DFtWPDLUviYubrQf7PKOX/iOSl1KTQOacd\n",
       "ybqNO7h54lxlCknsZH2BrZl1AHa5e3UL1SYR27qjhimzlP8jku+Ki4q4eEw/unduy8Spzi/ue52r\n",
       "zz6GEYN6RV2aCJBdkOEgM5sPLAVWmdnzZqaLawtAKv/nvBF9lf8jUgBGDzmUb3/2eFqXlXDnEwt4\n",
       "ZPZSEolG5yxEWkw2l37/AbjB3bu5ezfgNuCucMuSqKXn/4w/Sfk/IoViYJ8u3HDVMLp1TGYKPfEu\n",
       "NbV1Tb9QJETZNCtt3f3p1AN3nwLo4oU8lkgkuPdZ5f+IFKrUpFC/wzrw8jtrue2+19i6oybqsqSA\n",
       "ZbrPSu/kh2+Y2X8AfyYIMbwSmN0CtUlE5nolC1du4vh+XZX/I1KgOpS34nuXn8BfngoyhW6aOJd/\n",
       "v1SZQhKNTPdZmUlwU7gigumfr6RtSwD/Fl5ZEpVU/k9JcRGXjxsQdTkiEqFWZcGkUEWntjz5kjKF\n",
       "JDqZpoH6tmQhEg9TX1nJhqqdfHp4b3rof1AiBa+hSaEvnj2Q0wbpBpHScpq8b7qZGfA14BCCoywl\n",
       "QF93Pz3k2qSFrd+8g6deXqH8HxH5mNFDDqVbhzb8dsrb/OmJd1m7cTvXXDQk6rKkQGQT8nI/8Cgw\n",
       "Grgb+DTwdog1SURS+T+XjFH+j4h83MA+XfjB54fxq8lBptCHG6up6Ng66rJiq7y8Fdu374q6jFi6\n",
       "7pKh+/X52bwjFbv7j8ysDJhPMMr84gHUJjG2MC3/R4d3RaQxh3Zrx41XncQdD7/JnHc/jLocyVFh\n",
       "NCvbzaw1sAgY5u7Pm1mbAylO4ml3XR2TlP8jIlnq0K4V/++KE9myq44NG7ZFXU5sdepUzqZNylpq\n",
       "Dtk0K38DHicYWX7JzD4FrA61KmlRe/J/Biv/R0SyU1pSzNG9O1LZVqeMG1NR0Z7KyrKoy8gLTd7t\n",
       "y91/A1zs7pUEI8x/BC4MuS5pIfvk/4xV/o+IiMRPNtlAL7n7FgB3XwU8BrwSdmHSMh5R/o+IiMRc\n",
       "pjvYTiM4koKZpQdD1BI0LJLj3l+3lenK/xERkZjLdFO4MwHM7Nfu/s2WK0lagvJ/REQkV2Q6snKu\n",
       "uz8BzDezq+pvd/eJoVYmoZqn/B8REckRmS7jPhl4guSpoAaoWclRO2t2c7/yf0REJEdkOg30o+Tv\n",
       "V7dcOdIS9uT/nKr8HxERib9ssoGWEaQs78PdjwqlIgnVnvyfdq04d0SfqMsRERFpUjZ38xmb9nEZ\n",
       "cBGgMIgctSf/55PK/xERkdzQ5LuVu6+o99TPzWwucFM4JUlYUvk/Ryn/R0REckg2p4FOT3tYBBwH\n",
       "tA2tIglFkP+zGIArlf8jIiI5JJvzAD9O+zgBrAe+EE45EpZZr69hVeVW5f+IiEjOyeY00Bnpj82s\n",
       "g7tXhVeSNLetO2p4eNZS2rQq4eIxui5aRERySzangc4FRgM/BV4FKszsR+7+27CLk+aRyv/57Bn9\n",
       "6XiIro0WEZHcks091n8E3AVcDswB+gC690qOWKX8HxERyXFZBcK4+0LgHOAxd98KKJ43ByQSCSYl\n",
       "838uH6f8HxERyU3ZvHutNbM7gJOAqWZ2G7Ay3LKkOaTyf4b068qQfsr/ERGR3JRNszKB4FqVM9x9\n",
       "G7A0+ZzEWHr+zwTl/4iISA7LZhpoC2mhhbqwNjco/0dERPKFLmLIQxs2V/O08n9ERCRPqFnJQw9M\n",
       "X8Ku2jouGav8HxERyX1NNitm9lADzz0XTjlysHzlRl5V/o+IiOSRRv/bbWZTgOOBQ81sab3XvB92\n",
       "YbL/dtfV8fd/Bvk/V4xX/o+IiOSHTOcIvgB0AX4N/Fva87XA2jCLkgOTnv9z1KHK/xERkfzQaLOS\n",
       "zP+pAi4wsxOAQwhSl0uATwJ/ybRjMysCfkdwdKYauMbdlzbweX8ANrj7Dw70DyGwZfsu5f+IiEhe\n",
       "yuaalXuAB4BHgFuAx4HLstj3hUBrdx8BXA/c3sC+vwIM2p+CpWF/n7qQbdW1nD+yr/J/REQkr2Qz\n",
       "DXQ6cCwwGbgWOJXsbrc/CpgK4O6vENwBdw8zOw04GfjDftQrDVi1bitPv7iMHsr/ERGRPJRNs7LG\n",
       "3WuABcAQd38HaJ/F6zoAm9Me15pZMYCZ9SQISPwGwaklOUCp/J+6BExQ/o+IiOShbG7CsdrMrgee\n",
       "BW41MwiuX2lKFfs2NcXuXpf8+FKgK/AU0Atoa2YL3X0iGVRUZNMjFZYX3ljDwpWbOGlgD8YN7xN1\n",
       "ObGmfz+N09pkpvVpnNYmM61P88imWfkScI67v2pmDxPkAl2XxeteAM4FHjSz4cBbqQ3ufgdwB4CZ\n",
       "fQGwphoHdFIEAAATc0lEQVQVgMrKLVl82cKxq2Y3f3rkLUqKi/jyBYO0PhlUVLTX+jRCa5OZ1qdx\n",
       "WpvMtD6N298mLptzBt9w9/sgaDLc/QLgE1m8bgqw08xeAG4DvmVmE8zsmv2qUBoV5P9U84mTj+DQ\n",
       "imwOdomIiOSeTDeF+2+gO3C+maXH9pYCw4GMo8bungC+Wu/pRQ183j1ZVyt7bNhczVPK/xERkQKQ\n",
       "6TTQQwRTQOOAmWnP1wI/DbMoaVoq/+fzn1T+j4iI5LdMN4V7FXjVzKYkbxAnMZHK/+nbS/k/IiKS\n",
       "/zKdBprv7icCm8wskbapCEi4e0no1cnH1NUlmPRskP9z5VnK/xERkfyX6cjKicnfdeOOGJn5xhre\n",
       "X7eVkYN7Kv9HREQKQpMXO5hZGcGo8ligBvgn8JfkBbTSgrbuqOHhme/RplUJl4zpF3U5IiIiLSKb\n",
       "KzN/S3A32rsJTgF9ARgCfDO8sqQhj85exrbqWj57Rn/l/4iISMHIplkZ7u5DUg/M7AngjfBKkoas\n",
       "WreV6a+tVv6PiIgUnGyuR1ltZkelPT4U+CCkeqQBe/N/EkwY11/5PyIiUlAyTQNNBxJABfCGmc0C\n",
       "dhOkKb/dMuUJwDyvZOHKTQzp15Uh/bpFXY6IiEiLynQa6L8aef62EOqQRuyq2c3905ZQUlzE5eMG\n",
       "NP0CERGRPJNpdHnPXWvN7ASCpOUioAToy753tZWQTJ0T5P986tTe9OxSHnU5IiIiLS6b0eV7gBFA\n",
       "F2ABMJQgUfkv4ZYmGzZX89RLK+jQrhXnKf9HREQKVDZXap5OkBE0GbgWOBVoFWZREpg8I8j/uXSs\n",
       "8n9ERKRwZdOsrHH3GoKjKkPc/R2gfbhlia/cyJwFyv8RERHJ5r/rq83seuBZ4FYzg+D6FQlJev7P\n",
       "FWcNUP6PiIgUtGyOrHwJWJZMYX4YmAB8NdSqCtye/J9BPel3aMeoyxEREYlUk0dW3H0LcF/y4zuA\n",
       "O8IuqpBtq65hyqyltGlVwsVjlf8jIiKS6aZwdQQ3hauvCEi4e0loVRWwR2YvY+uOGi49ox+dlP8j\n",
       "IiKS8T4re04Rmdlr7n5Cy5RUuFZVbmX6/NX06NyWs046IupyREREYiHbkJmGjrBIM0okEtz77OIg\n",
       "/2f8AOX/iIiIJGX7jqhxlJDNX1TJghUblf8jIiJSj46sxIDyf0RERBqX6QLbZextUg4zs6XJj1MX\n",
       "2B4VdnGFYuqclazfXM2nTlH+j4iISH2ZRpfHtlQRheyjqrT8n5F9oi5HREQkdjJNA61oyUIK1QPT\n",
       "g/yfz31C+T8iIiIN0chJhNLzf0YMVv6PiIhIQ9SsRET5PyIiItlRsxKRWcr/ERERyYqalQhsq67h\n",
       "4VlLaa38HxERkSapWYlAKv/n/BF9lP8jIiLSBDUrLSw9/2e88n9ERESapGalBaXn/1w+bgBlpVp+\n",
       "ERGRpujdsgWl8n8GH9WV4/sr/0dERCQbalZayL75P/2jLkdERCRnqFlpIc8k83/OOukIenVtF3U5\n",
       "IiIiOUPNSgv4qKqaJ19W/o+IiMiBULPSAh6YvoRdNXVcPOYo5f+IiIjsJzUrIVv0/qZk/k97Rg7u\n",
       "FXU5IiIiOUfNSojq6hJM+uciAK4462jl/4iIiBwANSshmvXmGlau28oI5f+IiIgcMDUrIdlWXcPD\n",
       "M4P8n0uU/yMiInLA1KyE5FHl/4iIiDQLNSshWF25lWnzV9Nd+T8iIiIHTc1KM0skEkxS/o+IiEiz\n",
       "0TtpM5u/aP3e/J9+XaMuR0REJOepWWlGNbW7uX/a4j35P0UaVRYRETloalaa0dQ577N+czXjTzpc\n",
       "+T8iIiLNRM1KM/moqponX1pOh3atOH9k36jLERERyRtqVprJ5BnvKf9HREQkBGpWmsGi9zfxyrtr\n",
       "lf8jIiISAjUrB6muLsGkZ5P5P+OV/yMiItLc1KwcpFlvrmHl2mT+z2HK/xEREWlualYOgvJ/RERE\n",
       "wqdm5SA8+nyQ/3Oe8n9ERERCE9rYipkVAb8DjgeqgWvcfWna9gnAN4Ea4C13/1pYtYRhdeVWps0L\n",
       "8n/OUv6PiIhIaMI8snIh0NrdRwDXA7enNphZG+AnwBh3Hw10MrNzQ6ylWSUSCe59Tvk/IiIiLSHM\n",
       "d9lRwFQAd38FOClt205ghLvvTD4uJTj6khNeW7yed5dvZNBRXZT/IyIiErIw717WAdic9rjWzIrd\n",
       "vc7dE0AlgJn9K9DO3Z9taocVFe3DqXQ/7KrZzeQZ71FSXMTXLhlK9+7R15QSh/WJM61P47Q2mWl9\n",
       "Gqe1yUzr0zzCbFaqgPS/pWJ3r0s9SF7TciswAPhMNjusrNzSrAUeiMdfXM7aj7bzyVOOoE1xPGqC\n",
       "4BsiLrXEkdancVqbzLQ+jdPaZKb1adz+NnFhNisvAOcCD5rZcOCtetv/COxw9wtDrKFZ7cn/KS/j\n",
       "vBHK/xEREWkJYTYrU4CzzOyF5OOrkxNA7YB5wNXAbDObDiSAX7v7oyHWc9AeTOb/XDn+aMrbKP9H\n",
       "RESkJYT2jpu8LuWr9Z5e1BJfOwyL3t/Ey++upU/P9owcovwfERGRlqKZ2yyk5/9ceZbyf0RERFqS\n",
       "mpUszE7m/5x2nPJ/REREWpqalSZsr67hoZlLaV2m/B8REZEoqFlpwiOp/J+RfejcXvk/IiIiLU3N\n",
       "Sgar129T/o+IiEjE1Kw0IpFIcO+zi4L8nzOV/yMiIhIVvQM3Yp/8n/7K/xEREYmKmpUG1NTu5r7n\n",
       "FlNSXMSEcQMo0qiyiIhIZNSsNOCZOe+zfnM144YdTq+u7aIuR0REpKCpWanno6pqnngpyP85f6Ty\n",
       "f0RERKKmZqWeVP7PxWP6Kf9HREQkBtSspFm8Svk/IiIicaNmJamuLsGkfy4G4Arl/4iIiMSGmpWk\n",
       "2W+uYcXaLZx2XE/6K/9HREQkNtSsoPwfERGROFOzAjz6/HK27qjh3BFHKv9HREQkZgq+WVm9fhvP\n",
       "zVtF905t+cTJvaMuR0REROop6GYlkUhwXyr/Z5zyf0REROKooN+dX1+8nneWb2RQX+X/iIiIxFXB\n",
       "Nis1tbu5b1oy/2e88n9ERETiqmCblWfmvE/lJuX/iIiIxF1BNisbt+zkyZdWKP9HREQkBxRkszJ5\n",
       "xhJ21uzmM8r/ERERib2Ca1YWr9rEy++s5cie7Rml/B8REZHYK6hmJT3/58rxyv8RERHJBQXVrDz/\n",
       "1gfJ/J8e9D9c+T8iIiK5oGCale3VNTw4471k/k//qMsRERGRLBVMs6L8HxERkdxUEM3KmvXbmDY/\n",
       "lf9zRNTliIiIyH7I+2YlkUhw73OL2V2X4LJx/SkrLYm6JBEREdkPed+svL54Pe8s+4jj+nZhaP9u\n",
       "UZcjIiIi+ymvm5V98n/GKf9HREQkF+V1s/KPV/fm/xzaTfk/IiIiuShvm5WNW3byxIsraF9exvkj\n",
       "+0RdjoiIiBygvG1WUvk/F4/pR3mbsqjLERERkQOUl83KPvk/g5X/IyIiksvyrln5WP5PsS6qFRER\n",
       "yWV516yk8n+GK/9HREQkL+RVs7K9uoaHZgb5P5cq/0dERCQv5FWz8tgLy9myXfk/IiIi+SRvmpU1\n",
       "67fx3LxVVHRqo/wfERGRPJIXzUp6/s/lZw5Q/o+IiEgeyYtm5fUlafk/A5T/IyIikk9yvlmpqd3N\n",
       "fc8p/0dERCRf5Xyzksr/OfNE5f+IiIjko5xuVtLzfy4Y1SfqckRERCQEOd2sPKj8HxERkbyXs83K\n",
       "klWbeemdtRzZQ/k/IiIi+Swnm5W6RIK/P7sIgCvOGqD8HxERkTyWk83K829+wIoPg/yfAYd3iroc\n",
       "ERERCVHONSvK/xERESksOdespPJ/zjlN+T8iIiKFIKealfT8n0+eovwfERGRQlAa1o7NrAj4HXA8\n",
       "UA1c4+5L07afB/wnUAPc5e53Ztqf8n9EREQKU5hHVi4EWrv7COB64PbUBjMrTT4eD4wFrjWzikw7\n",
       "m/POh0H+T5/Oyv8REREpIGE2K6OAqQDu/gpwUtq2gcBid69y9xrgeeD0TDv782PvUFxUxOXjj1b+\n",
       "j4iISAEJs1npAGxOe1xrZsWNbNsCdMy0sw82bOPMYYdxmPJ/RERECkpo16wAVUD7tMfF7l6Xtq1D\n",
       "2rb2wKZMO3v8tgt0OKUJFRXtm/6kAqb1aZzWJjOtT+O0NplpfZpHmEdWXgDOBjCz4cBbadsWAP3N\n",
       "rJOZtSI4BfRSiLWIiIhIjipKJBKh7DhtGmhI8qmrgWFAO3e/08zOAX4EFAF/dvffh1KIiIiI5LTQ\n",
       "mhURERGR5pBTN4UTERGRwqNmRURERGJNzYqIiIjEmpoVERERibUw77PSLJrKGCp0yeiCvwB9gFbA\n",
       "ze7+eKRFxYyZdQfmAuPdfVHU9cSJmf0HcD5QBvzO3e+KuKRYSH5f3UPwfVULfFn/dgJmdirw3+5+\n",
       "hpn1A+4G6oC33f3rkRYXsXprMxT4X4J/PzuBq9y9MtICI5a+PmnPXQF8IxnN06hcOLLSaMaQAPA5\n",
       "YL27nw58GvhNxPXESvJN5/fA9qhriRszGwOclvzeGgsoynyvs4ESdx8J/BS4JeJ6YsHMvgf8CWid\n",
       "fOp24AfuPgYoNrMLIisuYg2sza+Ar7v7mcAU4D+iqi0OGlgfzOwE4IvZvD4XmpVMGUMCDxCkV0Pw\n",
       "91kTYS1x9Avg/4A1URcSQ58E3jazR4DHgCciridOFgGlySO7HYFdEdcTF0uAi9IeD3P32cmPnyYI\n",
       "py1U9dfmMndP3Qy1FNjR8iXFyj7rY2ZdgZuAb2bz4lxoVjJlDBU8d9/u7tvMrD0wGbgh6priwsz+\n",
       "BVjn7v8kuPmg7KsbwY0aLwG+CkyKtpxY2Qr0BRYCfyA4nF/w3H0KwWmNlPTvqyYz3vJZ/bVx97UA\n",
       "ZjYC+Drwy4hKi4X09Um+h98JfBvYRhY/n3PhTT9TxpAAZnYEMA24x93vj7qeGLkaOMvMpgNDgYnJ\n",
       "61cksAF4xt1rk9djVJtZt6iLiolvAVPd3Qiul5uYjAaRfaX/LG4y463QmNllBNdcnu3uG6KuJ0ZO\n",
       "BPoTHPW+FxhoZhkv8Yj9BbYEGUPnAg82kDFU8MysB/AMwbnR6VHXEyfJ8+gAJBuWr7j7ughLipvn\n",
       "gX8DfmlmhwLlBA2MwEfsPaW6ieBnZUl05cTWfDM73d1nEVwzNy3qguLCzD4HXAuMdXc1cXsVuftc\n",
       "YDCAmR0J3Ovu3870olxoVqYQ/O/4heTjq6MsJoauBzoB/2lmPwQSwKfdfWe0ZcWOciXqcfcnzWy0\n",
       "mc0hOAz7NXfXOgV+BfzFzGYRTEpd7+6Ffs1BQ74L/MnMyggCah+MuJ5YSJ7m+DWwAphiZglgprv/\n",
       "ONrKYuGAfsYoG0hERERiLReuWREREZECpmZFREREYk3NioiIiMSamhURERGJNTUrIiIiEmtqVkRE\n",
       "RCTW1KyIFBAzu8PMJtd77hNmtsTM2kVQTy8zCy2TyMyWmVnvsPYvIi1DzYpIYfkP4EQzOwfAzMoJ\n",
       "bgd+tbtva+li3P0Ddz83xC+hG0mJ5AHdFE6kwJjZOODPwLHAT4GEu3/XzE4GbgfaAusJ4glWmNkY\n",
       "gnTUtkBn4Pvu/pCZ3QV0BfoB3wfGEqTu7gYec/efNPB1/4cgT2YjMIEgT2aGu/dN7m8zQbjiYcBP\n",
       "3P1uM+ucrPcYoBr4jrtPN7NPAT8muBP3MuDL7r6x3tdcBswgyPfZkfwzvZ38WtPdfWLy8+rcvdjM\n",
       "fgQMB44AfgNcBswBRhMEP/6ruz9zoGsvIgdGR1ZECoy7P0eQJ3UXQXNxQ/J26X8CJrj7SQRNy53J\n",
       "l3wd+FLy+WuAH6btbr27H0eQ2fVpdz8BGAn0byD47waCZuEU4HGCMDPY9+jH4e4+Gjgf+EXyuZuA\n",
       "xe5+LHAVcFMycPFnwCfcfRjwD+DWxv/IfmJyPxMb+Zz0Glq7+yB3/33ycZm7jyBIiL25kdeLSIjU\n",
       "rIgUpu8CnwC+kcyROprgCMljZvYawRGQPsnP/Tww2MxuBL4DHJK2n1eSv68GtpvZ8wSJxTe6+656\n",
       "X/NR4BEzuwNY6O7PNlDXPwDc/W2CozgApwN/TT3v7iOBU4HewPRkvV9P1t+QPydf+zTQ28w6NLoq\n",
       "+/6ZUqYmf0+vSURakJoVkQLk7lsITsWsSD5VArzn7icmj46cSHDqA4J05pOBuQRHForSdrUjub/d\n",
       "BKdPbgS6AC+bWf96X/PXwBhgMXCrmV3fQGnVDTxXk/7AzCxZ7+y0ek8GLm3kj1tb7/EugiMpRcn9\n",
       "ldXbXj+wMFXTnteISMtSsyJSuNLfeBcCXcxsVPLxNcCk5PUi/YEfuvtU4JMEjcI+zGwoMBOY5e7f\n",
       "B94FrN7nvAx0cPf/BX7J3tNAjTUAqednAZcn93EM8DTB0Y/TzGxA8nN+BPy8kf1cmXztRQRHdKoJ\n",
       "rsk5Lrn9wkZel6kmEWlBpVEXICKR2XOdhrvvMrNLgf81s9ZAFXCVu280szuBd81sM/AS0NbM2tZ7\n",
       "/etm9iLwjpltA14jaCrSXQ/cbWa1wHbgunp11L/aP/X4R8CfzOx1gqMsn3P3tWb2ReABMysGVgGf\n",
       "a+TPeHTyVFEV8IXk8/8H3J/c5zRgTVNr1MhjEWkBmgYSERGRWNNpIBEREYk1NSsiIiISa2pWRERE\n",
       "JNbUrIiIiEisqVkRERGRWFOzIiIiIrGmZkVERERi7f8DTY2cDGSkKLIAAAAASUVORK5CYII=\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117e8ae80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = range(15)\n",
    "pl.plot(list(t), [get_habitat_suitability(ti) for ti in t])\n",
    "pl.xlabel('Years since burn')\n",
    "pl.ylabel('Habitat suitability index');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System states\n",
    "\n",
    "Recall from the discussion of state transition matrices that we can project a state vector into the next state by multiplying it by a matrix of transition probabilities. Each row in the matrix represents a state that the system can start in, while the columns represent the states that the system can transition to. `PyMDPtoolbox` handles state transitions exactly in this way, by matrix multiplication. We will specify one transition probability matrix for each action, `no_burn` and `burn`. PyMDPtoolbox expects a NumPy array as the data structure, since it has fast, built-in methods for performing linear algebra operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reward function\n",
    "\n",
    "Here, the reward function returns a chosen measure of habitat quality. Depending on the implementation of the MDP, a reward function can be in terms of just the state, or as a function of state-action pairs. For this example, we only need to specify reward as a function of state. The reward is simple: where the population is still extant, the state recieves a one, otherwise it is zero.\n",
    "\n",
    "### State space representation\n",
    "\n",
    "Functionally, each state is uniquely identified by an index into the transition probability matrix, but in the real world, we think of the state as a tuple containing the population abundance class and the number of years since the last fire. Therefore we need functions to crosswalk between these two representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def state_to_index(population, fire):\n",
    "    \"\"\"Convert state parameters to transition probability matrix index.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    population : int\n",
    "        The population abundance class of the threatened species.\n",
    "    fire : int\n",
    "        The time in years since last fire.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    index : int\n",
    "        The index into the transition probability matrix that corresponds to\n",
    "        the state parameters.\n",
    "\n",
    "    \"\"\"\n",
    "    check_population_class(population)\n",
    "    check_fire_class(fire)\n",
    "    return population*n_fire_classes + fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_to_index(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def index_to_state(index):\n",
    "    \"\"\"Convert transition probability matrix index to state parameters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    index : int\n",
    "        The index into the transition probability matrix that corresponds to\n",
    "        the state parameters.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    population, fire : tuple of int\n",
    "        ``population``, the population abundance class of the threatened\n",
    "        species. ``fire``, the time in years since last fire.\n",
    "\n",
    "    \"\"\"\n",
    "    if not (0 <= index < n_states):\n",
    "        msg = \"Invalid index '%i', it should be in {0, 1, …, %d}.\" % (index, n_states - 1)\n",
    "        raise ValueError(msg)\n",
    "    population = index // n_fire_classes\n",
    "    fire = index % n_fire_classes\n",
    "    return (population, fire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_state(43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State transitions\n",
    "\n",
    "The dynamics of the transition probabilities are given in Section 2.1 and Figure 1 of Possingham and Tuck (1997):\n",
    "\n",
    "![figure 1](http://fonnesbeck-dropshare.s3.amazonaws.com/Screen-Shot-2015-03-15-16-25-39.png)\n",
    "\n",
    "Transition probabilities are calculated row-wise, since each row represents the transitions from the state corresponding to that row to all other states. Hence, it must sum to one.\n",
    "\n",
    "The first component of the state dynamics is the fire state transition, which resets the fire class to zero if burning is performed, or advances to the next fire state if no burning is performed (until the highest fire class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transition_fire_state(F, a):\n",
    "    \"\"\"Transition the years since last fire based on the action taken.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    F : int\n",
    "        The time in years since last fire.\n",
    "    a : int\n",
    "        The action undertaken.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    F : int\n",
    "        The time in years since last fire.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ## Efect of action on time in years since fire.\n",
    "    \n",
    "    if a == burn:\n",
    "        # When the patch is burned set the years since fire to 0.\n",
    "        return 0\n",
    "    \n",
    "    elif (a == no_burn) and (F < n_fire_classes - 1):\n",
    "        # Increase the time since the patch has been burned by one year.\n",
    "        # The years since fire in patch is absorbed into the last class\n",
    "        return F + 1\n",
    "    \n",
    "    else:\n",
    "        return F\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the abundance transistion dynamics depends on the current abundance: if the abundance is zero, the population is extinct, and stays that way; if the abundance is in its largest state, it can stay there with probability $1−(1−s)(1−r)$, or drop with a probability $(1−s)(1−r)$; if the abundance is at an intermediate state, it can stay in that state with probability $s$, increase with probability $(1-s)r$, or drop with a probability $(1−s)(1−r)$.\n",
    "\n",
    "The following function returns the transition probabilities, calling `transition_fire_state` to get the new fire state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_transition_probabilities(s, x, F, a):\n",
    "    \"\"\"Calculate the transition probabilities for the given state and action.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s : float\n",
    "        The class-independent probability of the population staying in its\n",
    "        current population abundance class.\n",
    "    x : int\n",
    "        The population abundance class of the threatened species.\n",
    "    F : int\n",
    "        The time in years since last fire.\n",
    "    a : int\n",
    "        The action undertaken.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    prob : array\n",
    "        The transition probabilities as a vector from state (``x``, ``F``) to\n",
    "        every other state given that action ``a`` is taken.\n",
    "\n",
    "    \"\"\"\n",
    "    # Check that input is in range\n",
    "    check_probability(s)\n",
    "    check_population_class(x)\n",
    "    check_fire_class(F)\n",
    "    check_action(a)\n",
    "\n",
    "    # a vector to store the transition probabilities\n",
    "    prob = np.zeros(n_states)\n",
    "\n",
    "    # the habitat suitability value\n",
    "    r = get_habitat_suitability(F)\n",
    "    F = transition_fire_state(F, a)\n",
    "\n",
    "    ## Population transitions\n",
    "    if x == 0:\n",
    "        # population abundance class stays at 0 (extinct)\n",
    "        new_state = state_to_index(0, F)\n",
    "        prob[new_state] = 1\n",
    "    elif x == n_pop_classes - 1:\n",
    "        # Population abundance class either stays at maximum or transitions\n",
    "        # down\n",
    "        transition_same = x\n",
    "        transition_down = x - 1\n",
    "        # If action 1 is taken, then the patch is burned so the population\n",
    "        # abundance moves down a class.\n",
    "        if a == burn:\n",
    "            transition_same -= 1\n",
    "            transition_down -= 1\n",
    "        # transition probability that abundance stays the same\n",
    "        new_state = state_to_index(transition_same, F)\n",
    "        prob[new_state] = 1 - (1 - s)*(1 - r)\n",
    "        # transition probability that abundance goes down\n",
    "        new_state = state_to_index(transition_down, F)\n",
    "        prob[new_state] = (1 - s)*(1 - r)\n",
    "    else:\n",
    "        # Population abundance class can stay the same, transition up, or\n",
    "        # transition down.\n",
    "        transition_same = x\n",
    "        transition_up = x + 1\n",
    "        transition_down = x - 1\n",
    "        # If action 1 is taken, then the patch is burned so the population\n",
    "        # abundance moves down a class.\n",
    "        if a == burn:\n",
    "            transition_same -= 1\n",
    "            transition_up -= 1\n",
    "            # Ensure that the abundance class doesn't go to -1\n",
    "            if transition_down > 0:\n",
    "                transition_down -= 1\n",
    "        # transition probability that abundance stays the same\n",
    "        new_state = state_to_index(transition_same, F)\n",
    "        prob[new_state] = s\n",
    "        # transition probability that abundance goes up\n",
    "        new_state = state_to_index(transition_up, F)\n",
    "        prob[new_state] = (1 - s)*r\n",
    "        # transition probability that abundance goes down\n",
    "        new_state = state_to_index(transition_down, F)\n",
    "        # In the case when transition_down = 0 before the effect of an action\n",
    "        # is applied, then the final state is going to be the same as that for\n",
    "        # transition_same, so we need to add the probabilities together.\n",
    "        prob[new_state] += (1 - s)*(1 - r)\n",
    "\n",
    "    # Make sure that the probabilities sum to one\n",
    "    assert (prob.sum() - 1) < np.spacing(1)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we loop over the states and actions, getting the transition probabilities and fill in the transition probability matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_transition_and_reward_arrays(s):\n",
    "    \"\"\"Generate the fire management transition and reward matrices.\n",
    "\n",
    "    The output arrays from this function are valid input to the mdptoolbox.mdp\n",
    "    classes.\n",
    "\n",
    "    Let ``S`` = number of states, and ``A`` = number of actions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s : float\n",
    "        The class-independent probability of the population staying in its\n",
    "        current population abundance class.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out : tuple\n",
    "        ``out[0]`` contains the transition probability matrices P and\n",
    "        ``out[1]`` contains the reward vector R. P is an  ``A`` × ``S`` × ``S``\n",
    "        numpy array and R is a numpy vector of length ``S``.\n",
    "\n",
    "    \"\"\"\n",
    "    check_probability(s)\n",
    "\n",
    "    # The transition probability array\n",
    "    transition = np.zeros((2, n_states, n_states))\n",
    "    # The reward vector\n",
    "    reward = np.zeros(n_states)\n",
    "    # Loop over all states\n",
    "    for idx in range(n_states):\n",
    "        # Get the state index as inputs to our functions\n",
    "        x, F = index_to_state(idx)\n",
    "        # The reward for being in this state is 1 if the population is extant\n",
    "        if x != 0:\n",
    "            reward[idx] = 1\n",
    "        # Loop over all actions\n",
    "        for a in (0,1):\n",
    "            # Assign the transition probabilities for this state, action pair\n",
    "            transition[a][idx] = get_transition_probabilities(s, x, F, a)\n",
    "\n",
    "    return (transition, reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mdptoolbox import mdp\n",
    "\n",
    "def solve_mdp():\n",
    "    \"\"\"Solve the problem as a finite horizon Markov decision process.\n",
    "\n",
    "    The optimal policy at each stage is found using backwards induction.\n",
    "    Possingham and Tuck report strategies for a 50 year time horizon, so the\n",
    "    number of stages for the finite horizon algorithm is set to 50. There is no\n",
    "    discount factor reported, so we set it to 0.96 rather arbitrarily.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sdp : mdptoolbox.mdp.FiniteHorizon\n",
    "        The PyMDPtoolbox object that represents a finite horizon MDP. The\n",
    "        optimal policy for each stage is accessed with mdp.policy, which is a\n",
    "        numpy array with 50 columns (one for each stage).\n",
    "\n",
    "    \"\"\"\n",
    "    P, R = get_transition_and_reward_arrays(0.5)\n",
    "    sdp = mdp.FiniteHorizon(P, R, 0.96, 50)\n",
    "    sdp.run()\n",
    "    return sdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_policy(policy):\n",
    "    \"\"\"Print out a policy vector as a table to console\n",
    "\n",
    "    Let ``S`` = number of states.\n",
    "\n",
    "    The output is a table that has the population class as rows, and the years\n",
    "    since a fire as the columns. The items in the table are the optimal action\n",
    "    for that population class and years since fire combination.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    p : array\n",
    "        ``p`` is a numpy array of length ``S``.\n",
    "\n",
    "    \"\"\"\n",
    "    p = np.array(policy).reshape(n_pop_classes, n_fire_classes)\n",
    "    print(\"    \" + \" \".join(\"%2d\" % f for f in range(n_fire_classes)))\n",
    "    print(\"    \" + \"---\" * n_fire_classes)\n",
    "    for x in range(n_pop_classes):\n",
    "        print(\" %2d|\" % x + \" \".join(\"%2d\" % p[x, f] for f in\n",
    "                                     range(n_fire_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0  1  2  3  4  5  6  7  8  9 10 11 12\n",
      "    ---------------------------------------\n",
      "  0| 0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  1| 0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  2| 0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  3| 0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  4| 0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  5| 0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  6| 0  0  0  0  0  0  0  1  1  1  1  1  1\n"
     ]
    }
   ],
   "source": [
    "sdp = solve_mdp()\n",
    "print_policy(sdp.policy[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "1. Cordwell, SAW. [Optimal fire management of a threatened species, part 1](http://sawcordwell.github.io/mdp/conservation/2015/01/10/possingham1997-1/), Jan 10, 2015.\n",
    "\n",
    "1.\tPossingham H, Tuck G. Application of Stochastic Dynamic Programming to Optimal Fire Management of a Spatially Structured Threatened Species. In *Proceedings International Congress on Modelling and simulation*; 1997.\n",
    "\n",
    "2.\tZipkin EF, Jennelle CS, Cooch EG. A primer on the application of Markov chains to the study of wildlife disease dynamics. Methods in Ecology and Evolution. 2010;1(2):192–198. doi:10.1111/j.2041-210X.2010.00018.x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}